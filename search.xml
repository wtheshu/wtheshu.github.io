<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[合格运维人员必会的脚本列表]]></title>
    <url>%2F2018%2F03%2F01%2FShell%2F023.%20%E5%90%88%E6%A0%BC%E8%BF%90%E7%BB%B4%E4%BA%BA%E5%91%98%E5%BF%85%E4%BC%9A%E7%9A%84%E8%84%9A%E6%9C%AC%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[GO 合格运维人员必会的脚本列表下面列举的知识点是作为一个运维人员必须会的内容，这些内容不仅设计了脚本知识，还有设计了系统命令、大量网络服务的知识，这些都需要运维人员了解和掌握，Shell编程仅仅是其中的一部分内容。 作为一个合格的运维人员，需要掌握的脚本知识列表如下： 系统及各类服务的监控脚本，例如：文件、内存、磁盘、端口、URL监控报警等。 监控网站目录下的文件是否被篡改，以及当站点目录被批量篡改后如何批量恢复它们的脚本。 各类服务Rsync、Nginx、MySQL等的启动及停止专业脚本（使用chkconfig管理） MySQL主从复制监控报警，以及自动处理不复制故障的脚本 一键配置MySQL多实例、一键配置MySQL主从部署的脚本 监控HTTP、MySQL、Rsync、NFS、Memcached等服务是否异常的生产脚本。 一键软件安装及优化的脚本，比如LANMP、Linux一键优化，一键数据库安装、优化等。 MySQL多实例启动脚本，分库、分表自动备份脚本。 根据网络连接数及Web日志PV数封IP的脚本。 监控网站的PV及流量，并且对流量信息进行统计的脚本。 检查Web服务器多个URL地址是否异常的脚本，要是可以批量处理且通用的脚本。 对系统的基础配置一键优化的脚本. TCP连接状态及IP统计报警的脚本。 批量创建用户并设置随机8w位密码的脚本。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《黑客与画家》]]></title>
    <url>%2F2018%2F02%2F27%2FReading%2F003.%20%E3%80%8A%E9%BB%91%E5%AE%A2%E4%B8%8E%E7%94%BB%E5%AE%B6%E3%80%8B%2F</url>
    <content type="text"><![CDATA[GO 该书作者：Paul Graham该书译者：阮一峰 译者序这本书的内容不仅仅是写给程序员和创业者的，更是写给普通读者的。目的是让读者能够理解我们所处的这个计算机时代。从某种意义上说，这本书的作者试图从许许多多不同的方面解释这个时代的内在脉络，揭示它的发展轨迹，帮助读者看清我们现在的位置和将来的方向。 电子技术的发展，使得计算机日益称为人类社会必不可少的一部分。每个人日常生活的很大一部分都花在与计算机打交道上面。越来越多的迹象表明，未来的人类生活不仅是人与人的互动，而且更多的将是人与计算机的互动。 想要把握这个时代，就必须理解计算机。理解计算机的关键，则是要理解计算机背后的人。表面上这是一个机器的时代，但是实际上机器的设计者决定了我们的时代。程序员的审美决定了你看到的软件界面，程序员的爱好决定了你有什么样的软件可以使用。我们的时代是程序员主导的时代，而伟大的程序员就是黑客。这本书就是帮助你了解黑客、从而理解这个时代的一把钥匙。 要读懂这本书，首先就必须正确理解什么是黑客。那就让我们从源头说起。 1946年，第一台电子计算机ENIAC在美国诞生，从此世界上一些最聪明、最有创造力的人开始进入这个行业，在他们身上逐渐地形成了一种独特的技术文化。在这种文化的发展过程中，涌现了很多“行话”（jargon）。20世纪60年代初，麻省理工学院有一个学生团体叫做“铁路模型技术俱乐部”（Tech Model Railroad Club，简称TMRC），他们把难题的解决方法称为hack。 在这里，hack作为名词有两个意思，既可以指很巧妙或很便捷的解决方法，也可以指比较笨拙、不那么优雅的解决方法。两者都能称为hack，不同的是，前者是漂亮的解决方法（cool hack或neat hack），后者是丑陋的解决方法（ugly hack或neat hack）。hack的字典解释是砍（木头），在这些学生看来，解决一个计算机难题就好像砍倒一棵大树。那么相应地，完成这种hack的过程就被称为hacking，而从事hacking的人就是hacker，也就是黑客。 从这个意思触发，hack还有一个引申义，指对某个程序或设备进行修改、使其完成原来不可用的功能（或者禁止外部使用者接触到的功能）。在这种意义上，hacking可以与盗窃信息、信用卡欺诈或其它计算机犯罪联系在一起，这也是后来黑客一词被当作计算机入侵者的称呼的原因。 但是，在20世纪60年代这个词被发明的时候，黑客完全是正面意义上的称呼。TMRC使用这个词是带有敬意的，因为在他们看来，如果要完成一个hack，就必然包含着高度的革新、独树一帜的风格、精湛的技艺。最能干的人会自豪地称自己为黑客。 这时，黑客这个词不仅是第一流能力的象征，还包含着求解问题过程中产生的精神愉悦或享受。也就是说，从一开始，黑客就是有精深追求的。自由软件基金会创始人理查德·斯托曼说：“出于兴趣而解决某个难题，不管它有没有用，这就是黑客。” 根据理查德·斯拖曼的说法，黑客行为必须包含三个特点：好玩、高智商、探索净胜。只有其行为同时满足这三个标准，才能称为黑客。另一方面，它们也构成了黑客的价值观，黑客追求的就是这三种价值，而不是实用性或金钱。 1984年，《新闻周刊》的记者史蒂文·利维出版了历史上第一本介绍黑客的著作——《黑客：计算机革命的英雄》（Hackers: Heroes of the Computer Revolution）。在该书中，他进一步将黑客的价值观总结为六条黑客伦理（hacker ethic），直到今天这几条伦理都被视为这方面的最佳论述。 使用计算机以及所有有助于了解这个世界本质的事物都不应收到任何限制。任何事情都应该亲手尝试。（Access to computer-and anything that might teach you something about the way the world works-should be unlimited and total. Always yield to the Hands-On imperative!） 信息应该全部免费。（All information should be free.） 不信任权威，提倡去中心化。（Mistrust Authority-Promote Decentralization.） 判断一名黑客的水平应该看他的技术能力，而不是看他的学历、年龄或地位等其他标准。（Hackers should be judged by their hacking,not bogus criteria such as degrees,age,race,or position.） 你可以用计算机创造美和艺术。（You can create art and beauty on a computer.） 计算机使生活更美好。（Computers can change your life for the better.） 根据这六条黑客伦理，黑客价值观的核心原则可以概况成这样几点：分享、开放、民主、计算机的自由使用、进步。 黑客伦理的一个必然推论就是，黑客不服从管教，具有叛逆精神。黑客通常对管理者强加的】限制他们行为的愚蠢规定不屑一顾，会找出规避的方法。一部分原因是为了自由使用计算机，另一部分原因是为了显现自己的聪明。 这本书共15章，可以大致分成三个部分： 第一部分：1-4章，解释了黑客是如何成长的以及他们看待世界的一些观点。 第二部分：5-9章，解释了黑客怎样做出自己的成果，这些成果又是怎样对全世界产生影响。 第三部分：10-15章，解释了黑客的工具（编程语言）和工作方法，这是黑客文化的基础和核心。 《黑客与画家》这个书名就是在提示应该把黑客与画家当作同一种人看待。和画家一样，黑客只是怀有一门特殊手艺、有创造天赋的普通人。这个说明还有另外一层含义，即编程是一种艺术创作，黑客就是艺术家，开发软件与画家作画、雕塑家雕刻、建筑师设计房屋并没有本质不同。 总之，这是一本帮助你理解这个时代的书。作者想教给你的其实是新思想。读完以后，你看待世界的眼光很可能会完全不同了。 ————摘抄自 阮一峰做的译序 前言软件带来财富，仅仅代表了大趋势的一面而已。这中大趋势就是本书的主题。我们的时代是计算机时代。我们生活中的一切，都正在成为计算机。如果你想理解我们目前的世界以及它的未来动向，那么多了解一些黑客的想法会对你有帮助。 本书的前几章回答了一些大家可能都想过的问题： 怎样创业才会成功？ 技术是否造成了技术人员与普通人之间的隔阂？ 程序员到底在做什么？ 为什么那些读高中时普普通通的学生，最终却摇身一变成为世界上最有影响力的人士？ 怎样才能对付垃圾邮件？ 本书后面几章谈的是大多数非计算机行业的人士没有想过的问题——编程语言。为什么普通人要去关心编程语言？因为如果你想了解黑客，就必须懂一点编程语言。计算机程序只是文本而已。你选择什么语言，决定了你能说什么话。编程语言就是程序员的思维方式。因此很自然，编程语言对程序员的思想有巨大的影响。 为什么黑客那么在乎言论自由？我认为，部分原因在于，革新对于软件行业实在是太重要了，而革新和异端实际上是同一件事。优秀的黑客养成了一种质疑一切的习惯。这是肯定的，因为如果你不得不同一台机器打交道，而这台机器全部由文字组成，像机械式手表一样复杂，并且规模大出1000倍，那么你也会养成这种习惯的。此外，我还认为，行为怪异的人和愤世嫉俗的人比普通人更可能成为黑客。计算机世界就像是智力世界的大西部，在那里没有你不敢想的事情，只要你愿意承担冒险后果。 如果你喜欢思考，阅读此书应该会带给你很多乐趣。虽然黑客从外表看上去一般都是呆呆的，但是他们的大脑内部却是一个有趣得让你吃惊的地方。 1. 为什么书呆子不受欢迎聪明的书呆子一般在学校里面不会受到欢迎，这个问题的根源就是：书呆子的目标具有两重性，他们毫无疑问想让自己受欢迎，但是他们更愿意让自己聪明。 文艺复兴时期的代表人物阿尔伯蒂有一句名言：“任何一种艺术，不管是否重要，如果你想要在该领域出类拔萃，就必须全身心投入。”而大多数普通的学生在学校里面无时无刻都不在“如何让自己受欢迎”这件事上面全身心的投入。比如，他们很关注服饰，因为穿的好看会赢得其他小孩的赞赏。本质上说，对于那些普通小孩来说，同伴的意见称为他们判别事物的标准，这不仅体现在穿着上，还体现在他们做的几乎每一件事上。 而书呆子却没有认识到这一点，他们不受欢迎的真正原因，是他们脑子里想着别的事情。他们的注意力都放在读书或者观察世界上面，而不是放在穿衣打扮、开晚会上面。他们一直在做的，就是如何让自己更加的聪明。 聪明的书呆子往往会被人欺负，孩子们欺负书呆子的一部分原因，是青少年的心理还没有摆脱儿童状态，许多人都会残忍地对待他人。另一个原因是为了让自己感到好受一些。在任何社会等级制度中，那些对自己没自信的人就会通过虐待他们眼中的下等人来突显自己的身份。其实还有一个原因，孩子们欺负聪明的书呆子的主要原因也与追求受欢迎的心理有关。 成年人不知道孩子内部发生的事情。认识到这一点很重要。在抽象意义上，成年人知道孩子的行为有时是极端残酷的，这正如我们在抽象意义上知道贫穷国家的人民生活极端艰难。但是，像所有人一样，成年人不喜欢揪住不放这种令人不快的事实。你不去埋头探寻，就不会发现具体的证据，就会永远以为这件事是抽象的。 公立学校的老师很像监狱的狱卒。看着监狱的人主要关心的是犯人都待在自己应该待的位置。然后，让犯人有东西吃，尽可能不要发生斗殴和伤害事件，这就可以了。除此之外，他们一件事也不愿多管，没必要自找麻烦。所以，他们就听任犯人内部形成各种各样的小集团。根据我读到的材料，犯人内部的关系是扭曲、野蛮、无孔不入的。 总体上看，大多数学校与上面所说的监狱差不多。校方最重视的事情，就是让学生待在自己应该待的位置。与此同时，让学生有东西吃，避免公然的暴力行为，接下来才是尝试教给学生一些东西。除此之外，校方并不愿意在学生上多费心思。就像监狱的狱卒，老师们很大程度上对学生是最放任自然的。结果，学生就像犯人一样，发展出了野蛮的内部文化。 然而，在真实世界里就不会发生欺负聪明的书呆子这种情况。因为那是成年人的世界，他们都成熟了，不会把书呆子挑出来欺负。但是这并不是关键，关键是真实的世界它的庞大的规模，使得你做的每件事都能产生真正意义上的效果。真实世界的特点是，它及其庞大。如果总体足够大，即使是人数最少的少数派，只要聚集在一起，也能产生可观的力量。 如果能回到过去，我会向13岁的我提供一些建议，主要告诉他要昂起头看世界。我在那个年纪根本不知道这一点。在我生长的这个地方，感觉整个世界就是这么大，你根本没有别的地方可去，没有别的事情可做。这一点都不令人意外。郊区就是故意这样设计的，与外部世界隔离，不让儿童沾染到外界有害的东西。 至于学校，不过是这个虚假环境中关住牲口的围栏。表面上，学校的使命是教育儿童。事实上，学校的真正目的是把儿童都关在同一个地方，以便大人们白天可以腾出手来把事情做完。我对这一点没有意见，在一个高度工业化的社会，对孩子不加管束，让他们四处乱跑，无疑是一场灾难。 让我困扰的，不是把孩子关在监狱里，而是（a）不告诉他们这一点，（b）把这监狱的大部分交给犯人来管理。孩子们被送进来，花6年时间，记住一些毫无意义的事实，还要身处在一个由四肢发达的小巨人管理的世界，那些巨人们只知道追逐一个椭圆形的、棕色的球，好像这是全世界最天经地义的事情。这简直就像一场超现实的鸡尾酒化妆晚会，如果孩子畏缩不前、瑟瑟发抖，他们就会被视为怪人。 被其他小孩欺负只是问题的一部分。还有别的问题存在，甚至可能是更糟糕的问题。那就是我们没有得到真正的工作，没能发挥我们的才能。人类喜欢工作，在世界上大多数地方，你的工作就是你的身份证明。但是，我们那时做的所有事情根本就是无意义的，至少那时看来是这样。 最好的情况下，那些事情也不过是遥远的将来我们可能从事的实际工作的练习。它所面向的目标是如此遥远，以至于当时我们都不知道自己练习这些到底是为了干什么。更常见的情况是，那些事情不过是一系列随意设置的绳圈，你被要求一个个跳过去。你在学习中遇到的文字都是专为考试而设计的，目的就是为了出题，而不是为了讲清楚问题。（南北战争的三个主要原因是……等到考试的时候，就会有一道题：请列出南北战争的三个主要原因。） 过去的社会中，青少年扮演着一个更积极的角色。工业化时代到来前，青少年都是某种形式的学徒，不是在某个作坊，就是在某个农庄，甚至在某艘军舰上。他们不会被扔到一旁，创造自己的小社会。他们是成年人社会的低级成员。 以前的青少年似乎也更尊敬成年人，因为成年人都是看得见的专家，会传授他们所要学习的技能。如今的大多数青少年，对他们的家长在遥远的办公室所从事的工作几乎一无所知。他们看不到学校作业与未来走上社会后从事的工作有何联系（实际上，还是有那么一点点联系）。 如果青少年更尊重成年人，那么成年人也会更接受青少年。经过几年的训练，学徒就能担当重要的职责。即使是那些刚招收进来的学徒，也能用来送信或打扫场地。 如今的成年人根本不接受青少年。一般来说，他们都是在办公室工作，所以就在上班的路上，顺路把孩子送到学校去关着，这有点像他们周末外出度假时，把狗送到寄养的地方。 当今的青少年在生产活动中，根本就是毫无用处的。他们只能在诸如快餐店这样的地方充当廉价劳动力，而快餐店也看出来了，充分利用了这个事实。对于除此以外的几乎所有行业，青少年都会带来净损失。但是，他们又太年轻，不能放任不管，必须有人看着他们。最有效的解决方案，就是把他们集中在一个地方，用几个成年人看守所有小孩。 如果事情只发展到这一步，那么我们就是在描述一个监狱，唯一的区别就是这个监狱不是全日制的。问题在于，许多学校实际上真的停留在这一步。学校的使命据称是教育儿童，佴是并没有外在的压力监督他们把这件事做好。所以，大多数学校的教学质量都很糟糕，孩子们根本不把学习当回事，就连认真读书的孩子也是如此。许多时候，我们所有人——包括学生和老师——都只是做做样子，走过场而已。 还在学校里读书的书呆子不应该屏息凝神，等着全副武装的成年人某一天乘直升飞机从天而降来拯救你。也许会有这么一天，但是肯定不会很快到来。任何对生活立竿见影的改变，可能还是来自于书呆子自己。 哪怕你什么也改变不了，但是仅仅是理解自己的处境，也能使得痛苦减轻一些。书呆子并不是失败者。他们只是在玩一个不同的游戏，一个更接近于真实世界状况的游戏。成年人明白这一点。成功的成年人，几乎都声称自己在高中属于书呆子。 对于书呆子来说，意识到学校并非全部的人生，也是很重要的事情。学校是一个很奇怪的、人为设计出来的体系，一半像是无菌室，一半像是野蛮洪荒之地。它就像人生一样，里面无所不包，但又不是事物的真实样子。它只是一个暂时的过程，只要你向前看，你就能超越它，哪怕现在你还是身处其中。 如果你觉得人生糟透了，那不是因为体内激素分泌失调（你父母相信这种说法），也不是因为人生真的糟透了（你本人相信这种说法）。那是因为你对成年人不再具有经济价值（与工业社会以前的时期相比），所以他们把你扔在学校里，一关就是好几年，根本没有真正的事情可做。任何这种类型的组织都是可怕的生存环境。你根本不需要寻找其他的原因就能解释为什么青少年是不快乐的。 2. 黑客与画家 OK]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记16-Shell脚本开发环境的配置和优化]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F018.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016-Shell%E8%84%9A%E6%9C%AC%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E7%9A%84%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[GO 1. 使用Vim而不是Vi编辑器建议Shell程序或者Python程序开发都使用Vim。Vim是Vi的增强版，可以高亮显示代码、自动缩进等重要的功能。所以，要使用Vim来进行开发，可以将Vim的别名设置为Vi，这样一来，即使是用Vi的命令打开文件，也会调用Vim来进行工作。 因此，首先要做如下调整，以便只使用Vim作为开发脚本的工具：1234# echo 'alias vi=vim' &gt;&gt; /etc/profile# tail -1 /etc/profilealias vi=vim# source /etc/profile 经过上述调整后，当用vi命令时，会自动被vim替换。 2. 配置文件.vimrc的重要参数介绍在Linux中，每个用户都可以配置自己的Vim的风格，那就是~/.vimrc这个文件。我们可以进行适当的设置，从而达到高效开发的目的。 下面是一个在运维岗位用来开发Shell脚本时的一个设置：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208" ~/.vimrc" vim config file" date 2018-02-20" Created by theshu" """"""""""""" 全局配置""""""""""""" 关闭兼容模式set nocompatible" 设置历史记录步数set history=100" 开启相关插件filetype onfiletype plugin onfiletype indent on" 当文件在外部被修改时，自动更新该文件set autoread" 激活鼠标的使用set mouse=a""""""""""""" 字体和颜色""""""""""""" 开启语法syntax enable" 设置字体"set guifont=dejaVu\ Sans\ MONO\ 10"" 设置颜色"colorscheme desert" 高亮显示当前行set cursorlinehi cursorline guibg=#00ff00hi CursorColumn guibg=#00ff00""""""""""""" 代码折叠""""""""""""" 激活折叠功能set foldenable" 设置按照语法方式折叠（可简写set fdm=XX）" 共6种折叠方法："manual 手工定义折叠"indent 更多的缩进表示更高级别的折叠"expr 用表达式来定义折叠"syntax 用语法高亮来定义折叠"diff 对没有更改的文本进行折叠"marker 对文中的标志进行折叠set foldmethod=manual" 设置折叠区域的宽度" 如果不为0，则在屏幕左侧显示一个折叠标识列" 分别用 "-" 和 "+" 来表示打开和关闭的折叠set foldcolumn=0" 设置折叠层数为3setlocal foldlevel=3" 设置为自动关闭折叠set foldclose=all" 用空格键来代替zo和zc快捷键实现开关折叠" zo O-pen a fold (打开折叠)" zc C-lose a fold (关闭折叠)" zf F-old creation (创建折叠)nnoremap &lt;space&gt; @=((foldclosed(line('.')) &lt; 0) ? 'zc' : 'zo')&lt;CR&gt;""""""""""""" 文字处理""""""""""""" 使用空格来代替Tab"set expandtab" 设置所有的Tab和缩进为4个空格set tabstop=4" 设定 &lt;&lt; 和 &gt;&gt; 命令移动时的宽度为4set shiftwidth=4" 使得按退格键时可以一次删掉4个空格set softtabstop=4set smarttab" 缩进，自动缩进（继承前一行的缩进）"set autoindent 命令关闭自动缩进，是下面配置的缩写" 可使用autoindent命令的简写，即 ":set ai" 和 ":set noai"" 还可以使用 ":set ai sw=4" 在一个命令中打开缩进并设置缩进级别set ai" 智能缩进set si" 自动换行set wrap" 设置软宽度set sw=4""""""""""""" Vim界面""""""""""""" Turn on WiLd menuset wildmenu" 显示标尺set ruler" 设置命令行的高度set cmdheight=1" 显示行数set nu" Do not redraw, when running macros.. lazyredrawset lz" 设置退格set backspace=eol,start,indent"Bbackspace and cursor keys wrap toset whichwrap+=&lt;,&gt;,h,l" Set magic on （设置魔术）set magic" 关闭遇到错误时的声音提示" 关闭错误信息响铃set noerrorbells" 关闭使用可视响铃代替呼叫set novisualbell" 显示匹配的括号([&#123; 和 &#125;])set showmatch"How many tenths of a second to blinkset mat=2" 搜索时高亮显示搜索到的内容set hlsearch" 搜索时不区分大小写" 还可以使用简写（":set ic" 和 ":set noic"）set ignorecase""""""""""""" 编码设置""""""""""""" 设置编码set encoding=utf-8" 设置文件编码set fileencodings=utf-8" 设置终端编码set termencoding=utf-8""""""""""""" 其它设置""""""""""""" 开启新行时使用智能自动缩进set smartindentset cinset showmatch" 隐藏工具栏set guioptions-=T" 隐藏菜单栏set guioptions-=m" 置空错误铃音的终端代码set vb t_vb=" 显示状态栏（默认值为1，表示无法显示状态栏）set laststatus=2" 粘贴不换行问题的解决方法set pastetoggle=&lt;F9&gt;" 设置背景色set background=dark" 设置高亮相关highlight Search ctermbg=black ctermfg=white guifg=white guibg=black 说明：读者只需简单了解这些参数即可，实际使用时只需要把配置文件放到用户的家目录下，然后退出重新登陆即可使用Vim。 在Shell脚本的开头自动增加解释器及作者等版权信息123456789101112autocmd BufNewFile *.py,*.cc,*.sh,*.java exec ":call SetTitle()"func SetTitle() if expand("%:e") == 'sh' call setline(1, "#!/bin/bash") call setline(2, "#Author:oldboy") call setline(3, "#Blog:http://www.theshu.top") call setline(4, "#Time:".strftime("%F %T")) call setline(5, "#Name:".expand("%")) call setline(6, "#Version:V1.0") call setline(7, "#Description:This is a test script.") endifendfunc Vim路径等配置知识的整理如下表： 相关配置文件 功能描述 ~/.viminfo 用户使用vim的操作历史 ~/.vimrc 当前用户Vim的配置文件 /etc/vimrc 系统全局Vim的配置文件 /usr/share/vim/vim74/colors/ 配置模板文件存放路径 3. 让配置文件.vimrc生效将vim的配置文件.vimrc上传到Linux系统的家目录下，然后退出后重新登陆，即可应用.vimrc里对应的设置。 提示：同样适用于普通用户。 4. 使用Vim编辑器进行编码测试4.1. 代码自动缩进功能这个自动缩进的功能非常好用，当输入循环及条件结构语句等代码时，系统会自动将输入语句的关键字及命令代码缩进到合理的位置。而且缩进的宽度是可以在配置文件里面设置的。 4.2. 代码颜色高亮显示功能说明代码颜色高亮显示也是一个非常好的功能，可以通过它区分字符、变量、循环等很多不通的Shell脚本元素。例如当编写的代码出现错误时，对应的代码高亮颜色就会和正确时的不同，开发者可以根据代码的高亮颜色对Shell脚本进行调试，提升编码的效率，减少编码的错误。 5. Vim配置文件的自动增加版权功能配置文件的最后一段的意思就是自动为Shell脚本文件自动增加版权信息的，也可以对照着配置其它编程语言的相关信息。 6. Vim配置文件的代码折叠功能Vim非常强大，只不过对有些功能需要进行额外配置，比如在代码量较大时比较有用的高级功能——代码折叠（依赖.vimrc配置，当然也可以以命令模式执行）。 在命令模式下，可以把光标定位到当前的第2行，然后执行zf3j命令，便可将第2行及其下面的3行缩进，其他缩进也是如此。 在配置文件中，我们配置了这样的功能：把光标放到对应折叠后的行上，按空格键即可展开上述折叠的行。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记15-Shell脚本的调试]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F017.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015-Shell%E8%84%9A%E6%9C%AC%E7%9A%84%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[GO 这篇笔记是关于Shell脚本的调试知识，掌握了Shell脚本的调试技巧，可以让我们在开发大型脚本时做到事半功倍。虽然掌握了Shell脚本的调试技巧很重要，但是如果能够掌握并养成良好的Shell脚本开发的规范和习惯，就可以从源头上降低开发脚本的错误率，从而降低脚本调试的难度和时间，达到未雨绸缪的效果。 1. 常见Shell脚本错误范例1.1. if条件语句缺少结尾关键字 范例代码： 12345[root@theshu ~]# cat if.sh#!/bin/bashif [ 10 -lt 12 ]then echo "Yes, 10 is less than 12." 执行结果如下： 12[root@theshu ~]# sh if.shif.sh: line 5: syntax error: unexpected end of file 结果给出了提示，第5行存在语法错误：这不是所期待的（意外的）文件结尾。根据这个提示，我们知道脚本的尾部有问题，仔细观察发现，原来是缺少了fi结尾。 说明； 在Shell脚本开发中，脚本缺少fi关键字是很常见的问题。另外，当执行脚本时提示输出错误后，不要只看那些提示的错误行，而是要观察整个相关的代码段。 Shell脚本解释器一般不会对脚本错误进行精确的定位，而是在试图结束一个语句时进行错误统计，因此，掌握语法并养成良好的规范和习惯就显得很重要。 1.2. 循环语句缺少关键字for、while、until和case语句中的错误是指实际语句段不正确，也许是漏写或拼错了固定结构中的一个保留字。 范例：循环结构语句中缺少关键字引起的错误。 脚本内容 123456789101112#!/bin/bashwhile truedo status=`curl -I -s --connect-timeout 10 $1 | awk '&#123;print $2&#125;'` ok=`curl -I -s --connect-timeout 10 | head -1 | cut -d " " -f 3` if [ "$status" = "200" ] &amp;&amp; [ "$ok" = "ok" ]; the echo "this yrl is good" else echo "this url is bad" fi sleep 3done 执行上述脚本的结果： 12while.sh: line 8: syntax error near unexpected token `else'while.sh: line 8: ` else' 通过提示可知吗，是第8行的语法错误，在else附近。经过前后观察可以发现，the少加了个n，应为then。 如果报错的是循环或条件独立的语句，对上下关联部分语句也都要看一下。 1.3. 成对的符号落了单成对的符号有[]、()、{}、&quot;&quot;、&#39;&#39;等，如果它们落了单，也会导致一些错误。但是這些错误通过错误提示即可很快排除。 1.4. 中括号两端没空格中括号两端没空格导致的错误 代码如下： 123456789#!/bin/basha=3b=1if [$a -lt $b]then echo "Yes,$a &lt; $b"else echo "Yes,$a &gt;= $b"fi 执行结果如下： 12zhongkuohao.sh: line 4: [3: command not foundYes,3 &gt;= 1 1.5. Shell语法调试小结Shell的语法调试并不是很智能，报错也不是很精准，因此就需要我们在开发规范和书写脚本上多下功夫，企业里的Shell脚本大多都是比较短的，因此，开发起来也相对轻松。 如果能在开发过程中，重视书写习惯、开发规范和开发制度，那么就会减少脚本调试的难度和次数，提升开发效率。此外，要对Shell的基本语法十分熟练，这样才能更好地利用脚本调试。 此外，写脚本的思路要清晰，否则将给调试带来困难。可采用的思路如下： 首先思考开发框架，尽量模块化开发，复杂的脚本要简单化、分段实现。并采用打游戏过关的思想（第一关、第二关、第三关、直到通关）去完善框架结构。 然后利用函数分模块开发，语法结构如下： 1234函数1()函数2()main()main $* #&lt;==执行主函数 需要注意的是，不要强制模块化，分块要合理。 2. Shell脚本调试技巧2.1. 使用dos2unix命令处理在Windows下开发的脚本因为Windows系统下的文本文件和Linux系统下的文本文件在一些符号上面有差别（比如结尾换行符），所以，在Windows下编辑的Shell脚本直接放在Linux下执行会出现错误，所以需要用dos2unix工具来转换一下文件。 格式：dos2unix filename.sh 如果没有dos2unix，则用下面的命令进行安装：yum install dos2unix -y 2.2. 使用echo命令调试echo命令是最有用的调试脚本的工具之一。一般应在可能出现问题的脚本的重要部分加入echo命令，例如在变量读取或修改操作的前后加入echo命令，并紧挨着退出命令exit。 利用echo调试一个简单的判断脚本：1234567#!/bin/bashread -p "Pls input two num:" a becho $a $b #&lt;==增加打印输出，确认变量值是否符合要求exit #&lt;==退出脚本，目的是不执行后面的代码###########后面的代码省略...... 提示：这个调试方法不是Shell的专利，PHP、ASP、Perl、Python等语言都可以使用这样简单又好用的调试方法。 2.3. 使用bash命令参数调试可以利用bash或sh本身自带的参数进行调试。格式为：sh [-nvx] script.sh 参数 说明 -n 不会执行该脚本，仅查询脚本语法是否有问题，并给出错误提示 -v 在执行脚本时，先将脚本的内容输出到屏幕上，然后执行脚本，如果有错误，也会给出错误提示 -x 将执行的脚本内容及输出显示到屏幕上，这是对调试很有用的参数 说明：这些参数同样适用于bash 2.3.1. sh参数-n的测试12345678910111213[root@theshu ~]# cat script.sh#!/bin/bashecho "Hello $USER,"echo "Today is $(date +%F)"[root@theshu ~]# sh -n script.sh #&lt;==当脚本没错时什么也不显示[root@theshu ~]# vim script.sh[root@theshu ~]# cat script.sh #&lt;==修改成有问题的脚本#!/bin/bashecho "Hello $USER,echo "Today is $(date +%F)"[root@theshu ~]# sh -n script.sh #&lt;==有错误显示script.sh: line 3: unexpected EOF while looking for matching `"'script.sh: line 4: syntax error: unexpected end of file 2.3.2. sh参数-v的测试 普通的错误脚本的执行结果如下： 123456[root@theshu ~]# sh -v script.sh#!/bin/bashecho "Hello $USER,echo "Today is $(date +%F)"script.sh: line 3: unexpected EOF while looking for matching `"'script.sh: line 4: syntax error: unexpected end of file 带函数的错误脚本的执行结果如下： 123456789101112131415[root@theshu ~]# sh -v c.sh#!/bin/bashtheshu()&#123; echo "I am theshu!"&#125;theshan()&#123; echo "I am theshan "&#125;theshu1c.sh: line 11: theshu1: command not foundtheshanI am theshan 2.3.3. sh参数-x的测试 跟踪script.sh脚本的执行过程： 1234[root@theshu ~]# cat script.sh#!/bin/bashecho "Hello $USER,"echo "Today is $(date +%F)" 执行结果如下： 123456[root@theshu ~]# sh -x script.sh+ echo 'Hello root,'Hello root,++ date +%F+ echo 'Today is 2018-03-01'Today is 2018-03-01 说明： 使用-x追踪脚本是一种非常好的方法，它可以在执行前列出所执行的所有程序段 如果是程序段落，则在输出时，最前面会加上+符号，表示它是程序代码 一般情况下如果是调试逻辑错误的脚本，用-x的效果更佳 缺点是：加载系统函数库等很多我们不想看其整个过程的脚本时，会有太多输出，导致很难查看所需的内容 利用sh -x filename.sh调试的缺点可以用set -x命令来弥补，它可以缩小调试的作用域 在一个比较长的脚本中，你会看到很多的执行跟踪的输出，有时候阅读起来非常费劲，此时，可以在每一行的前面内容修改一下提示符，这会非常有用。要做到这样，只需要设置下面的环境变量： 12345# set | grep PS[1-5]PS1='[\u@\h \W]\$ 'PS2='&gt; 'PS4='+ '#&lt;==只需修改PS4变量即可，在默认情况下表示加号 参数-x是一个不可多得的参数，在生产环境中，经常会通过参数-x来实现调试的目的。一般情况下，如果执行脚本发生问题（非语法问题），利用-x参数，就可以知道问题出在哪一行。 2.4. 使用set命令调试部分脚本内容set命令也可以用于辅助脚本调试。以下是set命令常用的调试选项。 选项 说明 set -n 读命令但并不执行 set -v 显示读取的所有行 set -x 显示所有命令及其参数 提示：通过set -x命令开启调试功能，而通过set +x关闭调试功能。 set命令的最大优点是，和bash -x相比，set -x可以缩小调试的作用域。 范例：调试打印九九乘法表的简版脚本： 脚本内容： 123456789101112[root@theshu ~]# cat 99dug.sh#!/bin/bashset -x #&lt;==表示从这里开启脚本调试for a in `seq 9`do for b in `seq 9` do [ $a -ge $b ] &amp;&amp; echo -en "$a x $b = $(expr $a \* $b) " doneset +x #&lt;==表示到这里结束脚本调试echo " "done 执行脚本查看调试输出结果： 12345678910111213141516171819202122232425262728293031323334[root@theshu ~]# sh 99dug.sh++ seq 9+ for a in '`seq 9`'++ seq 9+ for b in '`seq 9`'+ '[' 1 -ge 1 ']'++ expr 1 '*' 1+ echo -en '1 x 1 = 1 '1 x 1 = 1 + for b in '`seq 9`'+ '[' 1 -ge 2 ']'+ for b in '`seq 9`'+ '[' 1 -ge 3 ']'+ for b in '`seq 9`'+ '[' 1 -ge 4 ']'+ for b in '`seq 9`'+ '[' 1 -ge 5 ']'+ for b in '`seq 9`'+ '[' 1 -ge 6 ']'+ for b in '`seq 9`'+ '[' 1 -ge 7 ']'+ for b in '`seq 9`'+ '[' 1 -ge 8 ']'+ for b in '`seq 9`'+ '[' 1 -ge 9 ']'+ set +x2 x 1 = 2 2 x 2 = 43 x 1 = 3 3 x 2 = 6 3 x 3 = 94 x 1 = 4 4 x 2 = 8 4 x 3 = 12 4 x 4 = 165 x 1 = 5 5 x 2 = 10 5 x 3 = 15 5 x 4 = 20 5 x 5 = 256 x 1 = 6 6 x 2 = 12 6 x 3 = 18 6 x 4 = 24 6 x 5 = 30 6 x 6 = 367 x 1 = 7 7 x 2 = 14 7 x 3 = 21 7 x 4 = 28 7 x 5 = 35 7 x 6 = 42 7 x 7 = 498 x 1 = 8 8 x 2 = 16 8 x 3 = 24 8 x 4 = 32 8 x 5 = 40 8 x 6 = 48 8 x 7 = 56 8 x 8 = 649 x 1 = 9 9 x 2 = 18 9 x 3 = 27 9 x 4 = 36 9 x 5 = 45 9 x 6 = 54 9 x 7 = 63 9 x 8 = 72 9 x 9 = 81 提示：加了set -x，在运行脚本的时候，就不要使用sh -x了。 熟悉sh及set的用法，可以让我们能够得心应手地管理Linux下Shell脚本执行的过程。在Shell脚本的学习上，需要“多看、多模仿，并将已有脚本修改成自己需要的样式”，这是最快的学习手段。网络上有很多实用的脚本，作为初学者，可以先将这些脚本拿过来，将其改成为适合自己服务器的脚本，然后再慢慢熟悉，慢慢尝试开发新的脚本。这种先模仿后开发的学习方法，会让你的学习事半功倍，而且学习起来也会很有兴趣和成就感。 Linux系统上本来就有很多适合阅读的规范脚本，如果想要更加深入地掌握Shell脚本编程，最好的方法就是阅读系统的这些脚本，然后仔细研究每一行都是什么作用，为什么这样写，久而久之，你的Shell开发水平就会得到大幅度提高。 2.5. 其它调试Shell脚本的工具下面再引荐两款Shell的调试工具吗，可以作为扩展知识来研究一下。 Shell调试工具：bashdb：它是一个类似于GDB的调试工具，可以完成对Shell脚本的断点设置、单步执行、变量观察等许多功能。不过一般很少有人使用它。 Shell调试工具：shellcheck：它是一个可检查sh/bash脚本和命令语法的小工具。一般也是很少有人使用它。 3. 小结这篇学习笔记主要介绍了Shell的调试技巧，包括： 要记得首先用dos2unix对脚本（从其它地方拿来用的）进行格式化。 执行脚本根据报错来调试时，要知道有时所报错误会不准确，应多关联上下文查看。 可通过sh -x命令调试整个脚本，且显示执行过程。 set -x和set +x命令用于调试部分脚本的执行过程（可在脚本中设置）。 可通过echo命令输出脚本中要确认的变量及相关内容，然后紧跟着使用exit退出，不执行后面程序，这种方式便于一步步跟踪脚本，对于逻辑错误的调试比较好用。写法即：echo $var; exit 最关键的还是要语法熟练，养成良好的编码习惯，提高编程思想，将错误扼杀在萌芽状态之中，从而降低错误率，减轻调试的负担，提高开发效率。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记14-Shell脚本开发规范]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F016.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014-Shell%E8%84%9A%E6%9C%AC%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[GO Shell脚本开发规范及习惯非常重要，有了好的规范和习惯，才能大大提升开发效率，降低后期的脚本维护成本，特别是在多人协作开发时，有一个互相遵守的规范显得特别重要。即使是自己一个人独自开发，也要采取一套科学的、固定的规范，这样脚本才更易读，易于后期维护。总之，就是要让自己养成一个一出手就是专业和规范的习惯。 1. Shell脚本基本规范1.1. 一些基本规范 在Shell脚本里，第一行通常用于指定脚本解释器。 该行内容为：#!/bin/bash或#!/bin/sh。 说明：此项在Linux系统场景下可能不是必须的，属于优秀规范和习惯 在Shell脚本的开头处解释器代码后，最好加上版本版权等信息，如下： 12345#Date: 13:30 2018-03-01#Author: Theshu#Mail: theshu@qq.com#Function: This scripts function is...#Version: 0.1 说明：可以在~/.vimrc配置文件时自动加上以上信息的功能。此项在Linux系统场景下不是必须的，属于优秀规范和习惯。 Shell脚本中尽量不要用中文注释，应用英文注释，以防止本机或切换系统环境后出现中文乱码的困扰。如果非要加中文，请根据自身的客户端对系统进行字符集调整，如：export LANG=&quot;zh_CN.UTF-8&quot;，并在脚本中重新定义字符集，使其和系统一致。 Shell脚本命名应以.sh为扩展名。例如：script-name.sh Shell脚本应存放在固定的路径下，例如：/server/scripts 1.2. 代码书写技巧 成对的符号应尽量一次写出来，然后退格在符号里增加内容，以防止遗漏。这些成对的符号包括： 1&#123;&#125;、[]、''、``、"" 中括号[]两端至少要有一个空格，因此，键入中括号的时候即可留出空格[ ]，然后再退格键入中间的内容，并确保两端都至少有一个空格。即：先键入一对中阔后，然后退一个格，输入两个空格，再退一个格，双中括号[[]]的写法也是如此。 对于流程控制语句应一次将格式写完，再添加内容。 比如：if语句的格式一次完成应为 1234if 条件内容then 内容fi 再比如：for循环语句的格式一次完成应为 1234fordo 内容done 提示：while和until、case等语句也是一样。 通过缩进让代码更易读，比如： 12345678if 条件内容then 内容fi############if 条件内容; then 内容fi 字符串赋值给变量时应加双引号，并且等号前后不能有空格。例如：THESHU_FILE=&quot;test.txt&quot; 脚本中的单引号、双引号及反引号，必须为英文状态下的符号，其实所有的Linux标准字符及符号都应该是英文状态下的符号，这一点需要特别注意。 2. Shell脚本变量命名及引用变量规范2.1. 全局变量定义全局变量也称环境变量，它的定义应全部大写，如APACHE_ERR或APACHEERR，名字对应的语义要尽量清晰，能够正确表达变量内容的含义，对于过长的英文单词可用前几个字符代替。多个单词间可用_符号连接，全局变量的定义一般放在系统的全局路径中，并且最好蚕蛹export来定义，全局变量一般可以在任意子Shell中直接使用（特殊情况除外，例如：定时任务执行Shell时就最好在Shell里重新定义这些全局变量，否则可能会出现问题）。 2.2. 局部变量定义局部变量也成为普通变量，在常规脚本中，普通变量的命名也要尽可能统一，可以使用用驼峰语法，即第二个单词的首字母大写，如theshuHome，或者每个单词首字母大写，如TheshuHome，当然也有人喜欢采用全部大写或全部小写的方式，例如：theshuhome、THESHUHOME。选择一种适合自己的方式即可。 Shell函数中的变量可以使用local方式进行定义，使之只在本函数作用域内有效，防止函数中的变量名称与外部程序中的变量相同，从而造成程序异常。下面是在函数中定义变量的例子：1234567function testFunc()&#123; local i for ((i=0; i&lt;5; i++)) do echo "do something" done&#125; 2.3. 变量的引用规范在引用变量时，若变量前后都有字符，则需要使用${APACHE_ERR}（加大括号的方式）引用变量，以防止产生歧义；当变量内容为字符串时，需要使用&quot;${APACHE_ERR}&quot;（外面加双引号的方式）引用变量；当变量内容为整数时，则最好直接使用$APACHE_ERR来引用变量。全局变量、局部变量、函数变量、数组变量等都是如此。 说明：对于需要环境变量的Java程序脚本等，在写脚本之前，最好通过export重新声明环境变量，一面在定时任务等场合的使用中出现问题。 3. Shell函数的命名及函数定义规范Shell函数的命名可采用单词首字母大写的形式，如CreateFile()，并且语义要清晰，比如，使用CreateFile()代替CFILE()。也可以使用小写形式，如createfile()。 可以加前后缀，如后缀为Max则为最大值，为Min则表示最小值，前缀Is为判断型函数，Get为取值函数，Do则为处理函数，这也有益于对函数功能的理解，使函数名更直观、更清晰。 范例：对操作系统函数库脚本的函数名进行定义：123456789# /etc/init.d/functionsif_ignored_file()&#123; case "$1" in *~ | *.bak | *.orig | *.rpmnew | *.rpmorig | *.rpmsave return 0 ;; esac return 1&#125; 如果需要区别一些常规的字符串，可在函数名前加上function关键字，如下：123function CreateFile()&#123; ...&#125; 显示函数返回值时，可在函数的结尾内容中包含return语句，并跟上返回值。即使是不关心返回值的函数，也可能在后续调用时无意识地去判断它的返回值并进行一系列动作，使用return语句不会带来多少负担，但确实能让函数的逻辑变得更加清晰和严谨。 范例：为操作系统函数库脚本函数定义return返回值123456# Log a warningwarning()&#123; local rc=$? [ "$BOOTUP" != "verbose" -a -z "$&#123;LSB:-&#125;" ] &amp;&amp; echo_warning return $rc&#125; 4. Shell脚本（模块）高级命名规范 常规的Shell脚本使用统一的后缀：.sh，例如theshu.sh 模块的启动和停止脚本统一命名为start_模块名.sh和stop_模块名.sh 监控脚本通常以*_mon.sh为后缀 控制脚本一般以*_ctl.sh为后缀 5. Shell脚本的代码风格5.1 代码框架易变的信息（如报警的收件人、机器名、用户名密码、URL等）最好都定义为变量或使用特殊位置的参数，这会使开发的脚本更具通用性。 把Shell的通用变量以配置文件的形式单独存放，以功能.cfg来命令，例如nginx.conf，并放在conf目录下；引用时通过在脚本开头使用conf/nginx.conf的形式来加载。 将程序的功能分段、分模块采用函数等来实现，并存放到单独的函数文件里，如过是通用的公共函数可以存放在/etc/init.d/functions下，调用时采用source 文件全路径即可。 把脚本中的功能和配置明确分开，主脚本只用于实现程序主干，加载配置及加载函数等功能实现应尽量封装在子函数中。 规范代码树如下：123456789[root@theshu scripts]# tree.|-- bin| `-- ipsecctl|-- conf| `-- ipsec.cfg`-- func `-- functions3 directories, 3 files 5.2. 缩进规范在使用条件语句时，每进行一层循环或是循环内部的操作时，就使用一个缩进，缩进一般用Tab键加空格。推荐采用4个空格缩进。 范例：写出脚本缩进规范：123456789if [ -d theshu_dir ]then cd theshu_dir if [ -f theshu_file ] then echo "DoSth" fi cd ..fi 提示：可调整Vim实现自动缩进，建议缩进4个空格。 6. Shell脚本的变量及文件检查规范脚本中要检查配置项是否为空、是否可执行等，尤其是对于一些重要的、会影响下面脚本正常运行的配置想，必须要进行是否为空等的检查，避免配置文件中出现遗漏等问题。 范例：针对字符串变量进行判断：1234if [ -n "$&#123;FILE_PATH&#125;" ]then echo "Do something"fi 范例：给出HTTP脚本变量的定义方式：1234httpd=$&#123;HTTPD-/usr/sbin/httpd&#125;prog=httpdpidfile=$&#123;PIDFILE-/var/run/httpd.pid&#125;lockfile=$&#123;LOCKFILE-/var/lock/subsys/httpd&#125; 提示：这样的定义可以防止变量出现空着，这是变量子串的特殊知识。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记13-Shell数组]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F015.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013-Shell%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[GO 1. Shell数组介绍1.1. 为什么会产生Shell数组通常在开发Shell脚本时，定义变量采用的形式为a=1;b=2;c=3，可如果有多个变量呢？这时再逐个地定义就会很费劲，并且要是有多个不确定的变量内容，也会难以进行变量定义，此外，快速读取不同变量的值也是一件很痛苦的事情，于是数组就诞生了，它就是为了解决上述问题而出现的。 1.2. 什么是Shell数组简单地说，Shell的数组就是一个元素集合，它把有限个元素（变量或字符内容）用一个名字来命令，然后用编号对它们进行区分。这名字就称为数组名，用于区分不同内容的编号就称为数组下标。组成数组的各个元素（变量）称为数组的元素，有时也称为下标变量。 有了Shell数组之后，就可以用相同名字来引用一系列变量及变量值了，并通过数字（索引）来识别使用它们。在很多场合中，使用数组可以缩短和简化程序开发。 2. Shell数组的定义与增删改查2.1. Shell数组的定义Shell数组的定义有多种方法，列举如下： 方法1用小括号将变量值括起来赋值给数组变量，每个变量值之间要用空格进行分隔。 语法：array=(value1 value2 value3 ...) 示例如下：123[root@theshu ~]# array=(1 2 3) #&lt;==数组定义[root@theshu ~]# echo $&#123;array[*]&#125; #&lt;==输出上面定义的数组的所有元素值，注意语法1 2 3 方法2用小括号将变量值括起来，同时采用键值对的形式赋值。 语法：array=([1]=one [2]=two [3]=three) 此种方法为key-value键值对的形式，小括号里对应的数字为数组下标，等号后面的内容为下标对应的数组变量的值，此方法比较复杂，不推荐使用。 示例如下：123456789[root@theshu ~]# array=([1]=one [2]=two [3]=three) #&lt;==数组定义[root@theshu ~]# echo $&#123;array[*]&#125; #&lt;==输出上面定义的数组的所有元素值one two three[root@theshu ~]# echo $&#123;array[1]&#125; #&lt;==输出上面定义的数组的第一个元素值one[root@theshu ~]# echo $&#123;array[2]&#125; #&lt;==输出上面定义的数组的第二个元素值two[root@theshu ~]# echo $&#123;array[3]&#125; #&lt;==输出上面定义的数组的第三个元素值three 方法3通过分别定义数组变量的方法来定义。 语法：array[0]=a; array[1]=b; array[2]=c 此种定义方法比较麻烦，不推荐使用。 示例如下：123456[root@theshu ~]# array[0]=a[root@theshu ~]# array[1]=b[root@theshu ~]# array[2]=c[root@theshu ~]# array[3]=d[root@theshu ~]# echo $&#123;array[*]&#125;a b c d 方法4动态地定义数组变量，并使用命令的输出结果作为数组的内容。 语法：123array=($(命令))或 array=(`命令`) 示例如下：12345678910[root@theshu ~]# mkdir /array/ -p[root@theshu ~]# touch /array/&#123;1..3&#125;.txt[root@theshu ~]# ll /array/total 0-rw-r--r-- 1 root root 0 Mar 1 11:31 1.txt-rw-r--r-- 1 root root 0 Mar 1 11:31 2.txt-rw-r--r-- 1 root root 0 Mar 1 11:31 3.txt[root@theshu ~]# array=($(ls /array))[root@theshu ~]# echo $&#123;array[*]&#125;1.txt 2.txt 3.txt 方法5还可以使用declare -a array来定义数组类型，但是这样用的情况比较少。一般不用。了解即可。 2.2. Shell数组的打印及输出1. 打印数组元素此为常用知识点，需要重点掌握。 打印单个数组元素用${数组名[下标]}，当未指定数组小标时，数组的小标将从0开始。 使用*或@可以得到整个数组的内容。 示例如下：1234567891011[root@theshu ~]# array=(one two three)[root@theshu ~]# echo $&#123;array[0]&#125;one[root@theshu ~]# echo $&#123;array[1]&#125;two[root@theshu ~]# echo $&#123;array[2]&#125;three[root@theshu ~]# echo $&#123;array[*]&#125;one two three[root@theshu ~]# echo $&#123;array[@]&#125;one two three 2. 打印数组元素的个数此为常用知识点，需要重点掌握。 使用${井数组名[@或*]}可以得到数组的长度。 这和变量子串的知识是一样的，因为数组也是变量，只不过是特殊的变量，因此变量的子串替换等知识也适用于数组。 示例如下：12345678[root@theshu ~]# echo $&#123;array[*]&#125;one two three[root@theshu ~]# echo $&#123;#array[*]&#125;3[root@theshu ~]# echo $&#123;array[@]&#125;one two three[root@theshu ~]# echo $&#123;#array[@]&#125;3 3. 数组赋值此知识不常用，了解即可。 可直接通过数组名[下标]对数组进行引用赋值，如果下标不存在，则自动添加一个新的数组元素，如果小标存在，则覆盖原来的值。 示例如下：123456789[root@theshu ~]# array=(one two three)[root@theshu ~]# echo $&#123;array[*]&#125;one two three[root@theshu ~]# array[3]=four[root@theshu ~]# echo $&#123;array[*]&#125;one two three four[root@theshu ~]# array[0]=theshu[root@theshu ~]# echo $&#123;array[*]&#125;theshu two three four 4. 数组的删除因为数组本质上还是变量，因此可通过unset 数组[下标]清除相应的数组元素，如果不带下标，则表示清除整个数组的所有数据。 示例如下：1234567[root@theshu ~]# echo $&#123;array[*]&#125;theshu two three four[root@theshu ~]# unset array[1][root@theshu ~]# echo $&#123;array[*]&#125;theshu three four[root@theshu ~]# unset array[root@theshu ~]# echo $&#123;array[*]&#125; 5. 数组内容的截取和替换这里和变量子串的替换是一样的，因为数组是特殊的变量。 数组元素部分的内容截取的示例如下：12345678910[root@theshu ~]# array=(1 2 3 4 5)[root@theshu ~]# echo $&#123;array[@]:1:3&#125; #&lt;==截取1号到3号数组元素2 3 4[root@theshu ~]# array=($(echo &#123;a..z&#125;)) #&lt;==将变量的结果赋值给数组变量[root@theshu ~]# echo $&#123;array[@]&#125;a b c d e f g h i j k l m n o p q r s t u v w x y z[root@theshu ~]# echo $&#123;array[@]:1:3&#125; #&lt;==截取下标为1到3的数组元素b c d[root@theshu ~]# echo $&#123;array[@]:0:2&#125; #&lt;==截取下标为0到2的数组元素a b 替换数组元素部分内容的代码如下：1234[root@theshu ~]# array=(1 2 3 1 1)[root@theshu ~]# echo $&#123;array[@]/1/b&#125;b 2 3 b b#&lt;==把数组中的1替换成b，原数组未被修改，和sed很像 提示：调用方法为${数组名[@或*]/查找字符/替换字符}，该操作不会改变原先数组的内容，如果需要修改，可以参考上面的例子，重新定义数组。 删除数组元素部分内容的代码如下：1234567891011[root@theshu ~]# array=(one two three four five)[root@theshu ~]# echo $&#123;array[@]&#125;one two three four five[root@theshu ~]# echo $&#123;array[@]#o*&#125; #&lt;==从左边开始匹配最短的数组元素，并删除ne two three four five[root@theshu ~]# echo $&#123;array[@]##o*&#125; #&lt;==从左边开始匹配最长的数组元素，并删除two three four five[root@theshu ~]# echo $&#123;array[@]%f*&#125; #&lt;==从右边开始匹配最短的数组元素，并删除one two three[root@theshu ~]# echo $&#123;array[@]%%f*&#125; #&lt;==从右边开始匹配最长的数组元素，并删除one two three 提示：数组也是变量，因此也适合于前面讲解过的变量的子串处理的功能应用。数组的其他相关知识可通过man bash命令然后搜索Areays来了解。 3. Shell数组脚本开发实践范例1：使用循环批量输出数组的元素 方法1：通过C语言型的for循环语句打印数组元素 123456#!/bin/basharray=(1 2 3 4 5)for ((i=0; i&lt;$&#123;#array[*]&#125;; i++))do echo $&#123;array[i]&#125;done 方法2：通过普通for循环语句打印数组元素 123456#!/bin/basharray=(1 2 3 4 5)for n in $&#123;array[*]&#125;do echo $ndone 方法3：使用while循环语句打印数组元素 12345678#!/bin/basharray=(1 2 3 4 5)i=0while ((i&lt;$&#123;#array[*]&#125;)) do echo $&#123;array[i]&#125; ((i++))done 范例2：通过竖向列举法定义数组元素并批量打印12345678910111213#!/bin/basharray=( theshu theshan thepi thewang )for ((i=0; i&lt;#&#123;#array[*]&#125;; i++))\do echo "This is num $i, then content is $&#123;array[$i]&#125;"doneecho ------------------echo "array len:$&#123;#array[*]&#125;" 4. Shell数组的重要命令4.1. 定义命令 静态数组：array=(1 2 3) 动态数组：array=($(ls)) 为数组赋值：array[3]=4 4.2. 打印命令 打印所有元素：${array[@]}或${array[*]} 打印数组长度：${井array[@]}或${井array[*]} 打印单个元素：${array[i]}其中i是数组下标 4.3. 循环打印的常用基本语法1234567891011121314151617#!/bin/basharr=( 10.0.0.11 10.0.0.22 10.0.0.33)#&lt;==C语言型for循环语法for ((i=0; i&lt;$&#123;#arr[*]; i++&#125;))do echo "$&#123;arr[$i]&#125;"doneecho ----------------#&lt;==普通for循环语法for n in $&#123;arr[*]&#125;do echo "$n"done 5. Shell数组相关面试题及高级实战案例5.1. 范例1利用bash for循环打印下面这句话中字母数不大于6的单词（某企业面试真题）：I am theshu teacher welcome to theshu training class 解答思路具体如下： 先把所有的单词放到数组里，然后一次进行判断。命令：array=(I am theshu teache welcome to theshu training class) 计算变量内容的长度。常见的方法有4种：char=theshu echo $char | wc -L echo ${井char} expr length $char echo $char | awk &#39;{print length($0)}&#39; 方法1：通过数组方法来实现（本例给出了用两种for循环打印数组元素的方法）： 123456789101112131415arr=(I am theshu teacher welcome to theshu training class)for ((i=0; i&lt;$&#123;#arr[*]; i++&#125;))do if [ $&#123;#arr[$i]&#125; -lt 6 ] then echo "$&#123;arr[$i]&#125;" fidoneecho ------------for word in $&#123;array[*]&#125;do if [ `expr length $word` -lt 6 ];then echo $word fidone 方法2：使用for循环列举取值列表法： 123456789101112131415for word in I am theshu teacher welcome to trheshu training classdo if [ `echo $word | wc -L` -lt 6 ]; then echo $word fidonechars="I am theshu teacher welcome to theshu training class"for word in $charsdo if [ `echo $word | wc -L` -lt 6 ]; then echo $word fidone 方法3：通过awk循环实现 12chars-"I am theshu teacher welcome ti theshu training class"echo $chars | awk '&#123;for(i=1;i&lt;NF;i++) if(length($i)&lt;=6) print $i&#125;' 5.2. 范例2批量检查多个网站地址是否正常。要求如下： 使用Shell数组的方法实现，检测策略尽量模拟用户访问 每10秒进行一次全部检测，无法访问的输出报警 待检测的地址如下：1234http://blog.theshu1.comhttp://blog.theshu2.comhttp://blog.theshu3.comhttp://10.0.0.7 解体思路： 把URL定义成数组，形成函数 编写URL检查脚本函数，传入数组的元素，即URL 组合实现整个案例，编写main主函数（即执行函数），每隔10秒检查一次 下面的参考答案采用了Shell数组的方法，同时检测多个URL是否正常，并给出专业的展示效果：12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/bin/bash. /etc/init.d/functionscheck_count=0url_list=(http://blog.theshu1.com http://blog.theshu2.com http://blog.theshu3.com http://10.0.0.7)function wait()&#123; echo -n '3秒后，执行检查URL操作.'; for ((i=0; i&lt;3; i++)) do echo -n "."; sleep 1 done done echo&#125;function check_url()&#123; wait for ((i=0; i&lt;`echo $&#123;#url_list[*]&#125;`; i++)) do wget -o /dev/null -T 3 --tries=1 --spider $&#123;url_list[$i]&#125; &gt;/dev/null 2&gt;&amp;1 if [ $? -eq 0 ] then action "$&#123;url_list[$i]&#125;" /bin/true else action "$&#123;url_list[$i]&#125;" /bin/false fi done ((check_count++))&#125;main()&#123; while true do check_url echo "------------check count:$&#123;check_count&#125;----------" sleep 10 done&#125;main 提示：实际使用时，一些基础的函数脚本（例如：加颜色的函数）是放在函数文件里的（例如：放在/etc/init.d/functions里），与执行的脚本内容部分分离，这样看起来会更清爽，大型的语言程序都是这样开发的。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记12-循环控制及状态返回值]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F014.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012-%E5%BE%AA%E7%8E%AF%E6%8E%A7%E5%88%B6%E5%8F%8A%E7%8A%B6%E6%80%81%E8%BF%94%E5%9B%9E%E5%80%BC%2F</url>
    <content type="text"><![CDATA[GO 这一篇文章是关于break（循环控制）、continue（循环控制）、exit（退出脚本）、return（退出函数）的知识。 1. break、continue、exit、return的区别和对比break、continue在条件语句及循环语句（for、while、if等）中用于控制程序的走向；而exit则用于终止所有语句并退出当前脚本，除此之外，exit还可以返回上一次程序或命令的执行状态值给当前Shell；return类似于exit，只不过return仅用于在函数内部返回函数执行的状态值。关于这几个命令的基本说明见下表。 命令 说明 break n 如果省略n，则表示跳出整个循环，n表示跳出循环的层数 continue n 如果省略n，则表示跳过本次循环，忽略本次循环的剩余代码，进入循环的下一次循环。n表示退到第n层继续循环 exit n 退出当前Shell程序，n为上一次程序执行的状态返回值。n也可以省略，在下一个Shell里可以通过$?接受exit n的n值 return n 用于在函数里作为函数的返回值，以判断函数执行是否正确。在下一个Shell里可通过$?接收exit n的n值 2. break、continue、exit功能执行流程图以while循环和for循环为例来说明这几个控制语句的流程： 2.1. 在循环中break功能和执行流程逻辑图 2.2. 在循环中continue功能和执行流程逻辑图 2.3. 在循环中exit功能和执行流程逻辑图 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记11-for和select循环语句]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F013.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011-for%E5%92%8Cselect%E5%BE%AA%E7%8E%AF%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[GO for循环语句和while循环语句类似，但for循环语句主要用于执行次数有限的循环，而不是用于守护进程及无限循环。for循环语句常见的语法有两种，下面将在不同的语法中对for循环语句进行详尽的讲解。 1. for循环语法结构第一种for循环语句为变量取值型，语法结构如下：1234for 变量名 in 变量取值列表do 指令...done 提示：在此结构中，in 变量取值列表可以省略，省略时相当于in &quot;$@&quot;，特就是使用for i就相当于使用for i in &quot;$@&quot;。 在这种for循环语句语法中，for关键字后面会有一个变量名，变量名依次获取in关键字后面的变量取值列表内容（以空格分隔），每次仅取一个，然后进入循环（do和done之间的部分）执行循环内的所有指令，当执行到done时结束本次循环。之后，变量名再继续获取变量列表里的下一个变量值，继续执行循环内的所有指令，当执行到done时结束返回，以此类推，知道取完变量列表里的最后一个值并进入循环执行到done结束为止。 第二种for循环语句称为C语言型for循环语句，其语法结构如下：1234for ((exp1; exp2; exp3))do 指令...done 说明：此种循环语句和while循环语句类似，但语法结构比while循环更规范、工整。 for关键字后的双括号内是三个表达式，第一个是变量初始化（例如：i=0），第二个为变量的范围（例如：i&lt;100），第三个为变量自增或自减（例如：i++）。当第一个表达式的初始化值符合第二个变量的范围时，就进入循环执行；当条件不满足时就退出循环。 范例：for循环和while循环对比 for版 1234for ((i=1; i&lt;=3; i++))do echo $idone 转化为while版 123456i=1while ((i&lt;=3))do echo $i ((i++))done 特别说明： 如果希望程序持续运行，则多用while，包括守护进程。 如果是有限次循环，则多用for，实际工作中使用for的机会更多。 2. for循环语句的基础实践下面是几个for循环语句的示例： 范例1：竖向打印5、4、3、2、1这个5个数字 参考答案1：直接列出元素的方法： 1234for num in 5 4 3 2 1do echo $numdone 参考答案2：利用大括号{}生成数字序列的方法 1234for num in &#123;5..1&#125;do echo $numdone 参考答案3：采用seq生产数字序列的用法 1234for num in `seq 5 -1 1`do echo $numdone 范例2：获取当前目录下的目录或文件名，并将其作为变量列表打印输出 12345cd /testfor filename in `ls`do echo $filenamedone 范例3：用for循环批量修改文件扩展名（把txt改成jpg） 123456#!/bin/bashcd /testfor filename in `ls | grep "txt$"`do mv $filename `echo $filename | cut -d . -f1`.gifdone 本题还有更简单的实现方法，即通过rename命令来直接实现，如下：12cd /testrename "gif" "txt" *.gif 3. for循环语句的企业级案例范例1：在Linux下批量修改文件名，将文件中的_finished去掉。 提示：通过此题的解答可以学习到sed、awk、rename、mv等命令的实战应用 参考答案1：采用Shell脚本、for循环加sed的方法 123456#!/bin/shcd /theshufor file in `ls *.jpg`do mv $file `echo $file | sed 's/_finished//g'`done 参考答案2：使用ls结合awk实现，这个方法中没有for循环，但它可以在很多场景中替换for循环（下例是：给文件名加上”_finished”）：（注意是对文件名的修改，而不是字符串的修改） 1ls | awk -F "." '&#123;print "mv",$0,$1"_finished."$2&#125;' | bash 参考答案3：通过专业的改名命令rename来实现： 1rename "_finished" "" *.jpg 范例2：在生产环境下，批量去掉测试数据所用的bd字符： 实现命令如下：rename &quot;bd&quot; &quot;&quot; *.html 4. select循环语句介绍及语法打印菜单可以用cat方法（被称为here文档），其实还有另外一种实现菜单的方法，即通过select循环语句实现。 select循环语句的主要作用可能就是创建菜单，在执行带select循环语句的脚本时，输出会按照数字顺序的列表显示一个菜单项，并显示提示符（默认是#?），同时等待用户输入数字进行选择。一下就是关于select的知识。 第一种for循环语句为变量取值型，语法结构如下：1234select 变量名 [ in 菜单取值列表 ]do 指令...done 在这种select循环语句的语法中，在执行脚本后，select关键字后面会有一个变量名，变量名依次获取in关键字后面的变量取值列表内容（以空格分隔），每次仅取一个，然后进入循环（do和done之间），执行循环内的所有指令，当执行到done时结束返回，之后变量名再继续取变量列表里的下一个变量值，继续执行循环内的所有指令，当执行到done时结束为止。与for循环不同的是，select循环执行后会出现菜单项等待用户选择（不会自动循环所有变量列表），而用户输入的只能是菜单项前面的数字序号，每输入一次对应的序号就会执行一次循环，直到变量后面对应列表取完为止。 5. select循环语句案例范例：用select循环打印简单菜单项的多种实现方法 方法1：直接使用列表字符串 脚本开发 12345#!/bin/bash select name in theshu theshan wang do echo $name done 执行结果如下： 12345678910111213[root@theshu ~]# sh select1.sh1) theshu2) theshan3) thewang#? 1 theshu#? 2 theshan#? 3 thewang#? 4 #&lt;==输入错误则返回空#? 方法2：采用数组做变量列表 123456#!/bin/basharray=(theshu theshan thewang)select name in "$&#123;array[@]&#125;"do echo $namedone 方法3：把命令结果作为变量列表（菜单项） 数据准备 1234567[root@theshu ~]# mkdir -p /tmp/test[root@theshu ~]# mkdir -p /tmp/test/&#123;theshu,theshan,thewang&#125;[root@theshu ~]# ls -l /tmp/test/total 12drwxr-xr-x 2 root root 4096 Mar 1 10:29 theshandrwxr-xr-x 2 root root 4096 Mar 1 10:29 theshudrwxr-xr-x 2 root root 4096 Mar 1 10:29 thewang 脚本开发 12345#!/bin/bashselect name in `ls /tmp/test`do echo $namedone 执行结果 12341) theshan2) theshu3) thewang#? OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记10-while循环和until循环]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F012.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010-while%E5%BE%AA%E7%8E%AF%E5%92%8Cuntil%E5%BE%AA%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[GO 循环语句命令常用于重复执行一条指令或一组指令，直到条件不再满足时停止，Shell脚本语言的循环语句常见的有while、until、for及select循环语句。 while循环语句主要用来重复执行一组命令或语句，在企业实际应用中，常用于守护进程或持续运行的程序，除此之外，大多数循环都会用for循环语句。 1. 当型和直到型循环语法1.1. while循环语句while循环语句的基本语法为：1234while &lt;条件表达式&gt;do 指令...done 提示：注意代码缩进 while循环语句会对紧跟在while命令后的条件表达式进行判断，如果该条件表达式成立，则执行while循环体里的命令或语句（即语法中do和done之间的指令），每一次执行到done时就会重新判断while条件表达式是否成立，直到条件表达式不成立时才会跳出while循环体。如果一开始条件表达式就不成立，那么程序就不会进入循环体中执行命令了。 1.2. until循环语句until循环语句的语法为：1234until &lt;条件表达式&gt;do 指令...done until循环语句的用法与while循环语句的用法类似，区别是until会在条件表达式不成立时，进入循环执行指令；条件表达式成立时，终止循环。until的应用场景很罕见，所以了解即可，不必深究。 2. 当型和直到型循环的基本范例首先了解一下Shell中的两个休息命令： sleep 1表示休息1秒 usleep 1000000也表示休息1秒 下面是与while和until循环语句相关的示例。 范例1：每隔2秒输出一次系统负载情况 参考答案1：每隔2秒在屏幕上输出一次负载值 123456#!/bin/bashwhile truedo uptime sleep 2done 参考答案2：将负载值追加到log里，使用微秒单位 123456#!/bin/bashwhile [ 1 ]do uptime &gt;&gt; /tmp/uptime.log usleep 2000000done 通过在脚本的结尾使用&amp;符号来在后台运行脚本：filename.sh &amp;。 在实际工作中，一般会通过客户端SSH来连接服务器，因此可能就会有在脚本或命令执行期间不能终端的去求，若终端，则会前功尽弃，更要命的是会破坏系统数据。下面是防止脚本执行中断的几个可行方法： 使用sh filename.sh &amp;命令，即用&amp;在后台运行脚本 使用nohup filename.sh &amp;命令，即使用nohup加&amp;在后台运行脚本 利用screen保持会话，然后再执行命令或脚本，即使用screen保持当前会话状态。 3. 让Shell脚本在后台运行的知识有关脚本运行的相关用法和说明见下表 用法 说明 sh *.sh &amp; 把脚本放到后台执行（在后台运行脚本时常用的方法） Ctrl+c 停止执行当前脚本或任务 Ctrl+z 暂停执行当前脚本或任务 bg 把当前脚本或任务放到后台执行，bg可以理解为background fg 把当前脚本或任务放到前台执行，如果有多个任务，可以使用fg加任务编号调处对应的脚本任务，如fg 2，是指调处第二个脚本任务，fg可以理解为frontground jobs 查看当前执行到的脚本或任务 kill 关闭执行的脚本任务，即以kill %任务编号的形式关闭脚本，这个任务编号，可以通过jobs来获得 更多有关进程管理的Linux相关命令如下： kill、killall、pkill：杀掉进程 ps：查看进程 pstree：显示进程状态树 top：显示进程 renice：改变优先权 nohup：用户退出系统之后继续工作 pgrep：查找匹配条件的进程 strace：跟踪一个进程的系统调用情况 ltrace：跟踪进程调用库函数的情况 4. while循环按行读文件的方式总结下面是利用while循环来按行读文件的几种常见方式： 采用exec读取文件，然后进入while循环处理： 123456exec &lt;FILEsum=0while read linedo cmddone 使用cat读取文件内容，然后通过管道进入while循环处理： 1234cat FILE_PATH | while read linedo cmddone 在while循环结尾done处理过输入重定向指定读取的文件： 1234while read linedo cmddone&lt;FILE 范例：开发一个Shell脚本实现Linux系统命令cat读文件的基本功能。参考答案如下：1234while read linedo echo $linedone &lt; $1 5. 小结5.1. while循环结构及相关语句综合实践小结 while循环的特长是执行守护进程，以及实现我们希望循环持续执行不退出的应用，适合用于频率小于1分钟的循环处理，其它的while循环几乎都可以被for循环及定时任务crond功能所替代。 case语句可以用if语句来替换，而在系统启动脚本时传入少量固定规则字符串的情况下，多用case语句，其他普通判断多用if语句。 一句话场景下，if语句、for语句最常用，其次是while（守护进程）、case（服务启动脚本）。 5.2. Shell脚本中各个语句的使用场景 条件表达式，用于简短的条件判断及输出（文件是否存在，字符串是否为空等） if取值判断，多用于不同值数量较少的情况 for最常用于正常的循环处理中 while多用于守护进程、无限循环（要加sleep和usleep控制频率）场景 case多用于服务启动脚本中，打印菜单可用select语句，不过很少见，一般用cat的here文档方法来替代。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记09-case条件语句的应用]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F011.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B009-case%E6%9D%A1%E4%BB%B6%E8%AF%AD%E5%8F%A5%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[GO case条件语句相当于多分支的if/elif/else条件语句，但是它比这些条件语句看起来更规范更公正，常被应用于实现系统服务启动脚本等企业应用场景中。 在case语句中，程序会将case获取的变量的值与表达式部分的值1、值2、值3等逐个进行比较，如果获取的变量值和某个值（例如值1）相匹配，就会执行值（例如值1）后面对应的指令（例如指令1，其可能是一组指令），直到执行到双分号（;;）才会停止，然后再跳出case语句主体，执行case语句（即esac字符）后面的其他命令。 如果没有找到匹配变量的任何值，则执行*)后面的指令（通常是给使用者的使用提示），直到遇到双分号（;;）（此处的双分号可以省略）或esac结束，这部分相当于if多分支语句中最后的else语句部分。另外，case语句中表达式对应值的部分，还可以使用管道等更多功能来匹配。 1. case条件语句的语法case条件语句的语法格式为：1234567891011case "变量名" in 值1) 指令1... ;; 值2) 指令2... ;; ... *) 指令3...esac 说明：当变量的值等于值1时，执行指令1；等于值2时执行指令2，以此类推；如果都不符合，则执行*)后面的指令，即指令3。此外，注意不同行内容的缩进距离。 2. case条件语句实践范例1：根据用户的输入判断用户输入的是哪个数字 如果用户输入的是1-9的任意数字，则输出对应输入的数字；如果是其它数字及字符，则返回输入不正确的提示并退出程序。 参考答案1：使用case语句实现： 12345678910111213141516#!/bin/bashread -p "Plaease input a number:" anscase "$ans" in 1) echo "The num you input is 1" ;; 2) echo "The num you input is 2" ;; [3-9]) #&lt;==如果用户输入的信息为3-9中的任意数字，注意范围匹配的正则写法，则执行下面的echo输出 echo "The num you input is $ans" ;; *) #&lt;==如果不匹配上面任何一个值，则执行下面的echo输出 echo "Please input [0-9] int" exit;esac #&lt;==esac语句结束前的最后一个值匹配，可以省略双分号 参考答案2：使用if语句实现 123456789101112#!/bin/bashread -p "Please input a number:" ansif [ $ans -eq 1 ];then echo "the num you input is 1"elif [ $ans -eq 2 ];then echo "the num you input is 2"elif [ $ans -ge 3 -a $ans -le 9 ];then echo "the num you input is $ans"else echo "the num you input must be [1-9]" exitfi 对比case语句和if语句，会发现case语句更简洁更规范，if语句看起来则要更复杂一些。 3. 实践：给输出的字符串加颜色3.1. 给输出的字符串加颜色的基础知识Linux命令行中给字体加颜色的命令为： echo -e &quot;\E[1;31m红色字theshu\E[0m&quot; echo -e &quot;\033[31m红色字theshu\033[0m&quot; 在上述命令中： echo -e可以识别转义字符，这里将识别特殊字符的含义，并输出 \E可以使用\033替代 [1数字1表示加粗显示（可以加不同的数字，以代表不同的意思，详细信息可用man console_codes获得） 31m表示为红色字体，可以换成不通的数字，以代表不同的意思 红色字theshu代表待设置的内容 [0m表示关闭所有属性，可以换成不同的数字，以代表不同的意思 有关ANSI控制码的说明如下： \33[0m表示关闭所有属性 \33[1m表示设置高亮度 \33[4m表示下划线 \33[5m表示闪烁 \33[7m表示反显 \33[8m表示消隐 \33[30m–\33[37m表示设置前景色 \33[40m–\33[47m表示设置背景色 console codes的更多知识可以参考man console_codes，普通读者了解即可。 在Linux脚本中，可以通过echo的-e参数，结合特殊的数字给不同的字符加上颜色并显示。 范例：给内容加上不同的颜色 内容的颜色可用数字表示，范围为30~37，每个数字代表一种颜色。代码如下：12345678echo -e "\033[30m 黑色字 theshu trainning \033[0m" #&lt;==30m表示黑色字echo -e "\033[31m 红色字 theshu trainning \033[0m" #&lt;==31m表示红色字echo -e "\033[32m 绿色字 theshu trainning \033[0m" #&lt;==32m表示绿色字echo -e "\033[33m 棕色字 theshu trainning \033[0m" #&lt;==33m表示棕色字echo -e "\033[34m 蓝色字 theshu trainning \033[0m" #&lt;==34m表示蓝色字echo -e "\033[35m 洋红色字 theshu trainning \033[0m" #&lt;==35m表示洋红色字echo -e "\033[36m 蓝绿色字 theshu trainning \033[0m" #&lt;==36m表示蓝绿色字echo -e "\033[37m 白色字 theshu trainning \033[0m" #&lt;==37m表示白色字 说明：不同的数字对应不同的字体颜色，详情参见系统帮助（man console_codes） 范例：通过定义变量的方式给字体加颜色（推荐使用的方式）123456789101112#!/bin/bashRED_COLOR='\E[1;31m'GREEN_COLOR='\E[1;32m'YELLOW_COLOR='\E1;33m'BLUE_COLOR='\E[1;34m'PINK='\E[1;35m'RES='\E[0m'echo -e "$&#123;RED_COLOR&#125;====red color====$&#123;RES&#125;"echo -e "$&#123;YELLOW_COLOR&#125;====yellow color====$&#123;RES&#125;"echo -e "$&#123;BLUE_COLOR&#125;====blue color====$&#123;RES&#125;"echo -e "$&#123;GREEM_COLOR&#125;====green color====$&#123;RES&#125;"echo -e "$&#123;PINK&#125;====pink color====$&#123;RES&#125;" 3.2. 结合case语句给输出的字符串加颜色请开发一个给指定内容加指定颜色的脚本。 要求：使用case语句及通过脚本传入指定内容和指定颜色，在脚本命令行传2个参数，给指定的内容（第一个参数）加指定的颜色（第二个参数）。 实现脚本如下： 1234567891011121314151617181920212223242526272829303132#!/bin/bashRED_COLOR='\E[1;31m'GREEN_COLOR='\E[1;32m'YELLOW_COLOR='\E[1;33m'BLUE_COLOR='\E[1;34m'PINK_COLOR='\E[1;35m'RES='\E[0m'#&lt;==以上部分将颜色字符定义为变量，方便后续使用if [ $# -ne 2 ];then echo "Usage $0 content &#123;red|yellow|blue|green|pink&#125;" exitficase "$2" in red|RED) echo -e "$&#123;RED_COLOR&#125;$1$&#123;RES&#125;" ;; yellow|YELLOW) echo -e "$&#123;YELLOW_COLOR&#125;$1$&#123;RES&#125;" ;; green|GREEN) echo -e "$&#123;GREEN_COLOR&#125;$1$&#123;RES&#125;" ;; blue|BLUE) echo -e "$&#123;BLUE_COLOR&#125;$1$&#123;RES&#125;" ;; pink|PINK) echo -e "$&#123;PINK_COLOR&#125;$1$&#123;RES&#125;" ;; *) echo "Usage $0 content &#123;red|yellow|blue|green|pink&#125;" exitesac 如果脚本中要加颜色的内容很多，还可以专门写一个给内容加颜色的函数，如下： 12345678910111213141516171819202122232425262728293031323334353637#!/bin/bashplus_color()&#123; RED_COLOR='\E[1;31m' GREEN_COLOR='\E[1;32m' YELLOW_COLOR='\E[1;33m' BLUE_COLOR='\E[1;34m' PINK_COLOR='\E[1;35m' RES='\E[0m' if [ $# -ne 2 ];then echo "Usage $0 content &#123;red|yellow|blue|green|pink&#125;" exit fi case "$2" in red|RED) echo -e "$&#123;RED_COLOR&#125;$1$&#123;RES&#125;" ;; yellow|YELLOW) echo -e "$&#123;YELLOW_COLOR&#125;$1$&#123;RES&#125;" ;; green|GREEN) echo -e "$&#123;GREEN_COLOR&#125;$1$&#123;RES&#125;" ;; blue|BLUE) echo -e "$&#123;BLUE_COLOR&#125;$1$&#123;RES&#125;" ;; pink|PINK) echo -e "$&#123;PINK_COLOR&#125;$1$&#123;RES&#125;" ;; *) echo "Usage $0 content &#123;red|yellow|blue|green|pink&#125;" exit esac&#125;plus_color "I" redplus_color "am" greenplus_color "theshu" blue 本题更专业更规范的实现脚本如下，此脚本为全函数模块化、标准化、专业化的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142#!/bin/bash#&lt;==定义加颜色函数addColorfunction addColor()&#123; RED_COLOR='\E[1;31m' GREEN_COLOR='\E[1;32m' YELLOW_COLOR='\E[1;33m' BLUE_COLOR='\E[1;34m' PINK_COLOR='\E[1;35m' RES='\E[0m' if [ $# -ne 2 ];then echo "Usage $0 content &#123;red|yellow|blue|green|pink&#125;" exit fi case "$2" in red|RED) echo -e "$&#123;RED_COLOR&#125;$1$&#123;RES&#125;" ;; yellow|YELLOW) echo -e "$&#123;YELLOW_COLOR&#125;$1$&#123;RES&#125;" ;; green|GREEN) echo -e "$&#123;GREEN_COLOR&#125;$1$&#123;RES&#125;" ;; blue|BLUE) echo -e "$&#123;BLUE_COLOR&#125;$1$&#123;RES&#125;" ;; pink|PINK) echo -e "$&#123;PINK_COLOR&#125;$1$&#123;RES&#125;" ;; *) echo "Usage $0 content &#123;red|yellow|blue|green|pink&#125;" exit esac&#125;#&lt;==定义主函数mainfunction main()&#123; addColor $1 $2&#125;#&lt;==执行主函数main $* 3.3. 给输出的字符串加背景颜色给输出的字符串加不同的背景颜色。字的背景颜色对应的数字的范围为40~47，代码如下：12345678echo -e "\033[40;37m 黑底白字 theshu \033[0m" #&lt;==40m表示黑色背景echo -e "\033[41;37m 红底白字 theshu \033[0m" #&lt;==41m表示红色背景echo -e "\033[42;37m 绿底白字 theshu \033[0m" #&lt;==42m表示绿色背景echo -e "\033[43;37m 棕底白字 theshu \033[0m" #&lt;==43m表示棕色背景，和黄色背景相近echo -e "\033[44;37m 蓝底白字 theshu \033[0m" #&lt;==44m表示蓝色背景echo -e "\033[45;37m 洋红底白字 theshu \033[0m" #&lt;==45m表示洋红色背景，和紫色背景相近echo -e "\033[46;37m 蓝绿底白字 theshu \033[0m" #&lt;==46m表示蓝绿色色背景，和浅蓝色背景相近echo -e "\033[47;30m 白底黑字 theshu \033[0m" #&lt;==47m表示白色背景 说明：不同的数字所对应的背景字体颜色见系统帮助（man console_codes） 4. 总结 case语句和if条件语句的适用性 case语句比较适合变量值较少且为固定的数字或字符串集合的情况，如果变量的值是已知固定的start|stop|restart等元素，那么采用case语句来实现就比较合适。 case语句和if语句的常见应用场景 case主要是写服务的启动脚本，一般情况下，传参不同且具有少量的字符串，其适用范围较窄。 if就是取值判断、比较，应用面比case更广。几乎所有的case语句都可以用if条件语句来实现。 case语句的特点及优势 case语句就相当于多分支的if/elif/else语句，但是case语句的优势是更规范、易读。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记08-Shell函数的知识]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F010.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B008-Shell%E5%87%BD%E6%95%B0%E7%9A%84%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[GO 1. Shell函数的概念与作用介绍简单地说，函数的作用就是将程序里多次被调用的相同代码组合起来（函数体），并为其取一个名字（即函数名），其它所有想重复调用这部分代码的地方都只需要调用这个名字就可以了。当需要修改这部分重复代码时，只需要改变函数体内的一份代码即可实现对所有调用的修改，也可以把函数独立地写到文件里，当需要调用函数时，再加载进来使用。 使用Shell函数的优势整理如下： 把相同的程序段定义成函数，可以减少整个程序的代码量，提升管理效率 增加程序的可读性、易读性，提升管理效率 可以实现程序功能模块化，使得程序具备通用性（可移植性） 对于Shell来说，Linux系统里的近2000个命令可以说都是Shell的函数，所以Shell的函数也是很多的，这一点需要注意一下。 2. Shell函数的语法下面是Shell函数的常见语法格式： 标准写法为： 1234function 函数名()&#123; #&lt;==推荐的书写函数的方法（带括号） 指令... return n&#125; 简化写法1：在Shell函数的语法中，当有function时，函数名后面的小括号()部分可以省略不写 1234function 函数名&#123; #&lt;==不推荐使用此方法（无括号） 指令... return n&#125; 简化写法2：在Shell函数的语法中，function表示生命一个函数，这部分可以省略不写 1234函数名()&#123; #&lt;==不用function的方法 指令... return n&#125; 3. Shell函数的执行Shell的函数分为最基本的函数和可传参的函数两种，其执行方式分别说明如下： 3.1. 基本函数的执行执行不带参数的基本函数时，直接输入函数名即可（注意不带小括号）。格式如下：1函数名 有关执行函数的重要说明； 执行Shell函数时，函数名前的function和函数后的小括号都不要带 函数的定义必须在执行的程序前面定义或加载 Shell执行系统中各种程序的执行顺序为：系统别名-函数-系统命令-可执行文件 函数执行时，会和调用它的脚本共用变量，也可以为函数设定局部变量及特殊位置参数 在Shell函数里面，return命令的功能与exit类似，return的作用是退出函数，而exit是退出脚本文件 return语句会返回一个退出值（即返回值）给调用函数的当前程序，而exit会返回一个退出值（即返回值）给执行程序的当前Shell 如果将函数存放在独立的文件中，被脚本加载使用，需要使用source或.来加载 在函数内一般使用local定义局部变量，这些变量离开函数后就会消失 3.2. 带参数函数的执行带参数的函数执行方法，格式如下：1函数名 参数1 参数2 ... 函数后接参数的说明： Shell的位置参数（$1、$2…、$#、$*、%$?及$@）都可以作为函数的参数来使用 此时父脚本的参数临时地被函数参数所掩盖或隐藏 $0比较特殊，它仍然是父脚本的名称 当函数执行完成时，原来的命令行脚本的参数即可恢复 函数的参数变量是在函数体里面定义的 4. Shell函数的基础实践4.1. 范例1开发脚本建立两个简单函数并调用执行12345678910111213#!/bin/bash#定义两个函数，名字为shu和shanshu()&#123; echo "I am shu."&#125;function shan()&#123; echo "I am shan."&#125;shushan 4.2. 范例2分离函数体和执行函数的脚本文件（更规范的方法） 首先建立函数库脚本（默认不会执行函数） 使用cat命令追加多行文本，以将函数代码追加到系统的函数文件中，即/etc/init.d/functions，命令如下： 123456cat &gt;&gt; /etc/init.d/dunctions&lt;&lt;- EOF &lt;==here文档的另一种写法，此写法允许后面的EOF可以使用Tab键，而不顶格theshu()&#123; echo "I am theshu."&#125;EOF #&lt;==就是这里的EOF可以使用Tab键，而不顶个，但不能使用空格 然后开发执行脚本以调用上述函数： 123456#!/bin/bash# 加载函数所在文件（functions是Linux系统内置的脚本函数库）[ -f /etc/init.d/functions ] &amp;&amp; . /etc/init.d/functions || exit 1# 提示：可以用source或.（点号）来加载脚本functions中的命令或变量参数等# 调用函数theshu 4.3. 范例3写出带参数的Shell函数示例，这里通过建立函数theshu来做示例讲解。将函数的传参转换成脚本文件命令行传参，代码如下：123456789# &lt;==functions函数库文件里的函数定义内容theshu()&#123; echo "I am theshu. You are $1"&#125;#&lt;==脚本内容#!/bin/bash[ -f /etc/init.d/functions ] &amp;&amp; . /etc/init.d/functions || exit 1theshu theshan #&lt;==将theshan作为参数传给theshu函数 Shell中使用函数的编程思想 学习了函数以后应尽量将脚本功能模块化，每个模块实现一个功能，并让脚本可以通用。 当一个脚本实现了高度模块化，即用函数1、函数2、…、main函数、main $*传参，并能对其调用执行，这样的脚本的不但专业规范，而且看上去也很高大上，这些很值得花功夫去研究、学习和掌握。 实际使用时，一些基础的函数脚本（例如：加颜色的函数）是放在函数文件里的，例如放在/etc/init.d/functions里，与执行的内容部分相分离，这看起来更清爽，大型的语言程序都是这样开发的。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记07-if条件语句的知识]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F009.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B007-if%E6%9D%A1%E4%BB%B6%E8%AF%AD%E5%8F%A5%E7%9A%84%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[GO 对于if条件语句，简单的说，其语义类似于汉语里的如果……那么……。if条件语句是Linux运维人员在实际生产工作中使用得最频繁也是最重要的语句，因此，请务必重视if条件语句的知识，并牢固掌握。 1. if条件语句的语法1.1. 单分支结构if条件语句的单分支结构主题就是如果……，那么…… 第一种语法：1234if &lt;条件表达式&gt;then 指令fi 第二种语法：123if &lt;条件表达式&gt;; then 指令fi 在这里： &lt;条件表达式&gt;可以是test、[]、[[]]、(())等条件表达式，甚至可以直接使用命令作为条件表达式。 条件语句可以嵌套，即if语句里面还有if语句。弹药注意每个if条件语句中都要有一个与之对应的fi，每个if和它下面最近的fi成对搭配，语法示例如下： 1234567if &lt;条件表达式&gt;then if &lt;条件表达式&gt; then 指令 fifi 通常在书写Shell条件语句编程时，要让成对的条件语句关键字的缩进相对应，以便于阅读浏览。 文件条件表达式[ -f &quot;$file1&quot; ] &amp;&amp; echo 1就等价于下面的if条件语句：123if [ -f "$file1" ] ; then echo 1fi 1.2. 双分支结构if条件语句的双分支结构主题则为如果……，那么……，否则…… 语法如下：123456if &lt;条件表达式&gt;then 指令集1else 指令集2fi 在这里： 也可以把then和if放在一行用分号;隔开 文件测试条件表达式[ -f &quot;$file1&quot; ] &amp;&amp; echo 1 || echo 0 就相当于下面的双分支的if条件语句：123456if [ -f "$file1" ]then echo 1else echo 0fi 1.3. 多分支结构if条件语句多分支结构的主题为：如果……，那么……，否则如果……，那么……，否则如果……，那么……，…… 否则…… 语法为：12345678910111213141516171819202122if &lt;条件表达式1&gt;then 指令1elif &lt;条件表达式2&gt;then 指令2fi------多个elif------if &lt;条件表达式1&gt;then 指令1elif &lt;条件表达式2&gt;then 指令2elif &lt;条件表达式3&gt;then 指令3 ......else 指令nfi 在这里： 注意多分支elif的写法，每个elif都要带有then 最后结尾的else后面没有then 2. if条件语句多种条件表达式语法if条件语句（包括多分支if）的&lt;条件表达式&gt;部分可以是test、[]、[[]]、(())等条件表达式，甚至还可以直接使用命令作为条件表达式，具体的语法如下： test条件表达式 1234if test 表达式then 指令fi []条件表达式 1234if [ 字符串或算术表达式 ]then 指令fi [[]]条件测试表达式 1234if [[ 字符串表达式 ]]then 指令fi (())条件表达式 1234if ((算术表达式))then 指令fi 命令表达式 1234if 命令then 指令if 提示：以上表达式除了语法不通之外，具体的应用是一致的，实际工作场景中，只需选择一种适合自己习惯的表达式就好。 3. 单分支if条件语句实践把下面测试文件中条件表达式的语句改成if条件语句： 1、[ -f /etc/hosts ] &amp;&amp; echo &quot;[1]&quot; 2、[[ -f /etc/hosts ]] &amp;&amp; echo &quot;[[1]]&quot; 3、test -f /etc/hosts &amp;&amp; echo &quot;test1&quot;参考答案如下：1234567891011121314151617# 1的答案if [ -f /etc/hosts ]then echo "[1]"fi# 2的答案if [[ -f /etc/hosts ]]then echo "[[1]]"fi# 3的答案if test -f /etc/hoststhen echo "test1"fi OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记06-Shell脚本的条件测试与比较]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F008.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B006-Shell%E8%84%9A%E6%9C%AC%E7%9A%84%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95%E4%B8%8E%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[GO 1. Shell脚本的条件测试1.1. 条件测试方法综述通常，在bash的各种条件结构和流程控制结构中都要进行各种测试，然后根据测试结果执行不同的操作，有时也会与if等条件语句相结合，来完成测试判断，以减少程序运行的错误。 执行条件测试表达式后通常会返回真或假，就像执行命令后的返回值为0表示真，非0表示假一样。 在bash编程里，条件测试常用的语法形式见下表： 条件测试语法 说明 语法1：test &lt;测试表达式&gt; 这是利用test命令进行条件测试表达式的方法。test命令和&lt;测试表达式&gt;之间至少有一个空格 语法2：[&lt;测试表达式&gt;] 这是通过[]（单中括号）进行条件测试表达式的方法，和test命令的用法相同，这是推荐使用的方法。[]的边界和内容之间至少有一个空格 语法3：[[&lt;测试表达式&gt;]] 这是通过[[]]（双中括号）进行条件测试表达式的方法，是比test和[]更新的语法格式。[[]]的边界和内容之间至少有一个空格 语法4：((&lt;测试表达式&gt;)) 这是通过(())（双小括号）进行条件测试表达式的方法，一般用于if语句里。(())（双小括号）两端不需要有空格。 上表中有几个注意事项需要说明一下： 语法1中的test命令和语法2中的[]是等价的。语法3中的[[]]为扩展的test命令，语法4中的(())常用于计算。建议以后使用相对友好的语法2，即中括号[]的语法格式。 在[[]]（双中括号）中可以使用通配符等进行模式匹配，这是其区别于其他几种语法格式的地方。 &amp;&amp;、||、&gt;、&lt;等操作符可以应用于[[]]中，但不能应用于[]中，在[]中一般用-a、-o、-gt（用于整数）、-lt（用于整数）代替上述操作符。 对于整数的关系运算，也可以使用Shell的算术运算符(())。 1.2. test条件测试的简单语法及示例test条件测试的语法格式：test &lt;测试表达式&gt; 对于如下语句：test -f file &amp;&amp; echo true || echo false。该语句表示如果file文件存在，则输出true，否则（||）输出false。这里的&amp;&amp;是并且的意思。test的-f参数用于测试文件是否为普通文件，test命令若执行成功（为真），则执行&amp;&amp;后面的，命令，而||后面的命令是test命令执行失败之后（为假）所执行的命令。 test命令测试表达式的逻辑也可以用上述表达式的一般逻辑（即仅有一个&amp;&amp;或||）来测试，示例如下：12test -f filename &amp;&amp; echo 1 #&lt;==若表达式成功，则输出1test -f filename || echo 0 #&lt;==若表达式不成功，则输出0 另外，逻辑操作符&amp;&amp;和||的两端既可以有空格，也可以无空格，这就要看个人的编程习惯了。 范例：在test命令中使用-f选项（文件存在且为普通文件则表达式成立）测试文件：12345[root@theshu ~]# test -f file &amp;&amp; echo true || echo falsefalse[root@theshu ~]# touch file[root@theshu ~]# test -f file &amp;&amp; echo true || echo falsetrue 范例：在test命令中使用-z选项（如果测试字符串的长度为0，则表达式成立）测试字符串：12345678[root@theshu ~]# test -z "theshu" &amp;&amp; echo 1 || echo 00[root@theshu ~]# char="theshu"[root@theshu ~]# test -z "$char" &amp;&amp; echo 1 || echo 00[root@theshu ~]# char=""[root@theshu ~]# test -z "$char" &amp;&amp; echo 1 || echo 01 提示：关于test测试表达式的更多知识可执行man test查看帮助，但大部分场景都会使用[]的语法替代test命令的语法。 结论：test命令测试的功能很强大，但是和[]、[[]]的功能有所重合，因此，在实际工作中选择一种适合自己的语法就好了。对于其它的语法，能读懂别人写的脚本就可以了。 1.3. []（中括号）条件测试语法及示例[]条件测试的语法格式为：[ &lt;测试表达式&gt; ] 注意：中括号内部的两端要有空格，[]和test等价，即test的所有判断选择都可以直接在[]里使用。 对于如下语句：[ -f /tmp/theshu.txt ] &amp;&amp; echo 1 || echo 0。如果/tmp/theshu.txt文件存在，则输出1，否则（||）输出0.这里的&amp;&amp;表示并且。[]的应用同test命令，若中括号里的命令执行成功（返回真），则执行&amp;&amp;后面的命令，否则执行||后面的命令。 []测试表达式的逻辑也可以用如下的语法来判断逻辑的表达式写法（test命令的用法也适合于此），即：12[ -f /tmp/theshu.txt ] &amp;&amp; echo 1 #&lt;==若表达式成功，则输出1[ -f /tmp/theshu.txt ] || echo 0 #&lt;==若表达式不成功，则输出0 另外，逻辑操作符&amp;&amp;和||的两端可以有空格也可以无空格。 示例：利用[]加-f选项（文件存在且为普通文件则表达式成立）测试文件：123456789[root@theshu ~]# [ -f /tmp/theshu.txt ] &amp;&amp; echo 1 || echo 00[root@theshu ~]# touch /tmp/theshu.txt[root@theshu ~]# [ -f /tmp/theshu.txt ] &amp;&amp; echo 1 || echo 01[root@theshu ~]# [ -f /tmp/theshu.txt ] &amp;&amp; echo 11[root@theshu ~]# [ -f /tmp/theshu1.txt ] || echo 00 提示：[]命令的选项和test命令的选项是通用的，因此，使用[]时的参数选项可以通过man test命令获取帮助。 1.4. [[]] 条件测试语法及示例[[]]条件测试的语法格式为：[[ &lt;测试表达式&gt; ]]。注意：双括号里的两端也要有空格。 对于如下语句：[[ -f /tmp/theshu.txt ]] &amp;&amp; echo 1 || echo 0。如果/tmp/theshu.txt文件存在就输出1，否则（||）就输出0.这里的&amp;&amp;表示并且。[[]]的应用属于[]和test命令的扩展命令，功能更丰富也更复杂。如果双括号里的表达式成立（为真），则执行&amp;&amp;后面的名利个，否则执行||后面的命令。 [[]]测试表达式的逻辑也可以使用如下的部分逻辑形式，即：12[[ -f /tmp/theshu.txt ]] &amp;&amp; echo 0 #&lt;==若表达式成功则输出1[[ -f /tmp/theshu.txt ]] || echo 1 #&lt;==若表达式不成功则输出0 另外，逻辑操作符&amp;&amp;和||的两端可以有空格也可以无空格。 双中括号内部的两端要有空格，[[]]里的测试判断选项，也可以通过man test来获得，[[]]表达式与[]和test用法的选项部分是相同的，其与[]和test测试表达式的区别在于，在[[]]中可以使用通配符等进行模式匹配；并且&amp;&amp;、||、&gt;、&lt;等操作符可以用用[[]]中，但不能应用于[]中，在[]中一般使用-a、-o、-gt（用于整数）、-lt（用于整数）等操作符代替上文提到的用于[[]]``中的符号。除了使用通配符功能之外，建议放弃这个双括号的写法，虽然它是较新的test`命令的语法格式。 范例：[[]]的使用示例：1234[root@theshu ~]# [[ -f /tmp/theshu.txt ]] || echo 00[root@theshu ~]# touch /tmp/theshu.txt[root@theshu ~]# [[ -f /tmp/theshu.txt ]] || echo 0 有关test、[]、[[]]这些操作符的用法，通过help test或man test查询即可得到帮助，完整的[]、[[]]用法可通过man bash来获取。 2. 文件测试表达式2.1. 文件测试表达式的用法在书写文件测试表达式时，通常可以使用下表中的文件测试操作符： 常用文件测试操作符 说明 -d 文件，d为directory 文件存在且为目录则为真，即测试表达式成立 -f 文件，f为file 文件存在且为普通文件则为真，即测试表达式成立 -e 文件，e为exist 文件存在则为真，即测试表达式成立。注意区别与-f，-e不辨别是目录还是文件 -r 文件，r为read 文件存在且可读则为真，即测试表达式成立 -s 文件，s为size 文件存在且文件大小不为0则为真，即测试表达式成立 -w 文件，w为write 文件存在且可写则为真，即测试表达式成立 -x 文件，x为executable 文件存在且可执行则为真，即测试表达式成立 -L 文件，L为link 文件存在且为链接文件则为真，即测试表达式成立 f1 -nt f2，nt为newer than 文件f1比文件f2新则为真，即测试表达式成立。根据文件的修改时间来计算 f1 -ot f2，or为older than 文件f1比文件f2旧则为真，即测试表达式成立。根据文件的修改时间来计算 上表列出的是企业里比较常用的操作符，这些操作符对于[[]]、[]、test的测试表达式几乎是通用的，更多的操作符可通过man test获得帮助。 2.2. 文件测试表达式举例2.2.1. 普通文件测试表达式示例 普通文件（测试文件类型） 12345[root@theshu ~]# touch theshu[root@theshu ~]# ls -l theshu-rw-r--r-- 1 root root 0 Feb 27 11:43 theshu[root@theshu ~]# [ -f theshu ] &amp;&amp; echo 1 || echo 01 目录文件（测试文件类型） 12345678910[root@theshu ~]# touch theshu[root@theshu ~]# mkdir test[root@theshu ~]# [ -f test ] &amp;&amp; echo 1 || echo 00[root@theshu ~]# [ -e test ] &amp;&amp; echo 1 || echo 01[root@theshu ~]# [ -d test ] &amp;&amp; echo 1 || echo 01[root@theshu ~]# [ -d teshu ] &amp;&amp; echo 1 || echo 00 2.2.2. 测试文件属性示例 范例：文件属性条件表达式测试实践：12345678910111213141516171819202122[root@theshu ~]# ll theshu-rw-r--r-- 1 root root 0 Feb 27 11:43 theshu #&lt;==文件权限默认为644[root@theshu ~]# [ -r theshu ] &amp;&amp; echo 1 || echo 01 #&lt;==测试theshu是否可读[root@theshu ~]# [ -w theshu ] &amp;&amp; echo 1 || echo 01 #&lt;==测试theshu是否可写[root@theshu ~]# [ -x theshu ] &amp;&amp; echo 1 || echo 00 #&lt;==测试theshu是否可执行，输出为0，因为用户权限为没有x[root@theshu ~]# chmod 001 theshu #&lt;==修改theshu的权限位为001[root@theshu ~]# ll theshu---------x 1 root root 0 Feb 27 11:43 theshu #&lt;==修改后的结果[root@theshu ~]# [ -w theshu ] &amp;&amp; echo 1 || echo 01 #&lt;==用户权限位命名没有w，为什么还是返回1呢？[root@theshu ~]# echo 'echo test' &gt; theshu #&lt;==因为确实是可以写，这是root用户比较特殊的地方[root@theshu ~]# [ -r theshu ] &amp;&amp; echo 1 || echo 01 #&lt;==用户权限位明明没有r，为什么还是返回1呢？[root@theshu ~]# cat theshuecho test #&lt;==确实是可以读，这是root用户比较特殊的地方[root@theshu ~]# [ -x theshu ] &amp;&amp; echo 1 || echo 01[root@theshu ~]# ./theshu #&lt;==可执行test 提示：测试文件的读、写、执行等属性，不光是根据文件属性rwx的标识来判断，还要看当前执行测试的用户是否真的可以按照对应的权限操作该文件。 2.2.3. 测试Shell变量示例 首先定义file1和file2两个变量，并分别赋予这两个变量对应的系统文件路径及文件名的值，如下： 123[root@theshu ~]# file1=/etc/services ; file2=/etc/rc.local[root@theshu ~]# echo $file1 $file2/etc/services /etc/rc.local 范例：对单个文件变量进行测试： 12345678[root@theshu ~]# [ -f "$file1" ] &amp;&amp; echo 1 || echo 01 #&lt;==文件存在且为普通文件，所以为真（1）[root@theshu ~]# [ -d "$file2" ] &amp;&amp; echo 1 || echo 00 #&lt;==是文件而不是目录，所以为假（0）[root@theshu ~]# [ -s "$file1" ] &amp;&amp; echo 1 || echo 01 #&lt;==文件存在且大小不为0，所有为真（1）[root@theshu ~]# [ -e "$file1" ] &amp;&amp; echo 1 || echo 01 #&lt;==文件存在，所以为真（1） 范例：对单个目录或文件进行测试： 12345678[root@theshu ~]# [ -e /etc ] &amp;&amp; echo 1 || echo 01[root@theshu ~]# [ -w /etc/services ] &amp;&amp; echo 1 || echo 01[root@theshu ~]# su - theshu #&lt;==切换到普通用户Last login: Tue Feb 27 10:35:07 CST 2018 from 221.199.162.130 on pts/0[theshu@theshu ~]$ [ -w /etc/services ] &amp;&amp; echo 1 || echo 00 #&lt;==文件不可写，所以返回0 测试时变量的特殊写法级问题 用[]测试变量时，如果被测试的变量不加双引号，那么测试结果可能会是不正确的，示例如下： 123456[root@theshu ~]# echo $theshu #&lt;==假设theshu变量没有被定义[root@theshu ~]# [ -f $theshu ] &amp;&amp; echo 1 || echo 01 #&lt;==不加引号测试变量，逻辑结果错误[root@theshu ~]# [ -f "$theshu" ] &amp;&amp; echo 1 || echo 00 #&lt;==加引号后测试变量，结果正确 如果是文件实体路径，那么加引号与不加引号的结果是一样的： 1234[root@theshu ~]# [ -f "/etc/services" ] &amp;&amp; echo 1 || echo 01 #&lt;==加引号测试，结果正确[root@theshu ~]# [ -f /etc/services ] &amp;&amp; echo 1 || echo 01 #&lt;==不加引号测试，结果也正确 范例：在生产环境下，系统NFS启动脚本（/etc/init.d/nfs）的条件测试： 12345# Source networking configuration.[ -f /etc/sysconfig/network ] &amp;&amp; . /etc/sysconfig/network# Check for and source configuration file otherwise set defaults[ -f /etc/sysconfig/nfs ] &amp;&amp; . /etc/sysconfig/nfs 特别提示：系统脚本是我们学习编程的第一标杆，新手要多多参考脚本来学习，虽然有些脚本也不是特别规范。 范例：实现系统bind启动脚本named（bind DNS服务）：1234[ -r /etc/sysconfig/network ] &amp;&amp; . /etc/sysconfig/network#&lt;==若文件存在且可读，则加载/etc/sysconfig/network[ -x /usr/sbin/$named ] || exit 5 #&lt;==如果/usr/sbin/$named不可执行，则退出 特别提示：前面所将的都是[ -f /etc ] &amp;&amp; echo 1 || echo 0的用法，bind启动脚本[ -x /usr/sbin/$named ] || exit 5的用法更值得注意，这里只用了一部分判断，结果却更简洁。 范例：写出简单高效的测试文件 在做测试判断时，不一定非得按照：前面的操作成功了如何，否则如何的方法来进行。直接做部分判断，有时看起来更简洁。例如：12[ -x theshu ] &amp;&amp; echo 1[ -f /etc] || echo 0 2.3. 特殊条件测试表达式案例以下写法适用于所有的条件测试表达式，是工作中比较常用的替代if语句的方法。判断条件测试表达式的条件成立或不成立后，还需要继续执行多条命令语句的语法形式如下。 例如：当条件1成立时，同时执行命令1、命令2、命令3.不用if测试表达式的格式如下：1234567891011121314151617181920#&lt;==第一种测试[ 条件1 ] &amp;&amp; &#123; 命令1 命令2 命令3&#125;#&lt;==第二种测试[[ 条件1 ]] &amp;&amp; &#123; 命令1 命令2 命令3&#125;#&lt;==第三种测试test 条件1 &amp;&amp; &#123; 命令1 命令2 命令3&#125; 上面的判断相当于下面的if语句的效果：123456if [ 条件1 ]then 命令1 命令2 命令3fi 上述的结构是当满足条件执行大括号里面的命令，如果是当条件不满足时才执行大括号里面的命令，那就要把&amp;&amp;换成||。 范例：当条件不成立时，执行大括号里的多条命令，这里要使用逻辑操作符||：12345678910[root@theshu ~]# cat test123.sh[ -f /etc ] || &#123; #&lt;==如果/etc/是普通文件不成立，则执行大括号里的命令集合 echo 1 echo 2 echo 3&#125;[root@theshu ~]# sh test123.sh123 如果把上述脚本写在一行里面，那么里面的每个命令都需要用分号结尾，示例如下：123[root@theshu ~]# [ -f /etc/services ] &amp;&amp; &#123; echo "I am theshu"; echo "I am goodman"; &#125;I am theshuI am goodman 3. 字符串测试表达式3.1. 字符串测试操作符字符串测试操作符的作用包括：比较两个字符串是否相同、测试字符串的长度是否为零、字符串是否为NULL等。（NULL是指通过bash区分零长度字符串和空字符串）。 在书写测试表达式时，可以使用下表中的字符串测试操作符： 常用字符串测试操作符 说明 -n &quot;字符串&quot; 若字符串的长度不为0，则为真，即测试表达式成立，n可以理解为no zero -z &quot;字符串&quot; 若字符串的长度为0，则为真，即测试表达式成立，z可以理解为zero的缩写 &quot;串1&quot;=&quot;串2&quot; 若字符串1等于字符串2，则为真，即测试表达式成立，可使用==代替= &quot;串1&quot;!=&quot;串2&quot; 若字符串1不等于字符串2，则为真，即测试表达式成立，但不能用!==代替!= 以下是针对字符串测试操作符的提示： 对于字符串的测试，一定要将字符串加双引号之后再进行比较。如[ -n &quot;$myvar&quot; ]，特别是使用[]的场景。 比较符号（例如=和!=）的两端一定要有空格。 !=和=可用于比较两个字符串是否相同。 字符串比较时的两个错误用法： 字符串比较是若等号两端没有空格，则会导致判断出现逻辑错误，即使语法没问题，但是结果依然可能不对。示例如下： 1234[root@theshu ~]# [ "abc"="1" ] &amp;&amp; echo 1 || echo 01 #&lt;==若等号两端不带空格，则会出现明显的逻辑错误[root@theshu ~]# [ "abc" = "1" ] &amp;&amp; echo 1 || echo 00 #&lt;==带空格的就是准确的 字符串不加双引号，可能会导致判断上出现逻辑错误，即使语法没问题，但是结果依然可能不对。示例如下： 1234567[root@theshu ~]# var="" #&lt;==将变量内容置空[root@theshu ~]# [ -n "$var" ] &amp;&amp; echo 1 || echo 0 #&lt;==有双引号0 #&lt;==给变量加双引号，返回0，-n不为空时为真，因为变量内容为空吗，因此输出0是对的。[root@theshu ~]# [ -n $var ] &amp;&amp; echo 1 || echo 0 #&lt;==去掉双引号1 #&lt;==同样的表达式，不加引号和加双引号后测试的结果相反，可见加双引号的重要性[root@theshu ~]# [ -z "$var" ] &amp;&amp; echo 1 || echo 01 #&lt;==如果字符串长度为0，则输出1，否则输出0 3.2. 字符串测试生产案例范例：有关双引号和等号两端空格的生产系统标准：1234[root@theshu ~]# sed -n '30,31p' /etc/init.d/network #&lt;==系统网卡启动脚本案例# Check that networking is up.[ "$&#123;NETWORKING&#125;" = "no" ] &amp;&amp; exit 6 #&lt;==字符串变量和字符串都加了双引号，比较符号两端也都有空格 4. 整数二元比较操作符4.1. 整数二元比较操作符介绍在书写测试表达式时，可以使用下面表中的整数二元比较操作符： []和test中使用 (())和[[]]中使用 说明 -eq == 或 = 相等，equal -ne != 不想等，not equal -gt &gt; 大于，greater than -ge &gt;= 大于等于，greater equal -lt &lt; 小于 le &lt;= 小于等于，less equal 以下是针对上述符号的特别说明： =和!=也可以在[]中做比较使用，但在[]中使用包含&gt;和&lt;的符号时，需要用反斜杠转义，有时不转义虽然语法不会报错，但是结果可能会不对。 也可以在[[]]中使用包含-gt和-lt的符号，但是不建议这样使用 比较符号两端也要有空格 范例：二元数字在[]中使用&lt;、&gt;非标准符号的比较：123456789101112[root@theshu ~]# [ 2 &gt; 1 ] &amp;&amp; echo 1 || echo 01[root@theshu ~]# [ 2 &lt; 1 ] &amp;&amp; echo 1 || echo 01 #&lt;==这里的逻辑结果不对，条件不成立，则应该返回0，可见，&lt;操作符在[]里使用时会带来问题[root@theshu ~]# [ 2 \&lt; 1 ] &amp;&amp; echo 1 || echo 00 #&lt;==转义后这里是正确的[root@theshu ~]# [ 2 = 1 ] &amp;&amp; echo 1 || echo 00 #&lt;==比较相等符号是正确的[root@theshu ~]# [ 2 = 2 ] &amp;&amp; echo 1 || echo 01 #&lt;==比较相等符号是正确的[root@theshu ~]# [ 2 != 2 ] &amp;&amp; echo 1 || echo 00 #&lt;==比较不相等符号也是正确的 对于比较符号的应用，建议尽可能地按照上面表格中标记的方法来使用，以避免出现逻辑错误。 范例：二元数字在[]中使用-gt、-le类符号的比较：12345678[root@theshu ~]# [ 2 -gt 1 ] &amp;&amp; echo 1 || echo 01 #&lt;==2大于1成立，输出1[root@theshu ~]# [ 2 -ge 1 ] &amp;&amp; echo 1 || echo 01 #&lt;==2大于等于1成立，输出1[root@theshu ~]# [ 2 -le 1 ] &amp;&amp; echo 1 || echo 00 #&lt;==2小于等于1不成立，输出0[root@theshu ~]# [ 2 -lt 1 ] &amp;&amp; echo 1 || echo 00 #&lt;==2小于1不成立，输出0 范例：二元数字配合不同种类的操作符在[[]]中的比较：123456789101112131415161718[root@theshu ~]# [[ 5 &gt; 6 ]] &amp;&amp; echo 1 || echo 00 #&lt;==5大于6不成立，输出0[root@theshu ~]# [[ 5 &lt; 6 ]] &amp;&amp; echo 1 || echo 01 #&lt;==5小于6成立，输出1[root@theshu ~]# [[ 5 != 6 ]] &amp;&amp; echo 1 || echo 01 #&lt;==5不等于6成立，输出1[root@theshu ~]# [[ 5 = 6 ]] &amp;&amp; echo 1 || echo 00 #&lt;==5等于6不成立，输出0[root@theshu ~]# [[ 5 -gt 6 ]] &amp;&amp; echo 1 || echo 00 #&lt;==5大于6不成立，输出0[root@theshu ~]# [[ 5 -lt 6 ]] &amp;&amp; echo 1 || echo 01 #&lt;==5小于6成立，输出0[root@theshu ~]# [[ 65 &gt; 66 ]] &amp;&amp; echo 1 || echo 00 #&lt;==65大于66不成立，输出0[root@theshu ~]# [[ 65 &lt; 66 ]] &amp;&amp; echo 1 || echo 01 #&lt;==65小于66成立，输出1[root@theshu ~]# [[ 65 = 66 ]] &amp;&amp; echo 1 || echo 00 #&lt;==65等于66不成立，输出0 提示：[[]]是扩展的test命令，其语法更丰富也更复杂。对于实际工作中的常规比较，不建议使用[[]]，会给Shell学习带来很多麻烦，除非是特殊的正则匹配等，在[]无法使用的场景下才hi考虑使用[[]]。 范例：二元数字在(())中的比较：1234567891011[root@theshu ~]# ((3&gt;2)) &amp;&amp; echo 1 || echo 01 #&lt;==3大于2成立，输出1[root@theshu ~]# ((3&lt;2)) &amp;&amp; echo 1 || echo 00 #&lt;==3小于2不成立，输出0[root@theshu ~]# ((3==2)) &amp;&amp; echo 1 || echo 00 #&lt;==3等于2不成立，输出0[root@theshu ~]# ((3!==2)) &amp;&amp; echo 1 || echo 0-bash: ((: 3!==2: syntax error: operand expected (error token is "=2")0 #&lt;== !==符号不可用，语法错误[root@theshu ~]# ((3!=2)) &amp;&amp; echo 1 || echo 01 #&lt;==3不等于2成立，输出1 有关[]、[[]]、(())用法的小结： 整数加双引号的比较是对的 [[]]中用类似-eq等的写法是对的，[[]]中用类似&gt;、&lt;的写法也可能不对，有可能会只比较第一位，逻辑结果不对 []中用类似&gt;、&lt;的写法在语法上虽然可能没错，但逻辑结果不对，可以使用=、!=正确比较 (())中不能使用类似-eq等的写法，可以使用类似&gt;、&lt;的写法 提示：对于工作场景中的整数比较，推荐使用[]（类似-eq的用法），当然使用(())的写法也是可以的。（只需要养成一个习惯即可） 4.2. 整数变量测试实践示例范例：通过[]实现整数条件测试1234567[root@theshu ~]# a1=98;a2=99[root@theshu ~]# [ $a1 -eq $a2 ] &amp;&amp; echo 1 || echo 00 #&lt;==测试$a1是否等于$a2[root@theshu ~]# [ $a1 -gt $a2 ] &amp;&amp; echo 1 || echo 00 #&lt;==测试$a1是否大于$a2[root@theshu ~]# [ $a1 -lt $a2 ] &amp;&amp; echo 1 || echo 01 #&lt;==测试$a1是否小于$a2 提示：有关整数（要确认是整数，否则hi报错）大小的比较，推荐使用本例中的方法。 范例：利用[[]]和(())实现直接通过常规数学运算符进行比较：123456789[root@theshu ~]# a1=98;a2=99[root@theshu ~]# [[ $a1 &gt; $a2 ]] &amp;&amp; echo 1 || echo 00 #&lt;==测试$a1是否大于$a2，尽量不用此写法[root@theshu ~]# [[ $a1 &lt; $a2 ]] &amp;&amp; echo 1 || echo 01 #&lt;==测试$a1是否小于$a2，尽量不用此写法[root@theshu ~]# (($a1&gt;=$a2)) &amp;&amp; echo 1 || echo 00 #&lt;==测试$a1是否大于等于$a2，此写法也可以[root@theshu ~]# (($a1&lt;=$a2)) &amp;&amp; echo 1 || echo 01 #&lt;==测试$a1是否小于等于$a2，此写法也可以 有关整数（要确认是整数，否则会报错）的大小比较，(())语法要优于[[]]，但还是推荐优先使用[]，次选是(())，不推荐使用[[]]。示例如下：12[ $num1 -eq $num2 ] #&lt;==注意比较符号两边的空格和比较符号的写法，必须要有空格(($sum1&gt;$sum2)) #&lt;==比较符号两边无需空格（多空格也可），使用常规数学的比较符号即可 5. 逻辑操作符5.1. 逻辑操作符介绍在书写测试表达式时，可以使用下表中的逻辑操作符实现复杂的条件测试： []和test中使用 [[]]和(())中使用 说明 -a &amp;&amp; and，与，两端都为真，则结果为真 -o 双竖线 or，或，两端有一个为真，则结果为真 ! ! not，非，两端相反，则结果为真 对于上述操作符，有如下提示： 逻辑操作符前后的表达式是否成立，一般用真假来表示 !的中文意思是反，即与一个逻辑值相反的逻辑值‘ -a的中文意思是与（and或&amp;&amp;），前后两个逻辑值都为真，综合返回值才为真，反之为假 -o的中文意思是或（or或||），前后两个逻辑值只要有一个为真,，返回值就为真 连接两含[]、test或[[]]的表达式可用&amp;&amp;或|| 逻辑操作符运算规则： -a和&amp;&amp;的运算规则：只有逻辑操作符两端的表达式都成立时才为真；真（true）表示成立，对应的数字为1；假（false）表示不成立，对应的数字为0，这一点相当于如下表达式： 1234[root@theshu ~]# [ -f /etc/hosts -a -f /etc/services ] &amp;&amp; echo 1 || echo 01 #&lt;==单中括号文件测试[root@theshu ~]# [[ -f /etc/hosts &amp;&amp; -f /etc/services ]] &amp;&amp; echo 1 || echo 01 #&lt;==双中括号文件测试 使用-a或&amp;&amp;的总和表达式结果，相当于将两端表达式结果的对应数字（0或1）相乘： 1234and结果1*0=0 假and结果0*1=0 假and结果1*1=1 真and结果0*0=0 假 结论：and（&amp;&amp;）也称为与，只有两端都是1时才为真，相当于取前后表达式的交集 -o或||两端都是0才为假，任何一端不为0就是真，这相当于将两边表达式结果的对应数字（0或1）相加，对应的表达式为： 1234[root@theshu ~]# [ 5 -eq 6 -o 5 -gt 3 ] &amp;&amp; echo 1 || echo 01[root@theshu ~]# ((5==6||5&gt;3)) &amp;&amp; echo 1 || echo 01 -o或||的运算规则为： 1234or 结果1+0=1 真or 结果1+1=2 真（非0即为真）or 结果0+1=1 真or 结果0+0=0 假 结论：or（||）也称为或，它的两端表达式的结果都是0时才为假，不为0就是真。相当于对前后表达式结果取并集。 5.2. 逻辑操作符实践示例范例：[]里的操作符错用&amp;&amp;等逻辑运算符示例：12345678[root@theshu ~]# f1=/etc/rc.local ; f2=/etc/services[root@theshu ~]# echo -ne "$f1 $f2\n"/etc/rc.local /etc/services[root@theshu ~]# [ -f "$f1" &amp;&amp; -f "$f2" ] &amp;&amp; echo 1 || echo 0-bash: [: missing `]' #&lt;==这是错误语法，[]中不能用&amp;&amp;或||0[root@theshu ~]# [ -f "$f1" ] &amp;&amp; [ -f "$f2" ] &amp;&amp; echo 1 || echo 01 #&lt;==如果在[]中想使用&amp;&amp;，则这样用 总结前面已讲过的内容： -a和-o逻辑操作符号需要用于[]中 &amp;&amp;和||逻辑操作符号可用于[[]]或(())中，也可以在外部连接多个[] 注意，在[]和[[]]的两端及比较符号的两端，必须要有空格，但是对于(())不需要。 提示：[]中使用-a或-o更常见，[[]]中使用&amp;&amp;或||不常见，使用&amp;&amp;或||连接两个[]的多表达式判断也不常见。 范例：系统启动脚本中有关[[]]的用法和与或非判断的使用案例 在操作系统中，[[]]的用法不是很多，并且大多数情况都用于与通配符匹配的场景。 这里不得不通过大海捞针的方法（遍历/etc.init.d/下的所有的脚本）来查找[[]]的用法： 123456[root@theshu ~]# for n in `ls /etc/init.d/*`;do egrep -wn "\[\[ " $n&amp;&amp;echo $n;done50: if [[ $route == *" via "* ]] ; then75: if ! [[ "$SYSLOGADDR" =~ $IPv4_regex ]] &amp;&amp; ! [[ "$SYSLOGADDR" =~ $IPv6_regex ]]; then80: if [[ $? -eq 2 ]]; then84: if [[ $? -ne 0 ]]; then/etc/init.d/netconsole 由上述遍历可见，[[]]的普通应用场景不多，但在[[]]通配符匹配的场景下，其它测试表达式无法替代，因此，如果需要通配符或正则匹配就用[[]] 5.3. 逻辑操作符企业案例范例：打印选择菜单，按照选项一键安装不同的Web服务。 示例菜单：12345# sh menu.sh 1.[install lamp] 2.[install lnmp] 3.[exit] Pls input the num you want: 要求： 当用户输入1时，输出”start installing lamp”提示，然后执行/server/scripts/lamp.sh，输出”lamp is installed”，并退出脚本，此为工作中所用的lamp一键安装脚本。 当用户输入2时，输出”start installing lnmp”提示，然后执行/server/scripts/lnmp.sh，输出”lnmp is installed”，并退出脚本，此为工作中所用的lnmp一键安装脚本。 当输入3时，退出当前菜单及脚本。 当输入任何其他字符时，给予提示”Input error”后退出脚本。 对执行的脚本进行相关的条件判断，例如：脚本文件是否存在，是否可执行等的判断。 打印简单的所选菜单示例1：1234567#&lt;==前面的准备工作# mkdir -p /server/scripts# cd /server/scripts# echo "echo lamp is installed" &gt; lamp.sh# echo "echo lnmp is installed" &gt; lnmp.sh# chmod +x lnmp.sh lamp.sh#&lt;==以上步骤模拟lamp和lnmp的安装脚本及过程。 下面是正式脚本的内容：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#!/bin/bashpath=/server/scripts #&lt;==定义脚本路径[ ! -d "$path" ] &amp;&amp; mkdir $path -p #&lt;==条件表达式判断，如果目录不存在，则创建目录#menucat &lt;&lt;END #&lt;==利用cat命令打印选择菜单，这里也可以用select语句打印选择菜单 1.[install lamp] 2.[install lnmp] 3.[exit] Pls input the num you want: ENDread num #&lt;==接受用户选择的数字 expr $num + 1 &amp;&gt; /dev/null #判断石佛为整数[ $? -ne 0 ] &amp;&amp; &#123; echo "the num you input must be (1|2|3)" exit 1&#125;[ "$num" = "1" ] &amp;&amp; &#123; echo "start installing LAMP." sleep 2; [ -x "$path/lamp.sh" ] || &#123; echo "$path/lamp.sh does not exist or can not be exec." exit 1 &#125; $path/lamp.sh #&lt;==执行脚本安装脚本，工作中建议用source $path/lamp.sh替代 #source $path/lamp.sh #&lt;==脚本中执行脚本，使用source比sh或不加解释器等更好一些 exit $?&#125;[ $num -eq 2 ] &amp;&amp; &#123; echo "start installing LNMP." sleep 2; [ -x "$path/lnmp.sh" ] || &#123; echo "$path/lnmp.sh does not exist or can not be exec." exit 1 &#125; $path/lnmp.sh #source $path/lnmp.sh exit $?&#125;[ $num -eq 3 ] &amp;&amp; &#123; echo bye. exit 3&#125;#这里有三种用户的输入不等于1、2或3的综合用法[[ ! $num =~ [1-3] ]] &amp;&amp; &#123; #&lt;==[[]]的正则匹配方法 echo "the num you input must be (1|2|3)" echo "Input ERROR" exit 4&#125; 提示：这里关于判断用户的输入是否等于1、2或3的用法共给出了三种。请一定要重视。使用菜单时还可以用select语句，不过还是cat的方法更常用，也更简单。 6. 测试表达式test、[]、[[]]、(()) 的区别总结测试表达式的语法比较复杂且容易混淆，对于初学者，一定要个自己设定个知识边界。下表中列出了测试表达式[]、[[]]、(())、test的区别： 测试表达式符号 [] test [[]] (()) 边界是否需要空格 需要 需要 需要 不需要 逻辑操作符 !、-a、-o !、-a、-o !、&amp;&amp;、双竖线 !、&amp;&amp;、双竖线 整数比较操作符 -eq、-gt、lt -ge、-le -eq、-gt、lt、-ge -le -eq、-gt、lt、-ge、-le 或=、&gt;、&lt;、&gt;=、&lt;= =、&gt;、&lt;、&gt;=、&lt;= 字符串比较操作符 =、==、!= =、==、!= =、==、!= =、==、!= 是否支持通配符匹配 不支持 不支持 支持 不支持 提示：普通的读者学习Shell编程主要是为了解决工作中的问题，因此无需掌握全部的语法，建议只用推荐的[]的用法，对其他的语法了解杰克，当有需要时，可以翻看资料或查阅bash文档man bash，以及对应命令man test的帮助。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记05-变量的数值计算]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F007.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B005-%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97%2F</url>
    <content type="text"><![CDATA[GO 1. 算术运算符常见的Shell算术运算符见下表： 算术运算符 意义（*表示常用） +、- 加法（或正号）、减法（或负号）* *、/、% 乘法、除法、取余（取模）* ** 幂运算* ++、-- 增加及减少，可前置也可放在变量结尾* !、&amp;&amp;、双竖 逻辑非（取反）、逻辑与（and）、逻辑或（or）* &lt;、&lt;=、&gt;、&gt;= 比较符号（小于、小于等于、大于、大于等于） ==、!=、= 比较符号（相等、不相等，对于字符串=也可以表示相当于）* &lt;&lt;、&gt;&gt; 向左移位、向右移位 ~、单竖、&amp;、^ 按位取反、按位异或、按位与、按位或 =、+=、-=、*=、/=、%= 赋值运算，例如a+=1相当于a=a+1，a-=1相当于a=a-1* 上表中的算术运算符号均适用于常见的运算命令。常见的运算命令见下表： 运算操作符与运算命令 意义 (()) 用于整数运算的常用运算符，效率很高 let 用于整数运算，类似于(()) expr 可用于整数运算，但还有很多其他的额外功能 bc Linux下的一个计算器程序（适合整数及小数运算） $[] 用于整数运算 awk awk既可以用于整数运算，也可以用于小数运算 declare 定义变量值和属性，-i参数可以用于定义整型变量，做运算 下面的内容，将逐一讲解Shell中的各种运算符号及运算命令。 2. 双小括号 (()) 数值运算的基础语2.1. 双小括号 (()) 数值运算的基础语法双小括号(())的作用是进行数值运算与数值比较，它的效率很高，用法灵活，是企业场景运维人员经常采用的运算操作符，其操作方法见下表： 运算操作符与运算命令 意义 ((i=i+1)) 此种书写方法为运算后赋值法，即将i+1的运算结果赋值给变量i。注意，不能用echo ((i=i+))的形式输出表达式的值，但可以用echo $((i=i+1))输出其值 i=$((i+1)) 可以在(())前加$符，表示将表达式运算后赋值给i ((8&gt;7&amp;&amp;5==5)) 可以进行比较操作，还可以加入逻辑与和逻辑或，用于条件判断 echo $((2+1)) 需要直接输出运算表达式的运算结果时，可以在(())前加$符 2.2. 双小括号 (()) 数值运算实践 例1：利用(())进行简单的数值计算 12345678[root@theshu ~]# echo $((1+1))2[root@theshu ~]# echo $((6-3))3[root@theshu ~]# ((i=5))[root@theshu ~]# ((i=i*2))[root@theshu ~]# echo $i10 例2：利用(())进行稍微复杂一些的综合算术运算 12345678910111213[root@theshu ~]# ((a=1+2**3-4%3)) #&lt;==这是一个较复杂的表达式运算并赋值的操作，其中2**3表示2的三次方[root@theshu ~]# echo $a8 #&lt;==表达式运算后将结果赋值给a ，先乘除后加减[root@theshu ~]# b=$((1+2**3-4%3)) #&lt;==这是另一种表达式运算后将结果赋值给变量的写法，变量放在了括号的外面[root@theshu ~]# echo $b8[root@theshu ~]# echo $((1+2**3-4%3)) #&lt;==还可以直接运算表达式并将结果输出，注意，不要落下$符号8[root@theshu ~]# a=$((100*(100+1)/2)) #&lt;==利用公式计算1到100的和[root@theshu ~]# echo $a5050[root@theshu ~]# echo $((100*(100+1)/2)) #&lt;==直接输出表达式的结果5050 例3：特殊运算符号的运算小示例 1234567[root@theshu ~]# a=8[root@theshu ~]# echo $((a=a+1)) #&lt;==将a+1赋值给a，然后输出表达式的值9[root@theshu ~]# echo $((a+=1)) #&lt;==相当于a=a+110[root@theshu ~]# echo $((a**2)) #&lt;==计算a的平方，**表示幂运算100 例4：利用(())双括号进行比较和判断 1234567891011[root@theshu ~]# echo $((3&lt;8)) #&lt;==3&lt;8的结果是成立的，因此输出了1，1表示真1[root@theshu ~]# echo $((8&lt;3)) #&lt;==8&lt;3的结果是不成立的，因此输出了0，0表示假0[root@theshu ~]# echo $((8==8)) #&lt;==判断是否相等1[root@theshu ~]# if ((8&gt;7&amp;&amp;5==5)) #&lt;==如果8&gt;7成立并且5==5成立，则打印yes。&gt; then&gt; echo yes&gt; fiyes #&lt;==显然两个条件都成立，所以打印了yes 提示：上面设计的数字及变量必须为整数（整型），不能是小数（浮点数）或字符串。后面的bc和awk命令可以用于进行小数（浮点数）运算，但一般用到的较少。 例5：在变量前后使用--和++特殊运算符的表达式123456789101112131415161718192021222324[root@theshu ~]# a=10[root@theshu ~]# echo $((a++)) 10#&lt;==如果a在运算符（++或--）的前面，那么在输出整个表达式时，会输出a的值，因为a为10，所以表达式的值为10[root@theshu ~]# echo $a11#&lt;==执行上面的表达式后，因为有a++，因此a会自增1，因此输出a的值为11[root@theshu ~]# a=11[root@theshu ~]# echo $((a--))11 #&lt;==理由同上[root@theshu ~]# echo $a10[root@theshu ~]# a=10[root@theshu ~]# echo $a10[root@theshu ~]# echo $((--a))9#&lt;==如果a在运算符（++或--）的后面，那么在输出整个表达式时，先进行自增或自减运算，因为a为10，且要自减，所以表达式的值为9[root@theshu ~]# echo $a9 #&lt;==执行上面的表达式后，a自减1，因此a为9[root@theshu ~]# echo $((++a))10 #&lt;==理由同上[root@theshu ~]# echo $a10 执行echo $((a++))和$((a--))命令输出整个表达式时，输出的值即为a的值，表达式执行完毕后，会对a进行++、–运算，而执行echo $((++a))和echo $((--a))命令输出整个表达式时，会先对a进行++、–的运算，然后再输出表达式的值，即为a运算后的值。 提示：有关++、--运算的记忆方法：变量a在运算符之前，输出表达式的值为a，然后a自增或自减；变量a在运算符之后，输出表达式会先自增或自减，表达式的值就是自增或自减后a的值。 例6：通过(())运算后赋值给变量12345678[root@theshu ~]# myvar=99[root@theshu ~]# echo $((myvar+1)) #&lt;=="(())"中的变量myvar前也可以加$符号，也可以不加100[root@theshu ~]# echo $(( myvar + 1 )) #&lt;=="(())"内部内容的两端有几个空格无所谓，变量和运算符号之间有无空格也无所谓，可以有一个或多个，也可以没有100[root@theshu ~]# myvar=$((myvar+1)) #&lt;==还可以在"(())"表达式前加$符号，将表达式赋值给变量[root@theshu ~]# echo $myvar100 提示：在(())中使用变量时可以去掉变量前的$符号 例7：包含(())的各种常见运算符命令的执行示例123456789101112[root@theshu ~]# echo $((6+2)) #&lt;==加法8[root@theshu ~]# echo $((6-2)) #&lt;==减法4[root@theshu ~]# echo $((6*2)) #&lt;==乘法12[root@theshu ~]# echo $((6/2)) #&lt;==除法，取商数3[root@theshu ~]# echo $((6%2)) #&lt;==取模，即取余数0[root@theshu ~]# echo $((6**2)) #&lt;==幂运算36 提示： (())表达式在命令执行时不需要加$符号，直接使用((6%2))形式即可，但是如果需要输出，就要加$符号，例如：echo $((6%2)) (())里的所有字符之间没有空格、有一个或多个空格都不会影响结果。 例8：各种(())运算的Shell脚本示例12345678910[root@theshu ~]# cat test.sh#!/bin/basha=6b=2echo "a-b=$(($a-$b))"echo "a+b=$(($a+$b))"echo "a*b=$(($a*$b))"echo "a/b=$(($a/$b))"echo "a**b=$(($a**$b))"echo "a%b=$(($a%$b))" 脚本运行如下：1234567[root@theshu ~]# sh test.sha-b=4a+b=8a*b=12a/b=3a**b=36a%b=0 例9：把例8中的a、b两个变量通过命令行脚本传参，以实现混合运算脚本的功能 这是一个考察实战编程思想的综合实践考试题。 参考答案1如下：12345678910[root@theshu ~]# cat test.sh#!/bin/basha=$1 #&lt;==直接把特殊位置参数变量$1赋值给ab=$2 #&lt;==并且把特殊位置参数变量$2赋值给b，这样，脚本传参的内容就会赋值给a和becho "a-b=$(($a-$b))"echo "a+b=$(($a+$b))"echo "a*b=$(($a*$b))"echo "a/b=$(($a/$b))"echo "a**b=$(($a**$b))"echo "a%b=$(($a%$b))" 执行结果如下：1234567[root@theshu ~]# sh test.sh 6 2a-b=4a+b=8a*b=12a/b=3a**b=36a%b=0 使用脚本传参的好处是可以进行各种数字间的运算，不想前一个脚本，因为是直接定义变量的，所以只能做6和2这两个数字的运算，也就是说，使用传参，可以让脚本更具备通用性。 参考答案2如下：1234567#!/bin/bashecho "a-b=$(( $1 - $2 ))"echo "a+b=$(( $1 + $2 ))"echo "a*b=$(( $1 * $2 ))"echo "a/b=$(( $1 / $2 ))"echo "a**b=$(( $1 ** $2 ))"echo "a%b=$(( $1 % $2 ))" 这个方法虽然也可以实现同样的功能，但是对源脚本的改动过大，所以，从编程思想方面来说，不如参考答案1。 3. let运算命令的用法 let运算命令的语法格式为：let 赋值表达式 let赋值表达式的功能等同于((赋值表达式)) 例子：给自变量i加8 123456789[root@theshu ~]# i=2[root@theshu ~]# i=i+8 #&lt;==假如开头不用let进行赋值[root@theshu ~]# echo $i #&lt;==输出时会发现，打印结果为 i+8，也就是没有计算i+8[root@theshu ~]# unset i[root@theshu ~]# i=2[root@theshu ~]# let i=i+8 #&lt;==采用let赋值后再输出[root@theshu ~]# echo $i10 #&lt;==结果为10 提示：let i=i+8等同于((i=i+8))，但后者效率更高。 4. expr命令的用法4.1. expr命令的基本用法示例expr（evaluate（求值）expressions（表达式））命令既可以用于整数运算，也可以用于相关字符串长度、匹配运算处理。 1. 用法1：expr用于计算语法：expr Expression 范例：expr命令运算用法实践：12345678910[root@theshu ~]# expr 2 + 24[root@theshu ~]# expr 2 - 20[root@theshu ~]# expr 2 * 2 #&lt;==注意，*号要用\来转义，否则语法错误expr: syntax error[root@theshu ~]# expr 2 \* 24[root@theshu ~]# expr 2 / 21 要注意，在使用expr时： 运算符及用于计算的数字左右都至少有一个空格，否则会报错 使用称号时，必须用反斜杠屏蔽其特定含义，因为Shell可能会误解星号的含义 2. 用法2：expr配合变量计算expr在Shell中可配合变量进行计算，但需要用反引号将计算表达式括起来。 范例：给自变量i加6：12345[root@theshu ~]# i=5[root@theshu ~]# i=`expr $i + 6` #&lt;注意用反引号将表达式引起来，变量和数字符号两边要有空格[root@theshu ~]# echo $i11 4.2. expr的企业级实战案例详解1. 判断一个变量值或字符串是否为整数在Shell编程里，由于函数库很少，所以判断字符串是否为整数就不是一键很容易的事情。在这里介绍一种简单的可以判断一个字符串是否为整数的方法。 实现原理是，利用以expr做计算时变量或字符串必须是整数的规则，把一个变量或字符串和一个已知的整数（非0）相加，看命令返回值是否为0。若为0，则做加法的变量或字符串为整数，否则就不是整数。下面是几个示例。 示例：通过expr判断变量或字符串是否为整数12345678[root@theshu ~]# i=5[root@theshu ~]# expr $i + 6 &amp;&gt; /dev/null[root@theshu ~]# echo $?0[root@theshu ~]# i=theshu[root@theshu ~]# expr $i + 6 &amp;&gt; /dev/null[root@theshu ~]# echo $?2 结论：利用expr做计算，将一个未知的变量和一个已知的整数相加，看返回值是否为0，如果为0就任务做加法的变量为整数，否则就不是整数。 示例：通过传参判断输出内容是否为整数12345678[root@theshu ~]# cat test.sh#!/bin/bashexpr $1 + 1 &gt; /dev/null 2&gt;&amp;1[ $? -eq 0 ] &amp;&amp; echo int || echo chars[root@theshu ~]# sh test.sh theshuchars[root@theshu ~]# sh test.sh 123int 示例：通过read读入持续等待输入例子。test.sh的内容如下：12345678[root@theshu ~]# cat test.sh#!/bin/bashwhile truedo read -p "Pls input:" a expr $a + 0 &gt; /dev/null 2&gt;&amp;1 [ $? -eq 0 ] &amp;&amp; echo int || echo charsdone 执行结果如下：123456[root@theshu ~]# sh test.shPls input:theshucharsPls input:123intPls input: 示例：将前文的混合运算小程序改成输入两个参数后进行计算的程序，并且要能判断传参的个数及通过expr判断传入的参数是否为整数。 待使用的脚本如下：12345678910[root@theshu ~]# cat test.sh#!/bin/basha=6b=2echo "a-b=$(($a-$b))"echo "a+b=$(($a+$b))"echo "a*b=$(($a*$b))"echo "a/b=$(($a/$b))"echo "a**b=$(($a**$b))"echo "a%b=$(($a%$b))" 这道题的编程思路如下： 第一关，判断参数个数是否为2，若不是，则给出提示终止运行 第二关，判断传入的参数是否为整数，若不是，则给出提示终止运行 第三关，做运算 参考答案1：12345678910111213141516171819202122232425[root@theshu ~]# cat test1.sh#!/bin/bash# NO.1 对传入参数个数进行判断[ $# -ne 2 ] &amp;&amp; &#123; echo $"USAGE $0 NUM1 NUM2" exit 1&#125;# NO.2 对传入参数是否是整数进行判断a=$1b=$2expr $a + $b + 110 &amp;&gt; /dev/nullif [ $? -ne 0 ]then echo "You must input two nums." exit 2fi# NO.3 进行运算echo "a-b=$(($a-$b))"echo "a+b=$(($a+$b))"echo "a*b=$(($a*$b))"echo "a/b=$(($a/$b))"echo "a**b=$(($a**$b))"echo "a%b=$(($a%$b))" 参考答案2：12345678910111213141516171819202122232425262728[root@theshu ~]# cat test2.sh#!/bin/bash# NO.1 对传入参数个数进行判断[ $# -ne 2 ] &amp;&amp; &#123; echo $"USAGE $0 NUM1 NUM2" exit 1&#125;# NO.2 对传入参数是否是整数进行判断a=$1b=$2expr $a + 1 &amp;&gt; /dev/nullRETVAL_A=$?expr $b + 1 &amp;&gt; /dev/nullRETVAL_B=$?if [ $RETVAL_A -ne 0 -o $RETVAL_B -ne 0 ]then echo "You must input two nums." exit 2fi# NO.3 进行运算echo "a-b=$(($a-$b))"echo "a+b=$(($a+$b))"echo "a*b=$(($a*$b))"echo "a/b=$(($a/$b))"echo "a**b=$(($a**$b))"echo "a%b=$(($a%$b))" 此外，用expr match功能进行整数判断时，可执行man expr命令获取帮助。如下： 2. expr的特殊用法：判断文件扩展名是否符合要求范例：通过expr判断文件扩展名是否符合要求123456789101112[root@theshu ~]# cat expr1.sh#!/bin/bashif expr "$1" : ".*\.pub" &amp;&gt; /dev/nullthen echo "you are using $1"else echo "pls use *.pub file"fi[root@theshu ~]# sh expr1.sh id_dsa.pubyou are using id_dsa.pub[root@theshu ~]# sh expr1.sh id_dsapls use *.pub file 3. 通过expr计算字符串的长度示例：利用expr计算字符串的长度123456789[root@theshu ~]# char="I am goodman"[root@theshu ~]# expr length "$char" #&lt;==利用expr的length函数计算字符串长度12[root@theshu ~]# echo $&#123;#char&#125; #&lt;==计算变量子串长度的方法12[root@theshu ~]# echo $&#123;char&#125; | wc -L #&lt;==wc方法12[root@theshu ~]# echo $&#123;char&#125; | awk '&#123;print length($0)&#125;' #&lt;==利用awk的length函数计算字符串的长度12 示例：编写Shell脚本，打印下面语句中字符数不大于6的单词：1234567for n in I am theshu linux welcome to our trainingdo if [ `expr length $n` -le 6 ] then echo $n fidone 更多expr的用法请查看帮助文件man expr 5. bc命令的用法bc是Unix/Linux下的计算器，因此，除了可以作为计算器来使用，还可以作为命令行计算工具使用。 范例：将bc用在命令行下面，以实现运算功能12345678910[root@theshu ~]# echo 3+5 | bc8[root@theshu ~]# echo 3.3+5.5 | bc8.8[root@theshu ~]# echo 8.8-5.5 | bc3.3[root@theshu ~]# echo "scale=2;355/113" | bc #&lt;==使用scale=2保留两位小数3.14[root@theshu ~]# echo "scale=6;355/113" | bc #&lt;==使用scale=6保留6位小数3.141592 利用bc配合变量运算：1234[root@theshu ~]# i=5[root@theshu ~]# i=`echo $i+6 | bc`[root@theshu ~]# echo $i11 提示：根据bc所具有的特殊性来看，如果是小数，则选择bc运算没问题（但高手前辈推荐awk）；若是整数场景，可用(())、let、expr等。 范例：通过一条命令计算输出1到10的表达式，并计算出结果，请使用bc命令计算。输出内容如1+2+3+4+5+6+7+8+9+10=55 这里生成上述表达式的方法有：12345[root@theshu ~]# seq -s "+" 10 #&lt;==seq是生成数字序列，-s是指定数字序列之间的分隔符1+2+3+4+5+6+7+8+9+10[root@theshu ~]# echo &#123;1..10&#125; | tr " " "+"#&lt;==&#123;1..10&#125;是生成以空格为间隔的数字序列，并交给tr将空格替换为+号1+2+3+4+5+6+7+8+9+10 实现本题的多种方法如下：12345678[root@theshu ~]# echo `seq -s "+" 10`=`seq -s "+" 10 | bc` #&lt;==使用bc计算1+2+3+4+5+6+7+8+9+10=55[root@theshu ~]# echo "`seq -s "+" 10`="$((`seq -s "+" 10`)) #&lt;==使用"(())"计算1+2+3+4+5+6+7+8+9+10=55[root@theshu ~]# echo `seq -s '+' 10`=`seq -s " + " 10 | xargs expr` #&lt;==使用expr计算1+2+3+4+5+6+7+8+9+10=55[root@theshu ~]# echo `seq -s "+" 10`=$(echo $[`seq -s "+" 10`]) #&lt;==使用$[]计算1+2+3+4+5+6+7+8+9+10=55 只需要记住，bc命令的独有特点是除了支持整数运算之外，还支持小数运算。 6. awk实现计算利用awk进行运算的效果也很好，适合小数和整数，特别是命令行计算，尤其是小数，运算很精确，好用。下面来看一个示例：1234567[root@theshu ~]# echo "7.7 3.8" | awk '&#123;print ($1-$2)&#125;'#&lt;==$1为第一个数字，$2为第二个数字，用空格隔开，下同3.9[root@theshu ~]# echo "358 113" | awk '&#123;print ($1-3)/$2&#125;'3.14159[root@theshu ~]# echo "3 9" | awk '&#123;print ($1+3)*$2&#125;'54 7. declare（同typeset）命令的用法使用typeset定义整数变量，直接进行计算。这个方法不是很常用，因为需要定义才能生效。示例如下：1234[root@theshu ~]# declare -i A=30 B=7 #&lt;==declare -i参数可以将变量定义为整型[root@theshu ~]# A=A+B #&lt;==因为已经声明是整型，因此可以直接进行运算[root@theshu ~]# echo $A37 8. $[] 符号的运算示例关于$[]符号运算的示例如下：12345678910111213141516[root@theshu ~]# i=5[root@theshu ~]# i=$[i+6][root@theshu ~]# echo $i11[root@theshu ~]# echo $[2*3]6[root@theshu ~]# echo $[2**3]8[root@theshu ~]# echo $[3/5]0[root@theshu ~]# echo $[3/2]1[root@theshu ~]# echo $[3%5]3[root@theshu ~]# echo $[ 3 % 5 ]3 下面是一个打印数学杨辉三角的案例，这个案例只作为学习意义使用，对于运维工作毫无意义：12345678910111213141516171819202122232425262728#!/bin/bashif (test -z $1) ; then read -p "Input Max Lines: " MAXelse MAX=$1fii=1while [ $i -le $MAX ]do j=1 while [ $j -le $i ] do f=$[i-1] g=$[j-1] if [ $j -eq $i ] || [ $j -eq 1 ] ; then declare SUM_$&#123;i&#125;_$j=1 else declare A=$[SUM_$&#123;f&#125;_$j] declare B=$[SUM_$&#123;f&#125;_$g] declare SUM_$&#123;i&#125;_$j=`expr $A + $B` fi echo -en $[SUM_$&#123;i&#125;_$j]" " let j++ done echo let i++done 9. 基于Shell变量输入read命令的运算实践9.1. read命令基础Shell变量除了可以直接赋值或脚本传参外，还可以使用read命令从标准输入中获得，read为bash内置命令，可通过help read查看帮助。 语法格式：read [参数] [变量名] 常用参数如下： -p prompt 设置提示信息 -t timeout 设置输入等待时间，单位默认为秒 示例：实现read的基本读入功能：123456789[root@theshu ~]# read -t 10 -p "Pls input one num: " num#&lt;==读入一个输入，赋值给num变量，注意，num变量前需要有空格Pls input one num: 24[root@theshu ~]# echo $num24[root@theshu ~]# read -p "Pls input two numbers:" a1 a2 #读入两个输入，依次赋值给变量，注意，变量前后都要有空格Pls input two numbers:1 2[root@theshu ~]# echo $a1 $a21 2 提示：read的读入功能就相当于交互式接受用户输入，然后给变量赋值。 上面的read -p的功能可以用echo和read来实现，如下：12echo -n "Pls input two number:"read a1 a2 以上两句和下面的命令相当（-t排除在外）1read -t 5 -p "Pls input two numbers:" a1 a2 9.2. 使用read的常见错误下面是一些典型使用read命令错误的地方： read -p &quot;Pls input:&quot; 这里的read没有用，因为没有变量来接收用户的输入 read -p &quot;Pls input:&quot; &quot;$1&quot; &quot;$2&quot; 这里的$1和$2本来是有特定功能的变量，不能用其作为变量来接受read的读入。错误在于，read后面接的是普通变量，并且将传参和read混用了，传参和read可以理解为是两种变量赋值的方法，使用其一即可。 a=$1 ; read -p &quot;Pls input:&quot; $a 作为接收read的变量，不该带$符号。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记04-Shell变量知识进阶]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F006.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B004-Shell%E5%8F%98%E9%87%8F%E7%9F%A5%E8%AF%86%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[GO 1. Shell中特殊且重要的变量1.1. Shell中的特殊位置参数变量在Shell中存在一些特殊且重要的变量，例如：$0、$1、$#等，我们称之为特殊位置参数变量。要从命令行、函数或脚本执行等处传递参数时，就需要在Shell脚本中使用位置参数变量。下表为常用的特殊位置参数变量的说明： 位置变量 作用说明 $0 获取当前执行的Shell脚本的文件名，如果执行脚本包含了路径，那么就包括脚本路径 $n 获取当前执行的Shell脚本的第n个参数，n=1..9，当n为0时表示脚本的文件名；如果n大于9，则要用大括号括起来，例如${10}，接的参数以空格隔开 $# 获取当前执行的Shell脚本后面接的参数的总个数 $* 获取当前Shell脚本所有传参的参数，不加引号和$@相同；如果给$*加上双引号，例如：&quot;$*&quot;，则表示将所有的参数视为单个字符串，相当于$1 $2 $3 $@ 获取当前Shell脚本所有传参的参数，不加引号和$*相同；如果给它加上双引号，例如：$@，则表示将所有的参数视为不同的独立字符串，相当于&quot;$1&quot; &quot;$2&quot; &quot;$3&quot; &quot;...&quot;。这是将多参数传递给其他程序的最佳方式，因为它会保留所有的内嵌在每个参数里的任何空白。当$@和$*都加双引号时，两者是有区别的；都不加双引号时，两者无区别。 1.1.1. $n的用法总结 加引号括起来的内容传参，会作为一个字符串参数，如：sh test.sh &quot;theshu boy&quot;中theshu boy作为一个参数 当$n的n大于9时，必须要这样用才能得到正确的结果：${n}，示例代码如下：12345678910111213141516[theshu@theshu ~]$ echo \$&#123;1..15&#125; #&lt;==利用大括号输出15个位置参数，学会了 该命令就不用手敲代码了。$1 $2 $3 $4 $5 $6 $7 $8 $9 $10 $11 $12 $13 $14 $15[theshu@theshu ~]$ echo \$&#123;1..15&#125; &gt; n.sh #&lt;==将15个位置参数定向到文件n.sh[theshu@theshu ~]$ vim n.sh #&lt;==在代码的最前面添加echo[theshu@theshu ~]$ cat n.sh #&lt;==最终的测试代码echo $1 $2 $3 $4 $5 $6 $7 $8 $9 $10 $11 $12 $13 $14 $15[theshu@theshu ~]$ echo &#123;a..z&#125; #&lt;=测试打印26个英文字母并以空格分隔a b c d e f g h i j k l m n o p q r s t u v w x y z[theshu@theshu ~]$ sh n.sh &#123;a..z&#125; #&lt;==传入26个英文字母，以空格分隔作为参数a b c d e f g h i a0 a1 a2 a3 a4 a5 #&lt;==位置参数大于9后，输出的内容就不对了[theshu@theshu ~]$ vim n.sh #&lt;==修改代码[theshu@theshu ~]$ cat n.sh #&lt;==最终代码如下echo $1 $2 $3 $4 $5 $6 $7 $8 $9 $&#123;10&#125; $&#123;11&#125; $&#123;12&#125; $&#123;13&#125; $&#123;14&#125; $&#123;15&#125;[theshu@theshu ~]$ sh n.sh &#123;a..z&#125; #重新测试a b c d e f g h i j k l m n o #&lt;==位置参数大于9的也正确了 1.1.2. $0特殊变量的作用及变量实践 $0的作用为取出执行脚本的名称（包括路径）。若不带路径执行脚本，那么输出结果就是脚本的名字，若使用绝对路径执行脚本，那么输出结果就是全路径加上脚本的名字。示例代码如下： 123456[theshu@theshu ~]$ cat n.shecho $0[theshu@theshu ~]$ sh n.shn.sh[theshu@theshu ~]$ sh /home/theshu/n.sh/home/theshu/n.sh 当执行的脚本为绝对路径时，$0也会带着路径，这时如果希望单独获取名称或路径，可以利用dirname和basename这两个命令。示例代买如下： 1234567891011[theshu@theshu ~]$ dirname /home/theshu/n.sh/home/theshu #&lt;==dirname命令的作用是获取脚本的路径[theshu@theshu ~]$ basename /home/theshu/n.shn.sh #&lt;==basename命令的作用是获取脚本的名字#&lt;==利用$0和dirname以及basename命令分别取出脚本名称和脚本路径的代码：[theshu@theshu ~]$ cat n.shdirname $0basename $0[theshu@theshu ~]$ sh /home/theshu/n.sh/home/theshun.sh 有关$0这个位置参数的系统生产场景案例如下，其中采用aegis系统脚本： 1234567891011[theshu@theshu ~]$ tail -6 /etc/init.d/aegis echo $"Usage: $0 &#123;start|stop|restart|status|uninstall&#125;"#&lt;==$0的基本生产场景就是，当用户的输入不符合脚本的要求时，就打印脚本的名字及使用帮助。 exit 1 ;;esac[theshu@theshu ~]$ sudo /etc/init.d/aegis #&lt;==不带任何参数执行aegis脚本Usage: /etc/init.d/aegis &#123;start|stop|restart|status|uninstall&#125;#&lt;==上文/etc/init.d/aegis就是$0从脚本命令行获取的值，当用户输入不符合脚本设定的要求时，打印脚本名字及预期的使用帮助 1.1.3. $#特殊变量获取脚本传参个数的实践例子：通过$#获取脚本传参的个数。123456[theshu@theshu ~]$ cat q.shecho $1 $2 $3 $4 $5 $6 $7 $8 $9echo $# #&lt;==此行是打印脚本命令行传参的个数[theshu@theshu ~]$ sh q.sh &#123;a..z&#125; #&lt;==传入26个字符作为26个参数a b c d e f g h i #&lt;==只接收了9个变量，所以打印9个字符26 #&lt;==传入26个字符作为26个参数，因此这里的数字为26，说明传入了26个参数 下面是一个针对$0、$1、$#等多位置参数的综合型企业案例，它的作用是根据用户在命令行的传参个数判断用户的输入，不合要求的给予提示并退出。首先来看条件表达式判断语句的写法，如下：12345678910[theshu@theshu ~]$ cat t1.sh[ $# -ne 2 ] &amp;&amp; &#123; echo "Must be two args" exit 1&#125;echo ok[theshu@theshu ~]$ sh t1.shMust be two args[theshu@theshu ~]$ sh t1.sh arg1 arg2ok 然后是if判断语句的写法，如下：1234567891011[theshu@theshu ~]$ cat t2.shif [ $# -ne 2 ]then echo "USAGE:/bin/sh $0 arg1 arg2" exit 1fiecho $1 $2[theshu@theshu ~]$ sh t2.shUSAGE:/bin/sh t2.sh arg1 arg2[theshu@theshu ~]$ sh t2.sh theshu boytheshu boy 1.1.4. $*和$@特殊变量功能及区别说明例子：利用set命令设置位置参数（同命令行脚本的传参）12345678910[theshu@theshu ~]$ set -- "I am" good man.#&lt;==通过set设置了三个字符串参数，"--"表示清除所有的参数变量，重新设置后面的参数变量[theshu@theshu ~]$ echo $# #&lt;==输出参数的个数3[theshu@theshu ~]$ echo $1 #&lt;==打印第一个参数值I am[theshu@theshu ~]$ echo $2 #&lt;==打印第二个参数值good[theshu@theshu ~]$ echo $3 #&lt;==打印打三个参数值man. 测试$*和$@，注意，此时不带双引号：1234567891011121314[theshu@theshu ~]$ echo $* #&lt;==打印$*I am good man.[theshu@theshu ~]$ echo $@ #&lt;==打印$@I am good man.[theshu@theshu ~]$ for i in $*;do echo $i;done #&lt;==使用for循环输出$*测试I #&lt;==（$*）不加双引号，因此会输出所有参数，然后第一个参数"I am"也拆开输出了amgoodman.[theshu@theshu ~]$ for i in $@;do echo $i;done #&lt;==使用for循环输出$@测试I #&lt;==（$0）不加双引号，因此会输出所有参数，然后第一个参数"I am"也拆开输出了amgoodman. 测试$*和$@，注意，此时带有双引号：12345678910111213141516171819[theshu@theshu ~]$ echo "$*"I am good man.[theshu@theshu ~]$ echo "$@"I am good man.[theshu@theshu ~]$ for i in "$*";do echo $i;done#&lt;==在有双引号的情况下"$*"，参数里引号中的内容当作一个参数输出了I am good man.[theshu@theshu ~]$ for i in "$@";do echo $i;done#&lt;==在有双引号的情况下，每个参数均以独立的内容输出I am #&lt;==有双引号算一个参数goodman.#&lt;==这才真正符合我们传入的参数需求，set -- "I am" good man.[theshu@theshu ~]$ for i;do echo $i;done#&lt;==去掉in变量列表，相当于有引号的in "$@"I amgoodman.#&lt;==这才真正符合我们传入的参数需求，set -- "I am" good man. 可以利用shift将位置参数移位（左移）：1234567[theshu@theshu ~]$ shift[theshu@theshu ~]$ echo $# #&lt;==移位（左移）2[theshu@theshu ~]$ echo $1 #&lt;==这里就打印原来的$2的值了good[theshu@theshu ~]$ echo $2 #&lt;==这里就打印原来的$3的值了man. 1.2. Shell进程中的特殊状态变量Shell进程中的特殊状态变量如下表：（提示：下表的查找方式为使用man bash命令，然后搜索关键字Special Parameteers） 位置变量 作用说明 $? 获取执行上一个指令的执行装填返回值（0为成功，非零为失败），这个变量最常用 $$ 获取当前执行的Shell脚本的进程号（PID），这个变量不常用，了解即可 $! 获取上一个在后台工作的进程的进程号（PID），这个变量不常用，了解即可 $_ 湖区在此之前执行的命令或脚本的最后一个参数，这个变量不常用，了解即可 1.2.1. 关于$?的说明 在不通命令的执行结果中，$?的返回值不尽相同，但在工作场景中，常用的就是0和非0两种状态，0表示成功运行，非0表示运行失败。 若使用源码编译安装软件，可以在每个步骤的结尾获取$?来判断命令执行成功与否。 对于新手来说，在安装服务时，可以通过获取执行命令的返回值来确定命令的执行状态，从而快速确定命令是否执行成功。不过，有经验的技术人员不需要获取返回值，通过命令的最后过程输出就可以快速判断是否成功。 当对服务器的数据进行备份时，我们会在执行完关键命令，例如tar或cp后，通过获取返回值来判断命令是否执行成功，备份数据是否完整。 在企业场景下，$?返回值的用法如下： 判断命令、脚本或函数等程序是否执行成功 若在脚本中调用执行exit 数字，则会返回这个数字给$?变量 如果是在函数里，则通过return 数字把这个数字以函数返回值的形式传给$? 1.2.2. 关于$$的应用例子：实现系统中多次执行某一个脚本后的进程只有一个（此为$$的企业级应用） 说明：有时执行定时任务脚本的频率比较快，并不知道上一个脚本是否真的执行完毕，但是，业务要求同一时刻只能有一个同样的脚本在运行，此时就可以利用$$获取上一次运行的脚本进程号，当程序重新运行时，根据获得的进程号，清理掉上一次的进程，运行新的脚本命令。脚本如下：123456789#!/bin/shpidpath=/tmp/a.pid #&lt;==定义pid文件if [ -f "$pidpath" ] #&lt;==如附哦pid存在，则执行then后面的命令then kill `cat $pidpath` &gt; /dev/null 2&gt;&amp;1 #&lt;==杀掉与前一个进程号对应的进程 rm -f $pidpath #&lt;==删除pid文件fiecho $$ &gt; $pidpath #&lt;==将当前Shell进程号记录到pid文件里sleep 300 提示：这是一个生产案例的简单模拟，脚本用于执行启动或定时任务时，相同的脚本中只能有一个在运行，当新脚本运行时，必须关闭未完成或未退出的上一次的同名脚本进程。 1.2.3. 关于$_的说明及实践$_的作用是获得上一条命令的最后一个参数值，此功能用的不多，了解即可。示例如下：12345678[theshu@theshu ~]$ echo hellohello[theshu@theshu ~]$ echo $_hello[theshu@theshu ~]$ ll -d /root/dr-xr-x---. 9 root root 4096 Feb 25 17:10 /root/[theshu@theshu ~]$ echo $_/root/ 1.2.4. 关于$!的说明及实践$!的功能类似与$$，只不过作用是获取上一次执行脚本的pid，对此，了解即可。范例如下：12345[theshu@theshu ~]$ ps ef | grep pid.sh | grep -v grep[theshu@theshu ~]$ sh pid.sh &amp;[1] 12077[theshu@theshu ~]$ echo $!12077 2. bash Shell内置变量命令bash Shell包含一些内置命令，它们是由Shell本身提供的。常用的内部命令有：echo、eval、exec、export、read、shift。下面简单介绍几个最常用的内置命令的格式和功能。 2.1. echo在屏幕上输出信息 命令格式：echo args （可以是字符串和变量的组成） 功能说明：将echo命令后面args指定的字符串及变量等显示到标准输出 常用参数见下表： echo参数选项 说明 -n 不换行输出内容 -e 解析转义字符（见下面的字符） 转义字符 \n 换行 \r 回车 \t 制表符（tab） \b 退格 \v 纵向制表符 参数的应用示例：123456789101112131415161718[theshu@theshu ~]$ echo theshu;echo hellotheshuhello[theshu@theshu ~]$ echo -n theshu;echo hello #&lt;==-n不换行输出theshuhello[theshu@theshu ~]$ echo "theshu\ttheshu\ntheshu\ttheshu"theshu\ttheshu\ntheshu\ttheshu[theshu@theshu ~]$ echo -e "theshu\ttheshu\ntheshu\ttheshu" #&lt;==加上-e解析"\"开头的字符theshu theshutheshu theshu[theshu@theshu ~]$ printf "theshu\ttheshu\ntheshu\ttheshu\n"theshu theshutheshu theshu#&lt;==printf的转义字符能力与echo类似[theshu@theshu ~]$ echo -e "1\b23" #&lt;==加上-e解析以"\"开头的字符，\b退格23[theshu@theshu ~]$ printf "1\b23\n" #&lt;==printf的转义字符功能与echo类似23 printf与echo的功能类似，但是printf更强大，当需要特殊复杂的格式时才考虑使用printf。 2.2. eval（后文有案例讲解） 命令格式：eval args 功能：当Shell程序执行到eval语句时，Shell读入参数args，并将它们组合成一个新的命令，然后执行。 范例如下：123456789[theshu@theshu ~]$ cat noeval.shecho \$$#[theshu@theshu ~]$ sh noeval.sh arg1 arg2$2[theshu@theshu ~]$ cat noeval.sheval "echo \$$# "#&lt;==加上eval命令，使得打印的也是位置参数，重新解析输出，而不是输出$2本身。[theshu@theshu ~]$ sh noeval.sh arg1 arg2arg2 #&lt;==输出了$2的值 2.3. exec 命令格式：exec 命令参数 功能：exec命令能够在不创建新的子进程的前提下，转去执行指定的命令，当指定的命令执行完毕后，该进程（也就是最初的Shell）就终止了，示例如下：123[root@theshu ~]# exec dateSun Feb 25 20:24:18 CST 2018[theshu@theshu ~]$ #&lt;==退到普通用户模式下了 当使用exec打开文件后，read命令每次都会将文件指针移动到文件的下一行进行读取，知道文件末尾，利用这个可以实现处理文件内容。exec的功能示例：123456789101112131415[theshu@theshu ~]$ seq 5 &gt; /tmp/tmp.log[theshu@theshu ~]$ cat exec.shexec &lt; /tmp/tmp.log #&lt;==读取log内容while read line #&lt;==利用read一行行读取处理do echo $line #&lt;==打印输出doneecho ok[theshu@theshu ~]$ sh exec.sh12345ok 2.4. read 命令格式：read 变量名列表 功能：从标准输入读取字符串等信息，传给Shell程序内部定义的变量。此命令将在后文详细讲解。 2.5. shift 命令格式：shift Shift positional parameters 功能：shift语句会按如下方式重新命令所有的位置参数变量，即$2成为$1、$3称为$2等，以此类推，在程序中每使用一次shift语句，都会使所有的位置参数一次向左移动一个位置，并使位置参数$#减1，直到减到0为止。 shift功能介绍：123456789[theshu@theshu ~]$ help shiftshift: shift [n] Shift positional parameters. Rename the positional parameters $N+1,$N+2 ... to $1,$2 ... If N is not given, it is assumed to be 1. Exit Status: Returns success unless N is negative or greater than $#. shift命令的主要作用是将位置参数$1、$2等进行左移，即如果位置参数是$3、$2、$1，那么执行一次shift后，$3就变成了$2、$2变成了$1，$1就消失了。 shift命令的使用示例：123456789[theshu@theshu ~]$ cat n.shecho $1 $2if [ $# -eq 2 ];then shift echo $1fi[theshu@theshu ~]$ sh n.sh 1 21 2 #&lt;==这是echo $1 $2的结果2 #&lt;==这里是echo $1的结果，但是输出的是传参时$2的值 应用场景：当我们写Shell希望像命令行的命令通过参数控制不同的功能时，就会先传一个类似-c的参数，然后再接内容。123[theshu@theshu ~]$ sh n.sh -c theshu-c theshu #&lt;==对应$1 $2的输出theshu #&lt;==对应$1的输出，因为执行shift，因此第二个参数$2的内容，就变成了$1 2.6. exit 命令格式：exit Exit the shell 功能：退出Shell程序。在exit之后可以有选择地指定一个数位作为返回状态。 3. Shell变量子串知识及实践3.1. Shell变量子串介绍Shell变量字串的常用操作见下表。可以执行man bash命令之后，搜索Parameter Expansion找到相应的帮助知识，对于Shell新手来说，次部分内容可以暂时忽略，可以学完全部内容之后再学这一部分即可。 序号 表达式 说明 1 ${parameter} 返回变量$parameter的内容 2 ${井parameter} 返回变量$parameter内容的长度（按字符），也适用于特殊变量 3 ${parameter:offset} 在变量${parameter}中，从位置offset之后开始提取字串到结尾 4 ${parameter:offset:length} 在变量${parameter}中，从位置offset之后开始提取长度为length的字串 5 ${parameter#word} 从变量${parameter}开头开始删除最短匹配的word子串 6 ${parameter##word} 从变量${parameter}开头开始删除最长匹配的word子串 7 ${parameter%word} 从变量${parameter}结尾开始删除最短匹配的word子串 8 ${parameter%%word} 从变量${parameter}结尾开始删除最长匹配的word子串 9 ${parameter/pattern/string} 使用string代替第一个匹配的pattern 10 ${parameter//pattern/string} 使用string代替所有匹配的pattern 3.2. Shell变量子串的实践 准备：定义THESHU变量，赋值内容为”I am theshu”，操作代码如下： 12345[theshu@theshu ~]$ THESHU="I am theshu"[theshu@theshu ~]$ echo $&#123;THESHU&#125;I am theshu[theshu@theshu ~]$ echo $THESHUI am theshu 例：返回THESHU变量值的长度。通过在变量名前加#，就可以打印变量值的长度： 12[theshu@theshu ~]$ echo $&#123;井THESHU&#125;11 例：Shell的其它打印变量长度的方法。 123456[theshu@theshu ~]$ echo $THESHU | wc -L11 #&lt;==输出变量值，然后通过管道交给wc计算长度[theshu@theshu ~]$ expr length "$THESHU"11 #&lt;==利用expr的length函数计算变量长度[theshu@theshu ~]$ echo "$THESHU" | awk '&#123;print length($0)&#125;'11 #&lt;==利用awk的length函数计算变量长度，也可无"（$0）"这几个字符 提示：上述计算变量长度的方法中，变量的子串方式是最快的，即${井THESHU} 例：利用time命令及for循环对几种获取字符串长度的方法进行性能比较 变量自带的获取长度的方法（echo ${井char}） 12345[theshu@theshu ~]$ time for n in &#123;1..10000&#125;;do char=`seq -s "theshu" 100`;echo $&#123;#char&#125; &amp;&gt; /dev/null;donereal 0m8.472s #&lt;==变量自带的获取长度的方法用时最少，效率最高user 0m5.331ssys 0m3.099s 利用管道加wc的方法（echo ${cahr} | wc -L） 12345[theshu@theshu ~]$ time for n in &#123;1..10000&#125;;do char=`seq -s "theshu" 100`;echo $&#123;char&#125; | wc -L &amp;&gt; /dev/null;donereal 0m27.965s #&lt;==使用了管道加wc -L计算，结果倒数第二，仅次于管道加awk统计的user 0m15.910ssys 0m11.917s 利用expr自带的length方法（expr length &quot;${char}&quot;） 12345[theshu@theshu ~]$ time for n in &#123;1..10000&#125;;do char=`seq -s "theshu" 100`;expr length "$&#123;cahr&#125;" &amp;&gt; /dev/null;donereal 0m15.283s #&lt;==好于使用管道和wc的计算方法，但是比变量自带的获取长度的方法要差一些user 0m9.217ssys 0m5.990s 利用awk自带的length函数方法 12345[theshu@theshu ~]$ time for n in &#123;1..10000&#125;;do char=`seq -s "theshu" 100`;echo $char | awk '&#123;print length($0)&#125;' &amp;&gt; /dev/null;donereal 0m30.363s #&lt;==使用了管道还有awk的函数计算，结果最差user 0m16.500ssys 0m13.709s 可以看到，这几种方法的速度相差几十到上百倍，一般情况下调用外部命令来处理的方式与使用内置操作的速度相差较大。在Shell编程中，应尽量使用内置操作或函数来完成。 有关获取字符串长度的几种统计方法的性能比较如下： 变量自带的计算长度的方法的效率最高，在要求效率的场景中尽量多用 使用管道统计的方法的效率都比较差，在要求效率的场景中尽量不用 对于日常简单的脚本计算，读者可以根据自己所擅长的或易用的程度去选择 例：截取THESHU变量的内容，从第2个字符之后开始截取，默认截取后面字符的全部，第2个字符不包含在内，也可理解为删除前面的多个字符 1234[theshu@theshu ~]$ echo $&#123;THESHU&#125;I am theshu[theshu@theshu ~]$ echo $&#123;THESHU:2&#125;am theshu #&lt;==相当于从I后面的空格开始计算，截取到了结尾 例：截取THESHU变量的内容，从第2个字符之后开始截取，截取2个字符 12345[theshu@theshu ~]$ echo $&#123;THESHU:2:2&#125;am提示：这个功能类似于cut命令-c参数的功能，如下；[theshu@theshu ~]$ echo $&#123;THESHU&#125; | cut -c 3-4am 例：从变量$THESHU内容的开头开始删除最短匹配&quot;a*C&quot;及&quot;a*c&quot;的子串 1234567[theshu@theshu ~]$ THESHU=abcABC123ABCabc[theshu@theshu ~]$ echo $THESHUabcABC123ABCabc[theshu@theshu ~]$ echo $&#123;THESHU#a*C&#125; #&lt;==从开头开始删除最短匹配"a*C"的子串123ABCabc #&lt;==从开头开始删除了abcABC[theshu@theshu ~]$ echo $&#123;THESHU#a*c&#125;ABC123ABCabc #&lt;==从开头开始删除了abc 例：从变量$THESHU开头开始删除最长匹配&quot;a*C&quot;及&quot;a*c&quot;的子串 1234567[theshu@theshu ~]$ THESHU=abcABC123ABCabc[theshu@theshu ~]$ echo $THESHUabcABC123ABCabc[theshu@theshu ~]$ echo $&#123;THESHU##a*c&#125; #&lt;==从开头开始删除最长匹配"a*c"的子串 #&lt;==结果为空了，说明都匹配了，全部都删除了[theshu@theshu ~]$ echo $&#123;THESHU##a*C&#125; #&lt;==从开头开始删除最长匹配"a*C"的子串abc #&lt;==结果为abc，说明匹配了abcABC123ABC并删除了这些字符 例：从变量$THESHU结尾开始删除最短匹配&quot;a*C&quot;及&quot;a*c&quot;的子串 1234567[theshu@theshu ~]$ THESHU=abcABC123ABCabc[theshu@theshu ~]$ echo $THESHUabcABC123ABCabc[theshu@theshu ~]$ echo $&#123;THESHU%a*C&#125; #&lt;==从结尾开始删除最短匹配"a*c"的子串abcABC123ABCabc #&lt;==原样输出，因为从结尾开始"a*C"没有匹配上任何子串，因此，没有删除任何字符[theshu@theshu ~]$ echo $&#123;THESHU%a*c&#125; #&lt;==从结尾开始删除最短匹配"a*c"的子串abcABC123ABC #&lt;==从结尾开始删除最短匹配"a*c"，即删除了结尾的abc三个字符 例：从变量$THESHU结尾开始删除最长匹配&quot;a*C&quot;及&quot;a*c&quot;的子串 1234567[theshu@theshu ~]$ THESHU=abcABC123ABCabc[theshu@theshu ~]$ echo $THESHUabcABC123ABCabc[theshu@theshu ~]$ echo $&#123;THESHU%%a*C&#125; #&lt;==从结尾开始删除最长匹配"a*C"的子串abcABC123ABCabc #&lt;==原样输出，因为从结尾开始"a*C"没有匹配上任何子串，因此，没有删除任何字符[theshu@theshu ~]$ echo $&#123;THESHU%%a*c&#125; #&lt;==从结尾开始删除最长匹配"a*c"的子串 #&lt;==从结尾开始删除最长匹配"a*C"的字符串，即删除全部字符 有关上述匹配删除的小结： #表示从开头删除匹配最短 ##表示从开头删除匹配最长 %表示从结尾删除匹配最短 %%表示从结尾删除匹配最长 a*C表示匹配的字符串，*表示匹配所有，a*C匹配开头为a、中间为任意多个字符、结尾为C的字符串 a*c表示匹配的字符串，*表示匹配所有，a*c匹配开头为a、中间为任意多个字符、结尾为c的字符串 例：使用thewang字符代替变量$THESHU匹配的theshu字符串 1234567[theshu@theshu ~]$ THESHU="I am theshu,yes,theshu"[theshu@theshu ~]$ echo $THESHUI am theshu,yes,theshu[theshu@theshu ~]$ echo $&#123;THESHU/theshu/thewang&#125; #&lt;==替换匹配的第一个字符串I am thewang,yes,theshu[theshu@theshu ~]$ echo $&#123;THESHU//theshu/thewang&#125; #&lt;==替换匹配的所有字符串I am thewang,yes,thewang 有关替换的小结： 一个/表示替换匹配的第一个字符串 两个/即//表示替换匹配的所有字符串 3.3. 变量子串的生产场景应用案例可以用来批量修改文件名：假如本目录里有一些文件，这些文件的名字当中都有theshu这个字符串，批量修改去掉它：1# for f in `ls *theshu*`;do mv $f `echo $&#123;f//theshu/&#125;`;done 4. Shell特殊扩展变量的知识与实践4.1. Shell特殊扩展变量介绍Shell的特殊扩展变量说明见下表，也可以执行man bash命令，然后搜索Parameter Expansion查找相关的帮助内容。 表达式 说明 ${parameter:-word} 如果parameter的变量值为空或未赋值，则会返回word字符串并替代变量的值。用途：如果变量未定义，则返回备用的值，防止变量为空值或因未定义而导致异常 ${parameter:=word} 如果parameter的变量值为空或未赋值，则设置这个变量值为word，并返回其值。位置变量和特殊变量不适用。用途：基本上同一个${parameter:-word}，但该变量又额外给parameter变量赋值了 ${parameter:?word} 如果parameter变量值为空或未赋值，那么word字符串将被作为标准错误输出，否则输出变量的值。用途：用于捕捉由于变量未定义而导致的错误，并退出程序 ${parameter:+word} 如果parameter变量值为空或未赋值，则什么都不做，否则word字符串将替代变量的值 在上表中，每个表达式内的冒号都是可选的。如果省略了表达式中的冒号，则将每个定义中的为空或未赋值部分改为未赋值，也就是说，运算符仅用于测试变量是否未赋值。 4.2. Shell特殊扩展变量的实践4.2.1. ${parameter:-word}功能实践${parameter:-word}的作用是如果parameter变量值为空或未赋值，则会返回word字符串替代变量的值。 示例1：1234567[root@theshu ~]# echo $test #&lt;==变量未设置，所以输出时为空[root@theshu ~]# result=$&#123;test:-UNSET&#125; #&lt;==若test没值，则返回UNSET[root@theshu ~]# echo $result #&lt;==打印result变量，返回UNSET，因为test没有赋值UNSET[root@theshu ~]# echo $&#123;test&#125; #&lt;==注意，此时打印test变量还是为空 结论：对于${test:-UNSET}，当test变量没有值时，就返回变量结尾设置的UNSET字符串。 示例2：12345678910[root@theshu ~]# test=theshu #&lt;==给test变量赋值theshu字符串[root@theshu ~]# echo $testtheshu[root@theshu ~]# result=$&#123;test:-UNSET&#125; #&lt;==重新定义result[root@theshu ~]# echo $resulttheshu #&lt;==因为test已赋值，因此，打印result就输出了test的值theshu，而不是原来的UNSET[root@theshu ~]# result=$&#123;test-UNSET&#125;#&lt;==提示：这个变量的功能可以用来判断变量是否已定义[root@theshu ~]# echo $result #&lt;==定义时忽略了冒号theshu 结论：当test有值时，就打印result变量，返回test变量的内容。 4.2.2. ${parameter:=word}功能实践${parameter:=word}的作用是：如果parameter变量值为空或未赋值，就设置这个变量值为word，并返回其值。位置变量和特殊变量不适用。 示例：12345678910111213141516[root@theshu ~]# unset result #&lt;==撤销result变量定义[root@theshu ~]# echo $result[root@theshu ~]# unset test #&lt;==撤销test变量定义[root@theshu ~]# echo $test[root@theshu ~]# result=$&#123;test:=UNSET&#125; #&lt;重新对变量result进行定义[root@theshu ~]# echo $resultUNSET[root@theshu ~]# echo $testUNSET #&lt;==注意，这里的test原来是没有定义的，现在已经被赋值UNSET了，这是和":-"表达式的区别[root@theshu ~]# result=$&#123;test=UNSET&#125; #&lt;==定义时忽略了冒号[root@theshu ~]# echo $resultUNSET #&lt;==打印结果和带冒号时没有变化[root@theshu ~]# echo $testUNSET #&lt;==打印结果和带冒号时没有变化 当变量result值里的变量test值没有定义时，会给变量result赋值:=后面的内容，同时会把:=后面的内容赋值给变量result值里没有定义的变量test。 这个变量的功能可以解决变量没有定义的问题，并确保没有定义的变量始终有值。 4.2.3. ${parameter:?word}功能实践${parameter:?word}的作用是：如果parameter变量值为空或未赋值，那么word字符串将被作为标准错误输出，否则输出变量的值。 范例：12345678910111213[root@theshu ~]# echo $&#123;key:?not defined&#125;-bash: key: not defined #&lt;==错误提示，只不过是事先定义好的错误输出#&lt;==key变量没有定义，因此，把"not defined"最为标准错误输出[root@theshu ~]# echo $&#123;key?not defined&#125; #&lt;==去掉冒号定义，并输出，结果一致-bash: key: not defined[root@theshu ~]# key=1 #&lt;==给变量赋值1[root@theshu ~]# echo $&#123;key:?not defined&#125; 1 #&lt;==因为key有值了，所以，打印key的值1[root@theshu ~]# echo $&#123;key?not defined&#125;1 #&lt;==去掉冒号定义，并输出，结果一致[root@theshu ~]# unset key #&lt;==取消key的定义[root@theshu ~]# echo $&#123;key:?not defined&#125; #&lt;==由打印错误提示了-bash: key: not defined 本例的用法可以用于设定由于变量未定义而报错的具体内容，如：”not defined”。 4.2.4. ${parameter:+word}功能实践${parameter:+word}的作用是：如果parameter变量值为空或未赋值，则什么都不做，否则word字符串将替代变量的值。 范例：1234567[root@theshu ~]# theshu=$&#123;wang:+word&#125; #&lt;==wang变量未定义[root@theshu ~]# echo $theshu #&lt;==因为wang变量未定义，所以打印theshu变量值为空[root@theshu ~]# wang=20 #&lt;==wang变量赋值为20[root@theshu ~]# theshu=$&#123;wang:+word&#125; #&lt;==注意，这里一定要重新定义theshu[root@theshu ~]# echo $theshuword #&lt;==因为wang变量有值，所以打印theshu变量输出为`:+`后面的内容 此功能可用于测试变量（wang的位置）是否存在，如果theshu的值为word，则证明wang变量有值。 4.3. Shell特殊扩展变量的生产场景应用案例一个生产案例：删除7天前的过期的数据备份： 如果忘记了定义path变量，又不希望path值为空值，就可以定义/tmp替代path空值的返回值，如下： 123456[root@theshu ~]# cat del.shfind $&#123;path-/tmp&#125; -name "*.tar.gz" -type f -mtime +7 | xargs rm -f[root@theshu ~]# sh -x del.sh+ find /tmp -name '*.tar.gz' -type f -mtime +7 + xargs rm -f#&lt;==执行时，系统会自动删除/tmp下的文件 如果忘了定义path变量，并且还未做特殊变量定义，那么命令就会出现意外，如下： 12345[root@theshu ~]# cat a.shfind $&#123;path&#125; -name "*.tar.gz" -type f -mtime +7 | xargs rm -f[root@theshu ~]# sh -x a.sh+ find -name '*.tar.gz' -type f -mtime +7 #&lt;==这条命令明显没有指定路径，因此将会导致异常+ xargs rm -f OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记03-Shell变量的核心基础知识]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F005.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B003-Shell%E5%8F%98%E9%87%8F%E7%9A%84%E6%A0%B8%E5%BF%83%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[GO 1. 什么是Shell变量1.1. 什么是变量简单地说，变量就是用一个固定的字符串（也可能是字符、数字等的组合）代替更多、更复杂的内容，该内容里可能还会包含变量、路径、字符串等其它的内容。 变量是暂时存储数据的地方及数据标记，所存储的数据存在于内存空间中，通过正确地调用内存空间中变量的名字就可以取出与变量对应的数据。使用变量的最大好处就是使程序开发更为方便，当然，在编程中使用变量也是必须的，否则就很难完成相关的程序开发工作。 下面是定义变量和打印变量的示例：123[root@theshu ~]# theshu="I am theshu" #&lt;==定义变量，名字为theshu，对应的内容为"I am theshu"[root@theshu ~]# echo $theshu #&lt;==打印变量的值I am theshu 变量的赋值方式为：变量名=值，中间没有任何空格，通过echo命令加上$变量名即可输出变量的值，变量的内容一般要加双引号，以防止出错，特别是当值里的内容之间有空格时。 1.2. Shell变量的特性默认情况下，在bash Shell中是不会区分变量类型的，例如：常见的变量类型为整数、字符串、小数等。这和其它强类型语言（例如： Java/C语言）是有区别的，当然，如果需要指定Shell变量的类型，也可以使用declare显示定义变量的类型，但在一般情况下没有这个需求，Shell开发者在开发脚本时需要自行注意Shell脚本中变量的类型，这对新手来说是个重点也是个难点。 1.3. 变量类型变量可分为两类：环境变量（全局变量）和普通变量（局部变量）。 环境变量也可称为全局变量，可以在创建它们的Shell及其派生出来的任意子进程Shell中使用，环境变量又可分为自定义环境变量和bash内置的环境变量。 普通变量也可称为局部变量，只能在创建它们的Shell函数或Shell脚本中使用。普通变量一般由开发脚本程序时创建。 2. 环境变量环境变量一般是指使用export内置命令导出的变量，用于定义Shell的运行环境，保证Shell命令的正确执行。Shell通过环境变量来确定登录用户名、命令路径、终端类型、登陆目录等，所有的环境变量都是系统全局变量，可用于所有子进程中，这包括编辑器，Shell脚本和各类应用。 环境变量可以在命令行中设置和创建，但用户退出命令行时这些变量值就会丢失，因此，如果希望永久保存环境变狼，可以在用户家目录下的.bash_profile或.bashrc（非用户登陆模式特有，例如远程SSH）文件中，或者全局配置/etc/bashrc（非用户登陆模式特有，例如远程SSH）或/etc/profile文件中定义。在将环境变量放入上述的文件中后，每次用户登陆时这些变量都将被初始化。 按照系统规范，所有环境变量的名字均采用大写形式。在将环境变量应用于用户进程程序之前，都应该用export命令导出定义，例如：正确的环境变量定义方法为：export OLDGIRL=1 有一些环境变量，比如HOME、PATH、SHELL、UID、USER等，在用户登陆之前就已经被/bin/login程序设置好了。通常环境变量被定义并保存在用户家目录下的.bash_profile文件或全局的配置文件/etc/profile中。 在查看设置的变量时，有3个命令可以显示变量的值：set、env、declare（替代早期的typeset）。 set命令输出所有的变量，包括全局变量和局部变量； env命令只显示全局变量； declare命令输出所有的变量、函数、整数和已经导出的变量。 set -o命令显示bash Shell的所有参数配置信息。 例子：set、env和declare输出：1234567891011121314151617181920212223242526272829303132333435[root@theshu ~]# env | tailMAIL=/var/spool/mail/rootPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/binPWD=/rootLANG=en_US.UTF-8HISTCONTROL=ignoredupsSHLVL=1HOME=/rootLOGNAME=rootLESSOPEN=||/usr/bin/lesspipe.sh %s_=/bin/env[root@theshu ~]# declare | tailSHELLOPTS=braceexpand:emacs:hashall:histexpand:history:interactive-comments:monitorSHLVL=1TERM=xtermUID=0USER=rootXDG_SESSION_ID=3340_=colors=/root/.dircolorstheshu='I am theshu'userdir=/root[root@theshu ~]# set -o | headallexport offbraceexpand onemacs onerrexit offerrtrace offfunctrace offhashall onhistexpand onhistory onignoreeof off 2.1. 自定义环境变量2.1.1. 设置环境变量利用export命令和declare命令设置环境变量的三种方法： export 变量名=值 变量名=值 ； export 变量名 declare -x 变量名=值 下面介绍让环境变量永久生效的常用设置文件。 用户的环境变量配置：~/.bashrc（推荐在此文件中优先设置）和~/.bash_profile 全局环境变量的配置：/etc/profile、/etc/bashrc（推荐在此文件中优先设置）和/etc/profile.d/ 若要在登陆后初始化或显示加载内容，则把脚本文件放在/etc/profile.d/下即可（无需加执行权限）。 2.1.2. 设置登陆提示的两种方式第一种是在/etc/motd里增加提示的字符串，如下：123[root@theshu ~]# cat /etc/motdWelcome to Alibaba Cloud Elastic Compute Service ! 登录后显示内容如下：123456login as: theshuAuthenticating with public key "rsa-key-20171224"Passphrase for key "rsa-key-20171224":Last login: Sat Feb 24 10:39:52 2018 from 116.117.102.109Welcome to Alibaba Cloud Elastic Compute Service ! 第二种是在/etc/profile.d/下面增加如下脚本：12[root@theshu ~]# cat /etc/profile.d/theshu.sh #&lt;==这里是脚本的内容echo " Here is theshu training " 以下是在生产场景下（在Java环境中），自定义环境变量的实例：1234export JAVA_HOME=/application/jdkexport CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/libexport PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH:$HOME/binexport RESIN_HOME=/application/resin 提示：上述的环境变量设置通常放在/etc/profile全局环境变量里。如果是写Java的脚本，那么最好是把上述Java环境配置放入脚本内重新定义，特别是作为定时任务执行的脚本。 2.2. 显示与取消环境变量2.2.1. 通过echo或printf命令打印环境变量下面来查看一下常见的系统环境变量： $HOME：用户登陆时进入的目录 $UID：当前用户的UID（用户标识），相当于id-u $PWD：当前工作目录的绝对路径名 $SHELL：当前SHELL $USER：当前用户 …… 通过echo和printf命令打印环境变量：12345678910111213[root@theshu ~]# echo $HOME/root[root@theshu ~]# echo $UID0[root@theshu ~]# echo $PWD/root[root@theshu ~]# echo $SHELL/bin/bash[root@theshu ~]# echo $USERroot[root@theshu ~]# printf "$HOME\n"/root#&lt;==printf是一个更复杂的格式化打印内容的工具，一般不需要 提示：在写Shell脚本时可以直接使用系统默认的环境变量，一般情况下是不需要重新定义的，在使用定时任务等执行Shell脚本时建议在脚本中重新定义。 2.2.2. 用env或set显示默认的环境变量用env（printenv）显示默认环境变量的示例如下：12345678910111213141516XDG_SESSION_ID=3413HOSTNAME=theshuSHELL=/bin/bashTERM=xtermHISTSIZE=1000USER=rootMAIL=/var/spool/mail/rootPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/binPWD=/rootLANG=en_US.UTF-8HISTCONTROL=ignoredupsSHLVL=1HOME=/rootLOGNAME=rootLESSOPEN=||/usr/bin/lesspipe.sh %s_=/bin/env 用set也可以显示环境变量（包括局部变量），如下：123456789[root@theshu ~]# setBASH=/bin/bashBASHOPTS=checkwinsize:cmdhist:expand_aliases:extquote:force_fignore:histappend:hostcomplete:interactive_comments:login_shell:progcomp:promptvars:sourcepathBASH_ALIASES=()BASH_ARGC=()BASH_ARGV=()BASH_CMDS=()BASH_LINENO=()一下内容省略... 2.2.3. 用unset消除本地变量和环境变量用unset消除本地变量和环境变量的示例如下：12345[root@theshu ~]# echo $USERroot[root@theshu ~]# unset USER[root@theshu ~]# echo $USER #&lt;==可以看到此处为空 2.2.4. 环境变量的知识小结： 变量名通常要大写 变量可以在自身的Shell及子Shell中使用 常用export来定义环境变量 执行env默认可以显示所有的环境变量名称及对应的值 输出时用$变量名，取消时用unset 变量名 书写crond定时任务时要注意，脚本要用到的环境变量最好先在所执行的Shell脚本中重新定义 如果希望环境变量永久生效，则可以将其放在用户环境变量文件或全局环境变量文件里 2.3. 环境变量初始化与对应文件的生效顺序在登陆Linux系统并启动一个bash shell时，默认情况下bash会在若干个文件中查找环境变量的设置。这些文件可统称为系统环境文件。bash检查的环境变量文件的情况取决于系统运行Shell的方式。系统运行Shell的方式一般有3种： 通过系统用户登陆后默认运行的Shell 非登陆交互式运行Shell 执行脚本运行非交互式Shell 当用户登陆Linux系统时，Shell会作为登陆Shell启动。此时的登陆Shell加载环境变量的顺序如下图所示： 用户登陆系统后首先会加载/etc/profile全局环境变量文件，这是Linux系统上默认的Shell主环境变量文件。系统上每个用户登陆都会加载这个文件。 当加载完/etc/profile文件后，才会执行/etc/profile.d/目录下的脚本文件，这个目录下的脚本文件有很多，例如：系统的字符集设置（/etc/sysyconfig/i18n）等，再比如开发跳板机时，我们也把脚本的起始加载放到这个目录下，以便用户登陆后即可运行脚本。 之后开始运行~/.bash_profile（用户环境变量文件），在这个文件中，又会去找~/.bashrc（用户环境变量文件），如果有，则执行，如果没有，则不执行。在~/.bashrc文件中又会去找/etc/bashrc（全局环境变量文件），如果有，则执行，如果没有，则不执行。 如果用户的Shell不是登陆时启动的（比如手动敲下bash时启动或者其它不需要输入密码的登陆及远程SSH连接情况），那么这种非登陆Sheel只会加载~/.bashrc（用户环境变量文件），并会去找/etc/bashrc（全局环境变量文件）。因此如果希望在非登陆Shell下也可读到设置的环境变量等内容，就需要将变量设定等写入~/.bashrc或者/etc/bashrc，而不是~/.bash_profile或/etc/profile。 3. 普通变量3.1. 定义本地变量本地变量在用户当前Shell生存期的脚本中使用。 3.1.1. 普通变量定义为普通变量的定义赋值，一般有以下3种写法： 变量名=值 赋值时不加引号 变量名=&#39;值&#39; 赋值时不加单引号 变量名=&quot;值&quot; 赋值时加双引号 3.1.2. 在Shell中定义变量名及为变量内容赋值的要求变量名一般是由字母、数字、下划线组成的，可以以字母或下划线开头，例如：theshu、theshu123、theshu_wang。 变量的内容可以用单引号或双引号引起来，也可不加引号，但是这三者的含义是不同的，具体参见后文。 3.1.3. 普通变量的定义及输出的示例例子1：采用不同的方式对普通变量进行定义，并一一打印输出：123456a=192.168.1.2b='192.168.1.2'c="192.168.1.2"echo "a=$a"echo "b=$b"echo "c=$&#123;c&#125;" 提示：$变量名表示输出变量，可以用$c和${c}两种方法。 例子1的输出结果如下：123a=192.168.1.2b=192.168.1.2c=192.168.1.2 可见，将连续的普通字符串的内容赋值给变量，不管用不用引号，或者不管用什么引号，它的内容是什么，打印变量时就会输出什么。 例子2：接着例子1的结果，再在Linux命令行下继续输入如下内容，a、b、c的输出结果又各是什么呢？123456a=192.168.1.2-$ab='192.168.1.2-$a'c="192.168.1.2-$a"echo "a=$a"echo "b=$b"echo "c=$&#123;c&#125;" 答案如下：123a=192.168.1.2-192.168.1.2b=192.168.1.2-$ac=192.168.1.2-192.168.1.2-192.168.1.2 3.1.4. 变量定义的基本技巧总结在这里以上面的例子2来说明： 第一种：a=192.168.1.2-$a。这种定义变量的方式是不加任何引号直接定义变量的内容，当内容为简单连续的数字、字符串、路径名时，可以这样用，例如：a=1，b=theshu等。不加引号时，值里有变量的会被解析后再输出，上述变量定义中因为$a的被解析为192.168.1.2，因此新的a值就是192.168.1.2-192.168.1.2 第二种：b=&#39;192.168.1.2-$a&#39;。这种定义变量的方式是通过单引号定义。这种定义方式的特点是：输出变量内容时单引号里是什么就输出什么，即使内容中有变量和命令（命令需要反引起来）也会把它们原样输出。这种方式比较适合于定义显示纯字符串的情况，即不希望解析变量、命令等的场景，因此，对于这里的b的值，定义时看到的是什么就输出什么，即：192.168.1.2-$a。 第三种：c=&quot;192.168.1.2-$a&quot;。这种定义变量的方式是通过双引号定义变量。这种定义方式的特点是：输出变量内容时引号里的变量及命令会经过解析后再输出内容，而不是把双引号中的变量名及命令（命令需要反引起来）原样输出。这种方式比较适合于字符串中附带有变量及命令且想将其解析后再输出的变量定义。 经验：数字内容的变量定义可以不加引号，其他没有特别要求的字符串等定义最好都加上双引号，如果真的需要原样输出就加单引号，定义变量加双引号是最常见的使用方式。 3.1.5. 把一个命令的结果作为变量的内容赋值的方法对需要获取命令结果的变量内容赋值的常见方法有两种：12变量名=`ls` #&lt;==把命令用反引号引起来，不推荐使用这种方法，因为容易和单引号混淆变量名=$(ls) #&lt;==把命令用$()括起来，推荐使用这种方法 例子1：用两种方法把命令的结果赋值给变量：12345678[theshu@theshu ~]$ ls1.txt hello.c hello.sh vimrc[theshu@theshu ~]$ CMD=`ls`[theshu@theshu ~]$ echo $CMD1.txt hello.c hello.sh vimrc[theshu@theshu ~]$ CMD1=$(pwd)[theshu@theshu ~]$ echo $CMD1/home/theshu 提示：生产场景中把命令的结果作为变量的内容进行复制的方法在脚本开发时很常见。 3.1.6. 局部（普通）变量定义及赋值的经验小结常规普通变量定义： 若变量内容为连续的数字或字符串，赋值时，变量内容两边可以不加引号，例如a=123 变量的内容很多时，如果有空格且希望解析内容中的变量，就加双引号，例如a=&quot;/etc/rc.local $USER&quot;，此时输出变量会对内容中的$USER进行解析然后再输出。 希望原样输出变量中的内容时就用单引号引起内容进行赋值，例如a=&#39;$USER&#39;。 希望变量的内容是命令的解析结果的定义及赋值如下： 要使用反引号将赋值的命令括起来；或者用$()括起来，例如：a=$(ls) 变量的输出方法如下： 使用$变量名即可输出变量的内容，常用echo $变量名的方式，也可用printf代替echo输出更复杂的格式内容。 变量定义的技巧及注意事项： 注意命令变量内容前后的字符（即反引号） 在变量名前加$可以取得该变量的值，使用echo或printf命令可以显示变量的值，$A和${A}的写法不同，但效果是一样的。 用echo等命令输出变量的时候，也可以用单引号、双引号、反引号，例如：echo $A、echo &quot;$A&quot;、echo &#39;$A&#39;，它们的用法和前面变量内容定义的总结是一致的。 $dbname_tname，当变量后面连接有其它字符的时候，必须给变量加上大括号{}，例如：$dbname_tname就要改成${dbname}_tname。 3.2. 变量定义及变量输出说明有关Shell变量定义、赋值及变量输出加单引号、双引号、反引号与不加引号的简要说明如下表： 命令 解释 单引号 所见即所得，即输出时会将单引号内的所有内容都原样输出，或者描述为单引号里面看到的是什么就会输出什么，这称为强引用 双引号（默认） 输出双引号内的所有内容；如果内容中有命令（要反引下）、变量、特殊转义符等，会先把变量、命令、转义字符解析出结果，然后再输出最终内容，推荐使用，这称为弱引用 无引号 赋值时，如果变量内容中有空格，则会造成赋值不完整。而在输出内容时，会将含有空格的字符串视为一个整体来输出；如果内容中有命令（要反引下）、变量等，则会先把变量、命令解析出结果，然后输出最终内容；如果字符串中带有空格等特殊字符，则有可能无法完整地输出，因此需要改加双引号。一般连续的字符串、数字、路径等可以不加任何引号进行赋值和输出，不过最好是用双引号替代无引号的情况，特别是对变量赋值时 反引号 反引号一般用于引用命令，执行的时候命令会被执行，相当于$()，赋值和输出都要用反引号将命令引起来 提示：这里仅为Linux Shell下的结论，对于awk语言会有点特别。下文示例中会有说明。 高手前辈的建议是： 在脚本中定义普通字符串变量时，应尽量把变量的内容用双引号括起来 单纯数字的变量内容可以不加引号 希望变量内容原样输出时需要加单引号 希望变量值引用命令并获取命令的结果时就用反引号或$() 3.3. 单引号、双引号与不加引号的实战演示 例子1：对由反引号引起来的date命令或$(date)进行测试。 1234567891011121314[theshu@theshu ~]$ echo 'today is date'today is date[theshu@theshu ~]$ echo 'tody is `date`'tody is `date`[theshu@theshu ~]$ echo "today is date"today is date[theshu@theshu ~]$ echo "today is `date`"today is Sun Feb 25 12:13:42 CST 2018[theshu@theshu ~]$ echo "today is $(date)" #&lt;==对于连续的字符串等内容输出 一般可以不加引号，但加双引号比较保险，所以推荐使用today is Sun Feb 25 12:13:59 CST 2018[theshu@theshu ~]$ echo today is $(date) #&lt;==带空格的内容不加引号，同样可 以正确地输出，但不建议这么做today is Sun Feb 25 12:14:09 CST 2018 例子2：变量定义后，在调用变量输出打印时加引号测试。 1234567[theshu@theshu ~]$ OLDBOY=testchars[theshu@theshu ~]$ echo $OLDBOYtestchars[theshu@theshu ~]$ echo '$OLDBOY'$OLDBOY[theshu@theshu ~]$ echo "$OLDBOY"testchars 例子3：使用三剑客中的grep过滤字符串时给过滤的内容加引号。 123456789[theshu@theshu ~]$ cat grep.log #&lt;==待测试的内容，THESHU变量值为theshutestcharstheshu[theshu@theshu ~]$ grep "$THESHU" grep.logtheshu[theshu@theshu ~]$ grep '$THESHU' grep.log[theshu@theshu ~]$ grep $THESHU grep.log #&lt;==同双引号的情况， 但不建议这样使用，没有特殊需求时应一律加双引号theshu 例子4：使用awk调用Shell中的变量，分别针对加引号、不加引号等情况进行测试。 首先在给Shell中的变量赋值时不加任何引号，这里使用awk输出测试结果：123456789101112[theshu@theshu ~]$ ETT=123 #&lt;==定义变量ETT并赋值123，没加引号[theshu@theshu ~]$ awk 'BEGIN &#123;print "$ETT"&#125;'$ETT#&lt;==加双引号引用$ETT，却只输出了本身，这个就不符合前文的结论了[theshu@theshu ~]$ awk 'BEGIN &#123;print $ETT&#125;'#&lt;==不加引号的￥ETT，又输出了空的结果，这个也不符合前文的结论[theshu@theshu ~]$ awk 'BEGIN &#123;print '$ETT'&#125;'123#&lt;==加单引号引用$ETT，成功输出解析后的结果，这个也不符合前文的结论[theshu@theshu ~]$ awk 'BEGIN &#123;print "'$ETT'"&#125;'123 以上结果正好与前面的结论相反，这是awk调用Shell变量的特殊用法。 然后在给Shell中的变量赋值时加单引号，同样使用awk输出测试结果：12345678910111213[theshu@theshu ~]$ ETT='theshu' #&lt;==定义变量ETT并赋值theshu，加单引号[theshu@theshu ~]$ awk 'BEGIN &#123;print "$ETT"&#125;'$ETT#&lt;==加双引号引用$ETT，输出本身[theshu@theshu ~]$ awk 'BEGIN &#123;print $ETT&#125;'#&lt;==对$ETT不加引号，输出空的结果[theshu@theshu ~]$ awk 'BEGIN &#123;print '$ETT'&#125;'#&lt;==加单引号引用$ETT，也是输出空的结果，这个和前文的不加引号定义、赋值的结果又不一样[theshu@theshu ~]$ awk 'BEGIN &#123;print "'$ETT'"&#125;'theshu#&lt;==在单引号外再加一层双引号引用$ETT，则输出解析后的结果 接着在给Shell中的变量赋值时加双引号，也使用awk输出测试结果：1234567891011121314[theshu@theshu ~]$ ETT="theshu" #&lt;==定义变量ETT并赋值theshu，加双引号 这个测试结果同单引号的情况。[theshu@theshu ~]$ awk 'BEGIN &#123;print "$ETT"&#125;'$ETT#&lt;==加双引号引用$ETT，会输出本身[theshu@theshu ~]$ awk 'BEGIN &#123;print $ETT&#125;'#&lt;==不加引号的$ETT，会输出空的结果[theshu@theshu ~]$ awk 'BEGIN &#123;print '$ETT'&#125;'#&lt;==加单引号的$ETT，会输出空的结果[theshu@theshu ~]$ awk 'BEGIN &#123;print "'$ETT'"&#125;'theshu#&lt;==在单引号外部再加双引号引用$ETT，会输出正确结果 最后在给Shell中的变量赋值时加反引号引用命令，同样使用awk输出测试结果：123456789101112131415[theshu@theshu ~]$ ETT=`pwd` #&lt;==定义变量ETT并赋值pwd命令，加反引号，这个测试结果更特殊[theshu@theshu ~]$ echo $ETT/home/theshu[theshu@theshu ~]$ awk 'BEGIN &#123;print "$ETT"&#125;'$ETT#&lt;==加双引号引用$ETT，会输出本身[theshu@theshu ~]$ awk 'BEGIN &#123;print $ETT&#125;'#&lt;==不加引号引用$ETT，会输出空格结果[theshu@theshu ~]$ awk 'BEGIN &#123;print '$ETT'&#125;'0#&lt;==单引号引用$ETT，会输出错误的结果[theshu@theshu ~]$ awk 'BEGIN &#123;print "'$ETT'"&#125;'/home/theshu#&lt;==在单引号外部再加双引号引用$ETT，会输出正确的结果 结论：不管变量如何定义、赋值，除了加单引号以外，利用awk直接获取变量的输出，结果都是一样的，因此，在awk取用Shell变量时，我们更多的还是喜欢先用echo $变量输出变量，然后通过管道给awk，进而控制变量的输出结果。举例如下：1234567891011121314151617[theshu@theshu ~]$ ETT="theshu" #&lt;==最常规的赋值语法[theshu@theshu ~]$ echo "$ETT" | awk '&#123;print $0&#125;'theshu#&lt;==用双引号引用$ETT[theshu@theshu ~]$ echo '$ETT' | awk '&#123;print $0&#125;'$ETT#&lt;==用单引号引用$ETT[theshu@theshu ~]$ echo $ETT | awk '&#123;print $0&#125;'theshu#&lt;==不加引号引用$ETT[theshu@theshu ~]$ ETT=`pwd` #&lt;==命令赋值的语法[theshu@theshu ~]$ echo "$ETT" | awk '&#123;print $0&#125;'/home/theshu[theshu@theshu ~]$ echo '$ETT' | awk '&#123;print $0&#125;'$ETT[theshu@theshu ~]$ echo $ETT | awk '&#123;print $0&#125;'/home/theshu 这就符合前面给出的普通情况的结论了。下面再来用sed测试一下指定变量关键字的过滤：12345678910[theshu@theshu ~]$ cat sed.logtestcharstheshu[theshu@theshu ~]$ sed -n /"$THESHU"/p sed.log #&lt;==加双引号测试theshu[theshu@theshu ~]$ sed -n /$THESHU/p sed.log #&lt;==不加引号测试theshu[theshu@theshu ~]$ sed -n /'$THESHU'/p sed.log #&lt;==加单引号测试#&lt;==注意，这里是输出本身，但是文件里没有与本身匹配的字符串，因此输出为空 所以得到结论，sed和grep的测试和前面的结论是相符的，唯有awk有些特殊。 3.4. 关于定义普通字符串变量的建议 内容是纯数字、简单的连续字符（内容中不带有任何空格）时，定义时可以不加任何引号，例如：theshuAge=24 没有特殊情况时，字符串一律用双引号定义赋值，特别是多个字符串中间有空格时，例如：myName=&quot;Theshu is a handsome boy.&quot; 当变量里的内容需要原样输出时，要用单引号，这样的需求极少，例如：THESHU_NAME=&#39;theshu&#39; 4. 变量定义技巧总结可以多学习和模仿操作系统自带的/etc/init.d/functions函数库脚本的定义思路，多学习Linux系统脚本中的定义，有经验的话最终应形成一套适合自己的规范和习惯。 变量名及变量内容定义小结 变量名只能为字母、数字或下划线，只能以字母或下划线开头。 变量名的定义要有一定的规范，并且要见名知意。建议用驼峰命名法。 一般的变量定义、赋值常用双引号；简单连续的字符串可以不加引号；希望原样输出时使用单引号。 希望变量的内容是命令的解析结果时，要用反引号，或者用$()把命令括起来再赋值。 Shell定义变量时使用=的知识 a=1里等号是赋值的意思；比较变量是否相等时也可以用=或==。 打印输出及使用变量的知识 打印输出或使用变量时，变量名前要接$符号；变量名后面紧接其它字符的时候，要用大括号将变量部分单独括起来，以防止出现金庸新著的问题；在unset、export、(())等场景中使用但不打印变量时不加$，这个有些例外。 打印输出或使用变量时，一般加双引号或不加引号；如果是字符串变量，最好加双引号；希望原样输出时使用单引号。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记02-Shell脚本初步入门]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F004.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B002-Shell%E8%84%9A%E6%9C%AC%E5%88%9D%E6%AD%A5%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[GO 1. 什么是ShellShell是一个命令解释器，它的作用是解释执行用户输入的命令及程序，用户每输入一条命令，Shell就解释执行一条。这种从键盘一直输入命令，就可以立即得到回应的对话方式，称为交互的方式。 Shell存在于操作系统的最外层，负责与用户直接对话，把用户的输入解释给操作系统，并处理各种各样的操作系统的输出结果，然后输出到屏幕返回给用户。输入系统用户名和密码并登陆到Linux后的所有操作都是由Shell解释与执行的。 2. 什么是Shell脚本当命令或程序语句不在命令行下执行，而是通过一个程序文件来执行时，该程序就被称为Shell脚本。如果在Shell脚本里内置了很多条命令、语句及循环控制，然后将这些命令一次性执行完毕，这种通过文件执行脚本的方式称为非交互的方式。用户可以在Shell脚本中敲入一系列的命令及命令语句组合。这些命令、变量和流程控制语句等有机地结合起来，就形成了一个功能强大的Shell脚本。 下面是一个Shell脚本的例子：清除/var/log下messages日志文件的简单命令脚本：123cd /var/logcat /dev/null &gt; messagesecho "Logs cleaned up." 3. Shell脚本在Linux运维工作中的地位Shell脚本语言很适合用于处理纯文本类型的数据，而Linux系统中几乎所有的配置文件、日志文件（如NFS、Rsync、Httpd、Nginx、LVS、MySQL等），以及绝大多数的启动文件都是纯文本类型的文件。因此，学号Shell脚本语言，就可以利用它在Linux系统中发挥巨大的作用。 4. 脚本语言的种类4.1. Shell脚本语言的种类Shell脚本语言是弱类型语言（无需定义变量的类型即可使用），在Unix/Linux中主要有两大类Shell：一类是Bourne Shell，另一类是C Shell。 Bourne ShellBounrn Shell又包括Bourne Shell（sh）、Korn Shell（ksh）、Bourne Agaim Shell（bash）三种类型。 Bourne Shell（sh）由AT&amp;T的Steve Bourne开发，是标准的UNIX Shell，很多UNIX系统都配有sh。 Korn Shell（ksh）由David Korn开发，是Bourne Shell（sh）的超集合，并且添加了csh引入的新功能，是目前很多UNIX系统标准配置的Shell，这些系统上的/bin/sh往往是指向/bin/ksh的符号链接。 Bourne Again Shell（bash）由GUN项目组开发，主要目标是与POSIX标准保持一致，同时兼顾对sh的兼容，bash从csh和ksh借鉴了很多功能，是各种Linux发行版默认配置的Shell，Linux系统上的/bin/sh往往是指向/bin/bash的符号链接。尽管如此，bash和sh还是有很多的不同之处：一方面，bash扩展了一些命令和参数；另一方面，bsh并不完全和sh兼容，它们有些行为并不一致，但在大多数企业运维的情况下区别不大，特殊场景可以使用bash替代sh。 C ShellC Shell又包括csh、tcsh两种类型。 csh由Berkeley大学开发，随BSD UNIX发布，它的流程控制语句很像C语言，支持很多Boruen Shell所不支持的功能，例如：作业控制、别名、系统算术、命令历史、命令行编辑等。 tcsh是csh的增强版，加入了命令补全等功能，在FreeBSD、Mac OS X等系统上替代了csh。 以上介绍的这些Shell中，较为通用的是标准的Bourne Shell（sh）和C Shell（csh）。其中Bourne Shell（sh）已经被Bouren Again Shell（bash）所取代。 可以通过下面的命令查看CentOS系统的Shell支持情况：1234567[root@theshu ~]# cat /etc/shells/bin/sh #&lt;==这是Linux里常用的Shell，指向/bin/bash/bin/bash #&lt;==这是Linux里常用的Shell，也是默认使用的Shell/sbin/nologin #&lt;==这是Linux里常用的Shell，用于禁止用户登陆/usr/bin/sh/usr/bin/bash/usr/sbin/nologin Linux系统中的主流Shell是bash，bash是由Bourne Shell（sh）发展而来的，同时bash还包含了csh和ksh的特色，但大多数脚本都可以不加修改地在sh上运行，如果使用了sh后发现结果和预期有差异，那么可以尝试用bash替代sh。 4.2. 其它常用的脚本语言种类1. PHP语言PHP是网页程序语言，也是脚本语言。它是一款更专注于Web页面开发（前端展示）的语言，例如：wordpress、dedecmd、discus等著名的开源产品都是用PHP语言开发的。用PHP程序语言也可以处理系统日志、配置文件等，还可以调用Linux系统命令，但是，很少有人这么用。 2. Perl语言Perl脚本语言比Shell脚本语言强大很多，在2010年以前很流行，它的语法灵活、复杂，在实现不同的功能时可以用多种不同的方式，缺点是不易读，团队协作困难，但它仍不失为一种很好的脚本语言，存世的大量相关程序软件（比如，xtrabackup热备工具、MySQL MHA集群高可用软件等）中都有Perl语言的身影。当下的Linux运维人员机会不需要了解Perl语言了，最多可了解一些Perl语言的安装环境。当然了想要二次开发用Perl编写软件人员例外，Perl语言已经称为历史了。 3. Python语言Python是近几年非常流行的语言，它不但可以用于脚本程序开发，也可以实现Web页面程序开发（例如：CMDB管理系统），甚至还可以实现软件的开发（例如：大名鼎鼎的OpenStack、SalStack都是Python语言开发的）、游戏开发、大数据开大、移动端开大。 现在越来越多的公司都要求运维人员会Python自动化开发。Python语言目前是全球第四大开发语言，未来的发展前景很好，每一个运维人员在掌握了Shell编程之后，都应该深入学习Python语言，以提升职场竞争力。 4.3. Shell脚本语言的优势Shell脚本语言的优势在于处理偏操作系统底层的业务，例如：Linux系统内部的很多应用（—有的是应用的一部分）都是使用Shell脚本语言开发的，因为有1000多个Linux系统命令为它做支撑，特别是Linux正则表达式和三剑客grep、awk、sed等命令。 对于一些常见的系统脚本，使用Shell开发会更简单、更快速，例如：让软件一键自动化安装、优化、监控报警脚本。软件启动脚本，日志分析脚本等，虽然PHP/Python语言也能够做到这些，但是，考虑到掌握难度、开发效率、开发习惯等因素，它们可能就不如Shell脚本语言流行及有优势了。对于一些常规的业务应用，使用Shell更符合Linux运维简单、易用、高效的三大基本原则。 PHP语言的优势在于小型网站系统的开发；Python余元的优势在于开发较复杂的运维工具软件、Web界面的管理工具和Web业务的开发等。（例如：CMD自动化运维平台、跳板机、批量管理软件SaltStack、云计算OpenStack软件等）。我们在开发一个应用时应根据业务需求，结合不通语言的优势及自身擅长的语言来选择，扬长避短，从而达到高效开发及易于自身维护等目的。 5. 常用操作系统默认的Shell在常用的操作系统中，Linux下默认的Shell是bash；Solaris和FreeBSD下默认的是sh；AIX下默认的是ksh。这里重点讲Linxu系统环境下的bash。 这是一道企业面试题：CentOS Linux系统默认的Shell是什么？这题的答案就是bash。 可以通过一下两种方法查看CentOS Linux 系统默认的Shell。 方法1： 12[root@theshu ~]# echo $SHELL/bin/bash 方法2： 123[root@theshu ~]# grep root /etc/passwdroot:x:0:0:root:/root:/bin/bash# 提示：结尾的/bin/bash就是用户登陆后的Shell解释器。 6. Shell脚本的建立和执行6.1. Shell脚本的建立在Linux系统中，Shell脚本（bash shell程序）通常是在编辑器vi/vim中编写的，由Unix/Linux命令、bash Shell命令、程序结构控制语句和注释等内容组成。这里推荐用Vim工具。 1. 脚本开头（第一行）一个规范的Shell脚本在第一行会指出由哪个程序（解释器）来执行脚本中的内容，这一行内容在Linux Bash的编程一般为：123#!/bin/bash或#!/bin/sh #&lt;==255个字符以内 其中，开头的#!字符又称为幻数（其实叫什么都无所谓，知道它的作用就好），在执行bash脚本的时候，内核会根据#!后的解释器来确定该用哪个程序解释这个脚本中的内容。 注意，这一行必须位于每个脚本顶端的第一行，如果不是第一行则为脚本注释行，例如下面的例子：12345#!/bin/bashecho "Shell start."#!/bin/bash #&lt;==写到这里就是注释了#!/bin/sh #&lt;==写到这里就是注释了echo "Shell start." 2. bash与sh的区别早期的bash与sh稍有不同，它还包含了csh和ksh的特色，但大多数脚本都可以不加修改地在sh上运行，比如：1234[root@theshu ~]# ll /bin/shlrwxrwxrwx 1 root root 4 Oct 15 23:22 /bin/sh -&gt; bash[root@theshu ~]# ll /bin/bash-rwxr-xr-x 1 root root 960608 Sep 7 00:25 /bin/bash 提示： sh为bash的软链接，大多数情况下，脚本的开头使用#!/bin/bash和#!/bin/sh是没有区别的，但更规范的写法是在脚本的开头使用#!/bin/bash 如果使用/bin/sh执行脚本出现异常，那么可以再使用/bin/bash试一试，但是一般不会发生此类情况。 一般情况下，在安装Linux系统时会自动安装好bash软件，查看系统的bash版本的命令如下：1234567891011[root@theshu ~]# cat /etc/redhat-releaseCentOS Linux release 7.4.1708 (Core) #&lt;==这里显示的是Linux的环境版本[root@theshu ~]# bash --versionGNU bash, version 4.2.46(2)-release (x86_64-redhat-linux-gnu) #&lt;==这里显示的是bash的版本Copyright (C) 2011 Free Software Foundation, Inc. #&lt;==下面几行是自由软件提示的相关信息License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software; you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. 如果读者使用的是较老版本的Shell，那么建议将其升级到最新版本的Shell，特别是企业使用，因为近两年老版本的bash被曝露出存在较为严重的安全漏洞。 例如：bash软件曾经爆出了严重漏洞（破壳漏洞），凭借此漏洞，攻击者可能会接管计算机的整个操作系统，得以访问各种系统内的机密信息，并对系统进行更改等。任何人的计算机系统，如果使用了bash软件，都需要立即打上补丁。检测系统是否存在漏洞的方法为：12[root@theshu ~]# env x='() &#123; :;&#125;; echo be careful' bash -c "echo this is a test"this is a test 如果返回如下两行，则表示需要尽快升级bash了，不过，仅仅是用于学习和测试就无所谓了。12be carefulthis is a test 升级方法为：123[root@theshu ~]# yum -y update bash[root@theshu ~]# rpm -qa bashbash-4.2.46-29.el7_4.x86_64 提示：如果没有输出be careful，则不需要升级。 下面是Linux中常用脚本开头的写法，不同语言的脚本在开头一般都要加上如下标识内容：12345678#!/bin/sh#!/bin/bash#!/usr/bin/awk#!/bin/sed#!/usr/bin/tcl#!/usr/bin/expect #&lt;==expect解决交互式的语言开头解释器#!/usr/bin/perl #&lt;==perl语言解释器#!/usr/bin/env python #&lt;==python语言解释器 CentOS和RedHat Linux下默认的Shell均为bash。因此，在写Shell脚本的时候，脚本的开头即使不加#!/bin/bash，它也会交给bash解释。如果写脚本不希望使用系统默认的Shell解释，那么就必须要指定解释器了，否则脚本文件执行后的结果可能就不是你所要的。建议养成良好的编程习惯，不管采用什么脚本，最好都加上相应的开头解释器语言标识，遵守Shell编程规范。 如果在脚本开头的第一行不指定解释器，那么就要用对应的解释器来执行脚本，这样才能确保脚本正确执行。例如： 如果是Shell脚本，就用bash test.sh执行test.sh 如果是Python脚本，就用python test.py执行test.py 如果是expect脚本，就用expect test.exp执行test.exp 其他的脚本程序大都是类似的执行方法 3. 脚本注释在Shell脚本中，跟在#后面的内容表示注释，用来对脚本进行注释说明，注释部分不会被当作程序来执行，仅仅是给开发者和使用者看的，系统解释器是看不到的，更不会执行。注释可自成一行，也可以跟在脚本命令后面与命令在同一行。开发脚本时，如果没有注释，那么团队里的其他人就会很难理解脚本对应内容的用途，而且若时间长了，自己也会忘记。因此，我们要尽量养成所开发的Shell脚本书写关键注释的习惯，书写注释不光是为了方便别人，更是为了方便自己，避免影响团队的写作效率，以及给后来接手的人带来维护困难。特别提示一下，注释尽量不要用中文，在脚本中最好也不要有中文。 6.2. Shell脚本的执行1. 通常情况下shell执行过程当Shell脚本运行时，它会先查找系统环境变量ENV，该变量制定了环境文件（加载顺序通常是/etc/profile、~/.bash_profile、~/.bashrc、/etc/bashrc等），在加载了上述环境变量文件后，Shell就开始执行Shell脚本中的内容（更多Shell加载环境变量的知识需要看Shell学习笔记3）。 Shell脚本是从上至下、从左至右依次执行每一行的命令及语句的，即执行完了一个命令后再执行下一个，如果在Shell脚本中遇到子脚本（即脚本嵌套）时，就会先执行子脚本的内容，完成后再返回父脚本继续执行父脚本内后续的命令及语句。 通常情况下，在执行Shell脚本时，会向系统内核请求启动一个新的进程，以便在该进程中执行脚本的命令及子Shell脚本。 特殊技巧: 设置Linux的crond任务时，最好能在定时任务脚本中重新定义系统环境变量，否则，一些系统环境变量将不会被加载，这个问题需要注意！ 2. Shell的几种执行方式Shell脚本的执行通常可以采用以下几种方式： bash script-name或sh script-name：这是当脚本文件本身没有可执行权限时常用的方法，或者脚本文件开头没有指定解释器时需要使用的方法。这也是推荐使用的方法。 path/script-name或./script-name：指在当前路径下执行脚本（脚本需要有执行权限），需要将脚本文件的权限先改为可执行（即文件权限属性加x位），具体方法为chmod +x script-name。然后通过脚本的绝对路径或相对路径就可以直接执行脚本了。（在企业生产环境中，不少运维人员在写完Shell脚本后，由于忘记为该脚本设置执行权限，然后就直接应用了，结果导致脚本没有按照自己的意愿手动或定时执行，对于这一点，避免出现该问题的方法就是用第1种方法代替第2种）。 source script-name或. script-name：这种方法通常是使用source或.（点号）读入或加载指定的Shell脚本文件（如son.sh），然后，依次执行指定的Shell脚本son.sh中所有语句。这些语句将在父Shell脚本father.sh进程中运行（其它几种模式都会启动新的进程执行子脚本）。因此，使用source或.可以将son.sh自身脚本中的变量值或函数等的返回值传递到当前父Shell脚本father.sh中使用。这是它和其它几种方法最大的区别，这也是值得特别注意的地方。（source或.命令的功能是：在当前Shell中执行source或.加载并执行的相关脚本文件中的命令及语句，而不是产生一个子Shell来执行文件中的命令。注意，.和后面的脚本名之间要有空格。如果学过PHP开发就会明白，source或.相当于include的功能。HTTP服务软件Apache、Nginx等配置文件里都支持这样的用法）。 sh &lt; script-name或cat script-name | sh：同样适用于bash，不过这种用法不是很常见，但有时也可以有出奇制胜的效果，例如：不用循环语句来实现精简开机自启动服务的案例，就是通过将所有字符串拼接为命令的形式，然后经由管道交给bash操作的案例。 3. 示例说明创建模拟脚本test.sh，并输入如下内容：12[root@theshu ~]# cat &gt; test.shecho 'I am theshu' 输入”echo ‘I am theshu’”内容后按回车键，然后再按Ctrl+D组合键结束编辑。此操作为特殊编辑方法，这里是作为cat用法的扩展知识。 第一种方法实践：1234567[root@theshu ~]# cat test.shecho 'I am theshu'[root@theshu ~]# sh test.sh #&lt;==使用第一种方式的sh命令执行脚本I am theshu[root@theshu ~]# bash test.sh #&lt;==使用第一种方式的bash命令执行脚本I am theshu#&lt;==这里使用第一种方法的bash和sh，均可以执行脚本并得到预期的结果 第二种方法实践：1234[root@theshu ~]# ls -l test.sh-rw-r--r-- 1 root root 19 Feb 24 18:09 test.sh[root@theshu ~]# ./test.sh #&lt;==使用第二种方式"./"在当前目录下执行test.sh脚本文件，其实这个地方无法自动补全，这是因为没有权限所导致的。-bash: ./test.sh: Permission denied #&lt;==提示：强制执行会提示权限拒绝，此处是因为没有执行权限。 虽然没有权限的test.sh脚本不能直接被执行，但是可以用source或.（点号）来执行，它俩的功能相同，都是读入脚本并执行脚本。如下：1234[root@theshu ~]# . test.shI am theshu[root@theshu ~]# source test.shI am theshu 给test.sh添加可执行权限，命令如下：123[root@theshu ~]# chmod u+x test.sh[root@theshu ~]# ./test.shI am theshu 可以看到，给test.sh加完可执行权限后就能执行了。前面也提到了，这种方法在使用前每次都需要给定执行权限，但容易忘记，且多了一些步骤，增加了复杂性。 第三种方法实践：会将source或.执行的脚本中的变量值传递到当前的Shell中，如下：123456789[root@theshu ~]# echo 'userdir=`pwd`' &gt; test.sh[root@theshu ~]# cat test.shuserdir=`pwd` #&lt;==定义了一个命令变量，内容是打印当前路径。注意，打印命令用反引号[root@theshu ~]# sh test.sh #&lt;==采用sh命令执行脚本[root@theshu ~]# echo $userdir #&lt;==此处为空，并没有出现当前路径/root的输出[root@theshu ~]# source test.sh #&lt;==采用source执行同一脚本[root@theshu ~]# echo $userdir/root #&lt;==此处输出了当前路径/root 以上步骤说明了，用第三种方法会使脚本中的变量值传递到当前的shell中。 提示：操作系统及服务自带的脚本是我们学习的标杆和参考（虽然有时感觉这些脚本也不是十分规范） 结论：通过source或.加载执行过的脚本，由于是在当前Shell中执行脚本，因此在脚本结束之后，脚本中的变量（包括函数）值在当前Shell中依然存在，而sh和bash执行脚本都会启动新的子Shell执行，执行完后退回到父Shell。因此，变量（包括函数）值等无法保留。在进行Shell脚本开发时，如果脚本中有引用或执行其他脚本的内容或配置文件的需求时，最好用.或source先加载到该脚本或配置文件，处理完之后，再将它们加载到脚本的下面，就可以调用source加载的脚本及配置文件中的变量及函数等内容了。 第四种方法实践：12345678[root@theshu ~]# ls -l test.sh-rwxr--r-- 1 root root 19 Feb 24 18:44 test.sh[root@theshu ~]# cat test.shecho "I am theshu"[root@theshu ~]# sh &lt; test.sh #&lt;==尽量不要使用这种方法I am theshu[root@theshu ~]# cat test.sh | bash #&lt;==这种方法在命令行拼接字符串命令后，需要执行时就会用到I am theshu 提示：代码中提到的两种执行方法相当于sh script-name，效率很高，但是初学者用得少。 下面再看一道面试题：12345678910已知如下命令及返回结果，请问`echo $user`的返回的结果为（）[root@theshu ~]# cat test.shuser=`whoami`[root@theshu ~]# sh test.sh[root@theshu ~]# echo $user参考的选项如下：a) 当前用户b) rootc) 空（无内容输出） 答案是c。经过上述面试题可以得到如下的结论： 子Shell脚本会直接继承父Shell脚本的变量、函数等，反之则不可。 如果希望反过来继承（即父Shell继承子Shell的），就要用source或.在父Shell脚本中事先加载子Shell脚本。 6.3. Shell脚本开发的基本规范及习惯Shell脚本的开发规范及习惯非常重要，虽然这些规范不是必须要遵守的，但有了好的规范和习惯，可以大大提升开发效率，并能在后期降低对脚本的维护成本。当多人写作开发时，大家有一个互相遵守的规范就显得更重要了。即使只是一个人开发，最好也采取一套固定的规范，这样脚本将会更易读、更易于后期维护，最重要的是要让自己养成一个一出手就很专业和规范的习惯。 规范下面来看看有哪些规范，这些规范在Shell学习笔记14中也会提及，以便更进一步巩固。 Shell脚本的第一行是指定脚本解释器，通常为： 123#!/bin/bash或#!/bin/sh Shell脚本的开头会加版本、版权等信息： Shell脚本中尽量不用中文（不限于注释） 尽量用英文注释，防止本机或切换系统环境后中文乱码的困扰。 如果非要加中文，请根据自身的客户端对系统进行字符集调整，如export LANG=&quot;zh_CN.UTF-8&quot;，并在脚本中，重新定义字符集设置，和系统保持一致。 Shell脚本中的命令应以.sh为扩展名，例如：script-name.sh Shell脚本应存放在固定的路径下，例如：/server/scripts 书写的良好习惯以下是Shell脚本代码书写的良好习惯： 成对的符号应尽量一次性写出来，然后退格在符号里增加内容，以防止遗漏。这些成对的符号包括：{}、[]、&#39;&#39;、&quot;&quot;等 中括号（[]）两端至少要有1个空格，因此，键入中括号时即可留出空格，然后再退格键入中间的内容，并确保两端都至少有一个空格，即先键入一对中括号，然后退1格，输入两个空格，再退1格，双中括号（[[]]）的写法也是如此。 对于流程控制语句，应一次性将格式写完，再添加内容。 比如，一次性完成if语句的格式，应为： 1234if 条件内容then 内容fi 一次性完成for循环语句的格式，应为： 1234fordo 内容done while和until，case等语句也是一样。 通过缩进让代码更易读 对于常规变量的字符串定义变量值应加双引号，并且等号前后不能有空格，需要强引用的（指所见即所得的字符引用），则用单引号，如果是命令的引用，则用反引号。 脚本中的单引号、双引号及反引号必须为英文状态下的符号，其实所有的Linux字符及符号都应该是英文状态下的符号，这点需要特别注意。 说明：好的习惯可以让我们避免很多不必要的麻烦，提升工作效率。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell学习笔记01-如何才能学好Shell编程]]></title>
    <url>%2F2018%2F02%2F19%2FShell%2F003.%20Shell%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001-%E5%A6%82%E4%BD%95%E6%89%8D%E8%83%BD%E5%AD%A6%E5%A5%BDShell%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[GO 1. 为什么要学习Shell编程Shell脚本语言是实现Linux/Unix系统管理及自动化运维所必备的重要工具，Linux/Unix系统的底层及基础应用软件的核心大都涉及Shell脚本的内容。每一个合格的Linux系统管理员或运维工程师，都需要能够熟练地编写Shell脚本，并能够阅读系统及各类软件附带的Shell脚本内容。只有这样才能提升运维人员的工作效率，适应日益复杂的工作环境吗，减少不必要的重复工作，从而为个人的职场发展奠定较好的基础。 2. 学好Shell编程所需的基础知识学好Shell编程并通过Shell脚本轻松地实现自动化管理企业生产系统的必备基础如下： 能够熟练使用Vim编辑器，熟悉SSH终端及.vimrc等的配置 要有一定的Linux命令基础，至少需要掌握80个以上Linux常用命令，能够熟练使用它们 要熟练掌握Linux正则表达式及三剑客命令（grep、sed、awk） 熟悉常见的Linux网络服务部署、优化、日志分析及排错（需要掌握的基础网络服务包括但不限于：Crond、Rsync、Inotify、Nginx、PHP、MySQL、Keepalived、Memcached、Redis、NFS、Iptables、SVN、Git） 3. 如何才能学好Shell编程之前辈的经验学好Shell编程的核心：多练–&gt;多思考–&gt;再练–&gt;再思考，坚持如此循环即可！ 以下是一个高手前辈对于如何学好Shell编程所分享的经验： 掌握Shell脚本基本语法的方法 最简单有效的方法就是将语法敲n+1遍。为什么不是n遍呢？因为这里的n指的是你刚开始为掌握语法而练习的那些天（21天法则），而1则是指在确定掌握语法后每天都要写一些、想一想，至少是要看一看，保持一个与Shell脚本接触的热度。 掌握Shell脚本的各种常见语法 要掌握各类条件表达式，if多种判断、for循环的不同用法、while多种读文件的循环等，这样做不是为了什么都学会，而是为了能够看懂别人写的代码。掌握常见的各种语法，也就是要经常写，而且要持续写一段时间（让动作定型，在大脑和肌肉里都打上深刻烙印），各种语法都要用。 形成自己的脚本开发风格 当掌握了各种常见的语法之后，就要选定一种适合自己的语法，形成自己的开发风格，例如：if语句的语法就只用一种，条件表达式的语法只用一种，函数的写法也只用一种，有些语法需要根据场景去选择。没有必要什么语法都掌握。在解决问题的前提下，掌握一种语法，然后将其用精、用透就是最好的，切记横向痰多，要多纵深学习。 从简单做起，简单判断，简单循环 初学者一定要从简单做起，最小化代码学习，简单判断，简单循环，简单案例练习，所有的大程序都是由多个小程序组成的，因此，一开始没必要写多大的程序，免得给自己带来过多的挫败感，形成编程恐惧感。可先通过小的程序培养兴趣及成就感，到碰到大的程序时，即使遇到困难也能坚持下去了。 多模仿，多放下参考资料练习，多思考 多找一些脚本例子来仔细分析一下，或者是系统自带的，或者是别人写的，不要只看，看着会并不是真的会。当你闭上眼睛的时候，还能完整地回忆起来，甚至还能完整口述或手写出来才是真的会。 学会分析问题，逐渐形成编程思维 在编写程序或脚本时，先将需求理解透，对大的需求进行分解，逐步形成小的程序或模块，然后再开发，或者先分许最终需求的基础实现，最后逐步扩展批量实现。例如在编写批量关闭不需要的自启动服务的脚本时，就采用了这种分析方法，思路如下： 掌握关闭一个服务的命令，即 chkconfig 服务名 off 批量处理时，会有多个服务名，那么就要用到多条以上的命令 仔细分析以上命令，会发现需要处理的所有命令中，只有“服务名”不同，其它地方都一样，那么自然就会想到用循环语句来处理。 如果能够想到这些了，则表示你已经形成了初级的编程思维了。 如果你能够通过分析将一个大的需求细分为各个小的单元，然后利用函数、判断、循环、命令等实现每一个小的单元，那么最后把所有程序组合起来就是一个大的脚本程序了。如果达到了这个水平，则表示你已经会编程了。对于领导提出的需求，就能够进行合理的分解，只要在机器上多进行调试，相信一定能写出来。 编程变量名字要规范，采用驼峰语法表示 oldboyAgeName用的就是驼峰表示法。记住，在学习的初期，不要去看大的脚本，要从小问题和小的方面着手，当你觉得小的判断、循环等在你的脑子里瞬间就能出来时，再开始去看和写大的脚本，进行深入练习。 新手初期最好的学习方法就是多敲代码，并针对问题进行分解练习，多敲代码就是让自己养成一个编程习惯，使肌肉、视觉和思维形成记忆，分解问题实际上就是掌握软件的设计和实现思想。 对于最高的编程境界，个人的理解是：能把大问题进行完整的分析、分解且高效解决。 完整性：就是指预先考虑到各种可能性，将问题分解后，合理模块化并实现 高效率：例如，在求1到100的和时，考虑使用算法(1+100)x100/2，而不是逐个去加。 不要拿来注意，特别是新手 好多网友看书或学习视频时，喜欢要文档、要代码，其实，这是学习的最大误区。 有了文档和代码，你会变得非常懒惰，心里面会觉得已经学会了，而实际上并没有学会。因此无论是看书还是学习视频，都要自己完成学习笔记及代码的书写，这本身就是最重要的学习过程，在学习上要肯于花时间和精力，而不是投机取巧。如果你至今都没有学好Linux运维，那么可以想一想是不是也犯了这个错误？ 4. 学习Shell应该达到何种的编程高度如果掌握了前文提到的Linux基础知识，再熟悉了Shell的编程知识，就能够成为一个合格的运维人员了。要达到的高度就是，至少能够搞定企业场景中的绝大多数Shell编程问题。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux重要命令汇总表]]></title>
    <url>%2F2018%2F02%2F18%2FLinux%2F019.%20Linux%E9%87%8D%E8%A6%81%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[GO 线上查询及帮助命令（2个） 命令 功能说明 man 查看命令帮助、命令的词典，更复杂的还有info，但不常用 help 查看Linux内置命令的帮助，比如cd命令 文件和目录操作命令（18个） 命令 功能说明 ls 全拼list，功能是列出目录的内容及内容属性信息 cd 全拼change directory，功能是从当前工作目录切换到指定的工作目录 cp 全拼copy，其动能为复制文件或目录 find 查找的意思，用于查找目录及目录下的文件 mkdir 全拼make directories，其功能是创建目录 mv 全拼move，其功能是移动或重命名文件 pwd 全拼print working directory，其功能是显示当前工作目录的绝对路径 rename 用于重命名文件 rm 全拼remove，其功能是删除一个或多个文件或目录 rmdir 全拼remove empty directories，其功能是删除空目录 touch 创建新的空文件，改变已有文件的时间戳属性 tree 其功能是以属性结构显示目录下的内容 basename 显示文件名或目录名 dirname 显示文件或目录名 chattr 改变文件的扩展属性 lsattr 查看文件扩展属性 file 显示文件的类型 md5sum 计算和校验文件的MD5值 查看文件及内容处理命令（21个） 命令 功能说明 cat 全拼concatenate，其功能是用于连接多个文件并且打印输出或重定向到指定文件中 tac tac是cat的反向拼写，因此该命令的功能为反向显示文件内容 more 分页显示文件的内容 less 分页显示文件的内容，more命令的扩展用法 head 显示文件内容的前面部分 tail 显示文件内容的后面部分 cut 将文件的每一行按指定分隔符分割并输出 split 分割文件为不同的小文件 paste 按行合并文件内容 sort 对文件的文本内容进行排序 uniq 去除重复行 wc 统计文件的行数、单词数或字节数 iconv 转换文件的编码格式 dos2unix 将DOS格式文件转换成UNIX格式 diff 全拼difference，比较文件的差异，常用于文本文件 vimdiff 命令行可视化文件比较工具，常用于文本文件 rev 反向输出文件内容 grep/egrep 过滤字符串，三剑客老三 join 按两个文件的相同字段进行合并 tr 替换或删除字符 vi/vim 命令行文本编辑神器 文件压缩及解压缩命令（4个） 命令 功能说明 tar 打包压缩 unzip 解压文件 gzip gzip压缩工具 zip 压缩工具 信息显示命令（11个） 命令 功能说明 uname 显示操作系统相关信息 hostname 显示或设置当前系统的主机名 dmesg 显示开机信息，用于诊断系统故障 uptime 显示系统运行时间及负载 stat 显示文件或文件系统的状态 du 计算磁盘空间的使用情况 df 报告文件系统磁盘空间的使用情况 top 实时显示系统资源的使用情况 free 查看系统内存 date 显示与设置系统时间 cal 查看日历等时间信息 搜索文件命令（4个） 命令 功能说明 which 查找二进制命令，按环境变量PATH路径查找 find 从磁盘遍历查找文件或目录 where 查找二进制命令，按环境变量PATH路径查找 lacate 从数据库（/var/lib/mlocate/mlocate.db）查找命令，使用updatedb更新库 用户管理命令（10个） 命令 功能说明 useradd 添加用户 usermod 修改系统已经存在的用户属性 userdel 删除用户 groupadd 添加用户组 passwd 修改用户密码 chage 修改用户密码有效期 id 查看用户的UID、GID及其所归属的用户组 su 切换用户身份 visudo 编辑/etc/sudoers文件的专属命令 sudo 以另一个用户身份（默认root用户）执行事先在sudoers文件中允许的命令 基础网络操作命令（11个） 命令 功能说明 telnet 使用TELNET协议远程登陆 ssh 使用SSH加密协议远程登陆 scp 全拼为secure copy，用于在不通主机之间复制文件 wget 命令行下载文件的工具 ping 测试主机之间网络的连通性 route 显示和设置Linux系统的路由表 ifconfig 查看、配置、启用或禁用网络接口的命令 ifup 启动网卡 ifdown 关闭网卡 netstat 查看网络状态 ss 查看网络状态 深入网络操作命令（9个） 命令 功能说明 nmap 网络扫描命令 lsof 全名为list open files，即列举系统中已经被打开的文件 mail 发送和接受邮件 mutt 邮件管理命令 nslookup 交互式查询互联网DNS服务器的命令 dig 查找DNS解析过程 host 查询DNS的命令 traceroute 追踪数据传输路由的状况 tcpdump 命令行的抓包工具 有关磁盘与文件系统的命令（16个） 命令 功能说明 mount 挂载文件系统 umount 卸载文件系统 fsck 检查并修复Linux文件系统 dd 转换或复制文件 dumpe2fs 导出ext2/ext3/ext4文件系统信息 dump ext2/ext3/ext4文件系统备份工具 fdisk 磁盘分区命令，适用于2TB一下的磁盘分区 parted 磁盘分区命令，没有磁盘大小的限制，常用于2TB以上的磁盘分区 mkfs 格式化创建Linux文件系统 partprobe 更新内核的硬盘分区表信息 e2fsck 检查ext2/ext3/ext4类型文件系统 mkswap 创建Linux交换分区 swapon 启用交换分区 swapoff 关闭交换分区 sync 将内存缓冲区内的数据写入磁盘 resize2fs 调整ext2/ext3/ext4文件系统的大小 系统及用户权限相关命令（4个） 命令 功能说明 chmod 改变文件或目录权限 chown 改变文件或目录的属主和属组 chgrp 更文文件用户组 umask 显示或设置权限掩码 查看系统用户登陆信息的命令（7个） 命令 功能说明 whoami 显示当前有效的用户名称，相当于执行id -un命令 who 显示目前登陆系统的用户信息 w 显示已经登陆系统的用户列表，并显示用户正在执行的指令 last 显示登入系统的用户 lastlog 显示系统中所有用户最近一次登陆的信息 users 显示当前登陆系统的所有用户的用户列表 finger 查找并显示用户信息 内置命令及其它（19个） 命令 功能说明 echo 打印变量，或者直接输出指定的字符串 printf 将结果格式化输出到标准输出 rpm 管理rpm包的命令 yum 自动化、简单化地管理rpm包的命令 watch 周期性地执行给定的命令，并将命令的输出以全屏的方式显示 alias 设置别名 unalias 取消别名 date 查看或设置系统时间 clear 清除屏幕，简称清屏 history 查看命令执行的历史记录 eject 弹出光驱 time 计算命令执行的时间 nc 功能强大的网络工具 xargs 将标准输入转换成命令行参数 exec 调用并执行指令的命令 export 设置或显示环境变量 unset 删除变量或函数 type 用于判断另外一个命令是否为内置命令 bc 命令行科学计算器 系统管理与性能监视命令（9个） 命令 功能说明 chkconfig 管理Linux系统开机启动项 vmstat 虚拟内存统计 mpstat 显示各个可用CPU的状态统计 iostat 统计系统IO sar 全面获取系统的CPU、运行队列、磁盘I/O、分页（交换区）、内存、CPU中断和网络等性能数据 ipcs 用于报告Linux中进程间通信设施的状态，显示的信息包括消息列表、共享内存和信号量的信息 ipcrm 用来删除一个或更多的消息队列、信号量集或共享内存标识 strace 用于诊断、调试Linux用户空间的跟踪器，也可用于监控用户空间简称和内核交互，比如系统调用、信号传递、进程状态变更等 ltrace 命令会跟踪进程的库函数调用，并显现出哪个库函数被调用 关机、重启、注销和查看系统信息的命令（6个） 命令 功能说明 shutdown 关机 halt 关机 poweroff 关闭电源 logout 退出当前登陆的Shell exit 退出当前登陆的Shell Ctrl+D 退出当前登陆的Shell的快捷键 进程管理相关命令（15个） 命令 功能说明 bg 将一个在后台暂停的命令编程继续执行（在后台执行） fg 将后台中的命令调至前台继续运行 jobs 查看当前有多少命令在后台运行 kill 终止进程 killall 通过进程名终止进程 pkill 通过进程名终止进程 crontab 定时任务命令 ps 显示进程的快照 pstree 树形显示进程 nice 调整程序运行的优先级 nohup 忽略挂起信号运行指定的命令 pgrep 查找匹配条件的进程 runlevel 查看系统当前的运行级别 init 切换运行级别 service 启动、停止、重新启动和关闭系统服务，还可以显示所有系统服务的当前状态 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础部分补充内容]]></title>
    <url>%2F2018%2F01%2F24%2FLinux%2F018.%20Linux%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86%E8%A1%A5%E5%85%85%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[GO 1. Linux的一些常用快捷键 快捷键 功能 stty -echoctl 取消在屏幕上显示控制的字符，比如Ctrl+C的^C Ctrl+c 取消命令的输入，中断进程 Ctrl+z 暂停命令（fg恢复） Ctrl+a 光标到行首 Ctrl+e 光标到行尾 Ctrl+u 删除光标前所有字符 Ctrl+k 删除光标后所有字符 Ctrl+l 清屏（clear命令也可清屏） Ctrl+d 退出登陆 == exit （logout也可退出登陆） Ctrl+s 锁住命令终端使其定身，按任何键都不会有反应 Ctrl+q 解锁命令终端 Ctrl+r 搜索命令历史以执行该条历史命令 TAB 文件名补全，命令补全等 2. 时间管理命令 date：显示系统时间 clock：显示硬件时间 hwclock -W：把系统时间同步到硬件时间 hwclock -s：把硬件时间同步到系统时间 date -s &quot;2015-03-21 20:08:50&quot;：手动更改时间 ntpdate 时间服务器 （常用的微软时间服务器：time.windows.com）：自动更改时间（这个方式很标准） cal：显示日历 cal 2017：显示2017年的日历 3. 基础命令的补充- seqseq命令用于产生从某个数到另外一个数之间的所有整数。 语法： seq [选项] ... 尾数 seq [选项] ... 首数 尾数 seq [选项] ... 首数 增量 尾数 选项： -f, –format=格式 使用printf 样式的浮点格式 -s, –separator=字符串 使用指定字符串分隔数字（默认使用：\n） -w, –equal-width 在列前添加0 使得宽度相同 实例： -f选项：指定格式：1234#seq -f"%3g" 9 1191011 %后面指定数字的位数 默认是%g，%3g那么数字位数不足部分是空格。 12345#sed -f"%03g" 9 11#seq -f"str%03g" 9 11str009str010str011 这样的话数字位数不足部分是0，%前面制定字符串。 -w选项：指定输出数字同宽 12345seq -w 98 101098099100101 不能和-f一起用，输出是同宽的。 -s选项：指定分隔符（默认是回车） 12seq -s" " -f"str%03g" 9 11str009 str010 str011 要指定/t做为分隔符号：1seq -s"`echo -e "/t"`" 9 11 指定\n作为分隔符号：12seq -s"`echo -e "\n"`" 9 1119293949596979899910911 得到的是个错误结果，不过一般也没有这个必要，它默认的就是回车作为分隔符。 - source 或 .source 配置文件和. 配置文件的作用是相同的，就是让指定的配置文件生效。 - typetype 命令：用来查看一个命令的类型，是bash的内置命令，还是命令别名，或是其它的命令。 - runlevelrunlevel：查看当前系统的运行级别 - sleepsleep 100：休眠100秒 - lddldd 命令的绝对路径：查看该命令所依赖的”动态链接库”文件 - 重启命令 reboot init 6 shutdown -r now（或0） - 关机命令 init 0 halt shutdown -h now（或0） - 关于语系系统默认语系的配置文件是： /etc/sysconfig/i18n LANG=”zh_CN.UTF-8” 只要将等号后面的值更改即可更改系统的语系 4. xargs 与 exec这两个工具都可以实现相同的功能，exec主要是和find一起配合使用，而xargs就要比exec用的地方要多。 4.1. xargs应用用一个例子来说明： echo &quot;121212121212&quot; &gt; 123.txt ls 123.txt | xargs cat（输出结果： 121212121212） 说明：它的作用就是把管道符前面的输出作为xargs后面命令的输入。它的好处在于就可以把本来两步或多步才能完成的任务简单一步就能完成。 xargs常常和find命令一起使用： 比如，查找当前目录创建时间大于10天的文件，然后再删除 具体命令为：find . -mtime +10 | xargs rm 说明：这种应用是最为常见的，xargs后面的rm也可以加选项，当是目录时，就需要加-r选项了 这个功能更神奇： 现在我有这样一个需求“查找当前目录下所有.txt文件，然后把这些.txt文件变成.txt_bak。正常情况下，我们不得不写脚本去实现，但是使用xargs就一步能实现这个目的。 命令操作如下： mkdir test cd test touch 1.txt 2.txt.3.txt.4.txt.5.txt ls *.txt | xargs -n1 -i{} mv {} {}_baka 说明：xargs -n1 -i{}类似for循环，-n1意思是一个一个对象去处理，-i{}把前面的对象使用{}取代，mv {} {}_bak相当于mv 1.txt 1.txt_bak。（其实，-n1这个选择可以不加，只用-i选项即可） 建议记住这个应用方法，很实用 4.2. exec应用exec其实是find命令的一个选项，只能与find一起用。使用find命令时，经常使用一个选项就是这个exec了，可以达到和xargs同样的效果。 比如，查找当前目录创建时间大于10天的文件并删除它们： find . -mtime +10 -exec rm -rf {} \; 说明：这个命令中也是把{}作为前面find出来的文件的替代符，后面的\为;的脱义符，不然shell会把分号作为该行命令的结尾。 另一个使用exec的实用功能，就是它同样可以实现刚刚上面批量修改文件名的需求： find ./*_bak -exec mv {} {}_bak \; 5. 不中断命令行工具介绍需求：要执行一个命令或者脚本，但是需要几个小时甚至几天，这就要考虑到一个问题，就是中途断网或出现其他意外情况，执行的任务中断了怎么办？你可以把命令或者脚本丢到后台去运行，不过这样做也不保险。下面就介绍两种方法来避免这样的问题发生。 5.1. nohup命令nohup sh /usr/local/sbin/sleep.sh &amp; 说明：直接加一个”&amp;”虽然丢到后台了，但是当退出该终端很有可能这个脚本也会退出的，而在前面加上nohup就没有问题了。nohup的作用就是不挂断地运行命令，把运行命令产生的日志都记录到nohup文件里，这个文件是在nohup执行后在当前目录下面生成的nohup.out。 这个工具的缺点就是不能实时地控制和查看所进行的任务。 5.2. screen命令介绍：简单来说，screen是一个可以在多个进程之间多路复用一个物理终端的窗口管理器。scrren中有会话的概念，用户可以在一个screen会话中创建多个screen窗口，在每一个screen窗口中就像操作一个真是的SSH连接窗口那样。 如果系统中没有screen命令，请用yum install -y screen安装。 下面介绍一个screen的简单应用： 打开一个会话，直接输入screen命令然后回车，进入screen会话窗口 screen -ls查看已经打开的screen会话（在会话前会显示编号） Ctrl+a 再按d退出该screen会话，只是退出，并没有结束 结束会话输入Ctrl+d或者exit 退出后还想再次登陆某个screen会话，使用screen -r [scrren标号]，当只有一个screen会话时，后面的编号是可以省略的。当你有某个需要长时间运行的命令或者脚本时就打开一个screen会话，然后运行该任务。按Ctrl+a再按d退出会话，不影响终端窗口上的任何操作。 创建新的screen时，指定自定义名称： scrren -S aming 要想进入该screen，可以直接screen -r aming 6. 几个与网络有关的命令- crul命令curl命令是Linux系统命令行下用来简单测试web访问的工具。几个常用的选项要掌握： curl 网址 查看网站的HTML源代码 -x 指定一个代理，简单地指定一个hosts。可以指定ip和端口，省略写hosts，方便实用，格式：curl -xip:port www.baidu.com -l 可以把访问的内容省略掉，只显示状态码;-v可以显示详细过程。如：curl -lv http://www.baidu.com 几个常用的状态码如下： 200：正常状态 302：跳转状态 301：跳转状态 404：找不到 500：服务器报错 -u 可以指定用户名和密码，因为有些网站只有登陆后才能查看到内容：curl -u user:password http://123.com -O（大写） 直接下载页面或者对象：curl -O http://study.lishiming.net/index.html 还可以使用-o自定义所下载的文件的名字：curl -o index2.html http://study.lishiming.net/index.html - pingping命令用来测试主机之间网络的连通性。执行ping指令会使用ICMP传输协议，发出要求回应的信息，若远端主机的网络功能没有问题，就会回应该信息，因而得知该主机运作正常。 语法：ping [选项] [参数] 选项 作用 -d 使用Socket的SO_DEBUG功能 -c&lt;完成次数&gt; 设置完成要求回应的次数 -f 极限检测 -i&lt;间隔秒数&gt; 指定收发信息的间隔时间 -I&lt;网络界面&gt; 使用指定的网络界面送出数据包 -l&lt;前置载入&gt; 设置在送出要求信息之前，先行发出的数据包 -n 只输出数值 -p&lt;范本样式&gt; 设置填满数据包的范本样式 -q 不显示指令执行过程，开头和结尾的相关信息除外 -r 忽略普通的Routing Table，直接将数据包送到远端主机上 -R 记录路由过程 -s&lt;数据包大小&gt; 设置数据包的大小 -t&lt;存活数值&gt; 设置存活数值TTL的大小 -v 详细显示指令的执行过程 参数： 目的主机：指定发送ICMP报文的目的主机 实例：12345678910[root@AY1307311912260196fcZ ~]# ping www.linuxde.netPING host.1.linuxde.net (100.42.212.8) 56(84) bytes of data.64 bytes from 100-42-212-8.static.webnx.com (100.42.212.8): icmp_seq=1 ttl=50 time=177 ms64 bytes from 100-42-212-8.static.webnx.com (100.42.212.8): icmp_seq=2 ttl=50 time=178 ms64 bytes from 100-42-212-8.static.webnx.com (100.42.212.8): icmp_seq=3 ttl=50 time=174 ms64 bytes from 100-42-212-8.static.webnx.com (100.42.212.8): icmp_seq=4 ttl=50 time=177 ms...按Ctrl+C结束--- host.1.linuxde.net ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 2998msrtt min/avg/max/mdev = 174.068/176.916/178.182/1.683 ms - ttyLinux tty命令用于显示终端机连接标准输入设备的文件名称。 在Linux操作系统中，所有外围设备都有其名称与代号，这些名称代号以特殊文件的类型存放于/dev目录下。你可以执行tty(teletypewriter)指令查询目前使用的终端机的文件名称。 语法：tty [选项] 选项 作用 -s 不显示任何信息，只回传状态代码 –silent 同上 –quiet 同上 –help 在线帮助 –version 显示版本信息 实例： 显示当前终端12# tty/dev/pts/4 - wallwall命令用于向系统当前所有打开的终端上输出信息。通过wall命令可将信息发送给每位同意接收公众信息的终端机用户，若不给予其信息内容，则wall命令会从标准输入设备读取数据，然后再把所得到的数据传送给所有终端机用户。 语法：wall [参数] 参数： 消息：指定广播消息 实例：123[root@localhost ~]# wall this is a test lineBroadcast message from root (pts/1) (Fri Dec 20 11:36:51 2013):this is a test line - writewrite命令用于向指定登录用户终端上发送信息。通过write命令可传递信息给另一位登入系统的用户，当输入完毕后，键入EOF表示信息结束，write命令就会将信息传给对方。如果接收信息的用户不只登入本地主机一次，你可以指定接收信息的终端机编号。 语法：write [参数] 参数： 用户：指定要接受信息的登录用户 登陆终端：指定接收信息的用户的登录终端 实例： 传信息给Rollaend，此时Rollaend只有一个连线 :1write Rollaend 接下来就是将信息打上去，结束请Ctrl+C： 传信息给Rollaend、Rollaend的连线有pts/2、pts/3：1write Rollaend pts/2 接下来就是将信息打上去，结束请Ctrl+C： 若对方设定mesg n，则此时信息将无法传给对方。 - telnettelnet命令用于登录远程主机，对远程主机进行管理。telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录，因此弄清楚telnet客户端的使用方式仍是很有必要的。 语法：telnet [选项] [参数] 选项 作用 -8 允许使用8位字符资料，包括输入与输出 -a 尝试自动登入远端系统 -b&lt;主机别名&gt; 使用别名指定远端主机名称 -c 不读取用户专属目录里的.telnetrc文件 -d 启动排错模式 -e&lt;脱离字符&gt; 设置脱离字符 -E 滤除脱离字符 -f 此参数的效果和指定”-F”参数相同 -F 使用Kerberos V5认证时，加上此参数可把本地主机的认证数据上传到远端主机 -k&lt;域名&gt; 使用Kerberos认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名 -K 不自动登入远端主机 -l&lt;用户名称&gt; 指定要登入远端主机的用户名称 -L 允许输出8位字符资料 -n&lt;记录文件&gt; 指定文件记录相关信息 -r 使用类似rlogin指令的用户界面 -S&lt;服务类型&gt; 设置telnet连线所需的ip TOS信息 -x 假设主机有支持数据加密的功能，就使用它 -X&lt;认证形态&gt; 关闭指定的认证形态 参数： 远程主机：指定要登陆进行管理的远程主机 端口：指定TELNET协议使用的端口号 实例：12345678telnet 192.168.2.10Trying 192.168.2.10...Connected to 192.168.2.10 (192.168.2.10).Escape character is '^]'. localhost (Linux release 2.6.18-274.18.1.el5 #1 SMP Thu Feb 9 12:45:44 EST 2012) (1)login: rootPassword: Login incorrect - traceroutetraceroute命令用于追踪数据包在网络上的传输时的全部路径，它默认发送的数据包大小是40字节。 通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其ip地址。 语法：traceroute [选项] [参数] 选项 作用 -d 使用Socket层级的排错功能 -f&lt;存活数值&gt; 设置第一个检测数据包的存活数值TTL的大小 -F 设置勿离断位 -g&lt;网关&gt; 设置来源路由网关，最多可设置8个 -i&lt;网络界面&gt; 使用指定的网络界面送出数据包 -I 使用ICMP回应取代UDP资料信息 -m&lt;存活数值&gt; 设置检测数据包的最大存活数值TTL的大小 -n 直接使用IP地址而非主机名称 -p&lt;通信端口&gt; 设置UDP传输协议的通信端口 -r 忽略普通的Routing Table，直接将数据包送到远端主机上 -s&lt;来源地址&gt; 设置本地主机送出数据包的IP地址 -t&lt;服务类型&gt; 设置检测数据包的TOS数值 -v 详细显示指令的执行过程 -w&lt;超时秒数&gt; 设置等待远端主机回报的时间 -x 开启或关闭数据包的正确性检验 参数： 主机：指定目的主机IP地址或主机名 实例：1234567891011121314traceroute www.58.comtraceroute to www.58.com (211.151.111.30), 30 hops max, 40 byte packets 1 unknown (192.168.2.1) 3.453 ms 3.801 ms 3.937 ms 2 221.6.45.33 (221.6.45.33) 7.768 ms 7.816 ms 7.840 ms 3 221.6.0.233 (221.6.0.233) 13.784 ms 13.827 ms 221.6.9.81 (221.6.9.81) 9.758 ms 4 221.6.2.169 (221.6.2.169) 11.777 ms 122.96.66.13 (122.96.66.13) 34.952 ms 221.6.2.53 (221.6.2.53) 41.372 ms 5 219.158.96.149 (219.158.96.149) 39.167 ms 39.210 ms 39.238 ms 6 123.126.0.194 (123.126.0.194) 37.270 ms 123.126.0.66 (123.126.0.66) 37.163 ms 37.441 ms 7 124.65.57.26 (124.65.57.26) 42.787 ms 42.799 ms 42.809 ms 8 61.148.146.210 (61.148.146.210) 30.176 ms 61.148.154.98 (61.148.154.98) 32.613 ms 32.675 ms 9 202.106.42.102 (202.106.42.102) 44.563 ms 44.600 ms 44.627 ms10 210.77.139.150 (210.77.139.150) 53.302 ms 53.233 ms 53.032 ms11 211.151.104.6 (211.151.104.6) 39.585 ms 39.502 ms 39.598 ms12 211.151.111.30 (211.151.111.30) 35.161 ms 35.938 ms 36.005 ms 记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果用traceroute -q 4 www.58.com，表示向每个网关发送4个数据包。 有时我们traceroute一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。 有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n参数来避免DNS解析，以IP格式输出数据。 如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。 - digdig命令是常用的域名查询工具，可以用来测试域名系统工作是否正常。 语法：dig [选项] [参数] 选项 作用 @&lt;服务器地址&gt; 指定进行域名解析的域名服务器 -b IP地址 当主机具有多个IP地址，指定使用本机的哪个IP地址向域名服务器发送域名查询请求 -f&lt;文件名称&gt; 指定dig以批处理的方式运行，指定的文件中保存着需要批处理查询的DNS任务信息 -P 指定域名服务器所使用端口号 -t&lt;类型&gt; 指定要查询的DNS数据类型 -x IP地址 执行逆向域名查询 -4 使用IPv4 -6 使用IPv6 -h 显示指令帮助信息 参数： 主机：指定要查询域名主机 查询类型：指定DNS查询的类型 查询类：指定查询DNS的class 查询选项：指定查询选项 实例：123456789101112131415161718[root@localhost ~]# dig www.linuxde.net; &lt;&lt;&gt;&gt; DiG 9.3.6-P1-RedHat-9.3.6-20.P1.el5_8.1 &lt;&lt;&gt;&gt; www.linuxde.net;; global options: printcmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 2115;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 2, ADDITIONAL: 0;; QUESTION SECTION:;www.linuxde.net. IN A;; ANSWER SECTION:www.linuxde.net. 0 IN CNAME host.1.linuxde.net.host.1.linuxde.net. 0 IN A 100.42.212.8;; AUTHORITY SECTION:linuxde.net. 8 IN NS f1g1ns2.dnspod.net.linuxde.net. 8 IN NS f1g1ns1.dnspod.net.;; Query time: 0 msec;; SERVER: 202.96.104.15#53(202.96.104.15);; WHEN: Thu Dec 26 11:14:37 2013;; MSG SIZE rcvd: 121 - nc/netcatnc命令是netcat命令的简称，都是用来设置路由器。如果没有这个命令，请安装netcat。 语法：nc/netcat [选项] [参数] 选项 作用 -g&lt;网关&gt; 设置路由器跃程通信网关，最多设置8个 -G&lt;指向器数目&gt; 设置来源路由指向器，其数值为4的倍数 -h 在线帮助 -i&lt;延迟秒数&gt; 设置时间间隔，以便传送信息及扫描通信端口 -l 使用监听模式，监控传入的资料 -n 直接使用ip地址，而不通过域名服务器 -o&lt;输出文件&gt; 指定文件名称，把往来传输的数据以16进制字码倾倒成该文件保存 -p&lt;通信端口&gt; 设置本地主机使用的通信端口 -r 指定源端口和目的端口都进行随机的选择 -s&lt;来源位址&gt; 设置本地主机送出数据包的IP地址 -u 使用UDP传输协议 -v 显示指令执行过程 -w&lt;超时秒数&gt; 设置等待连线的时间 -z 使用0输入/输出模式，只在扫描通信端口时使用 参数： 主机：指定主机的IP地址或主机名称 端口好：可以是单个整数或者是一个范围 实例： 远程拷贝文件 从server1拷贝文件到server2上。需要先在server2上，用nc激活监听。 server2上运行：1[root@localhost2 tmp]# nc -lp 1234 &gt; install.log server1上运行：123[root@localhost1 ~]# ll install.log-rw-r–r– 1 root root 39693 12月 20 2007 install.log[root@localhost1 ~]# nc -w 1 192.168.228.222 1234 &lt; install.log 克隆硬盘或分区 操作与上面的拷贝是雷同的，只需要由dd获得硬盘或分区的数据，然后传输即可。克隆硬盘或分区的操作，不应在已经mount的的系统上进行。所以，需要使用安装光盘引导后，进入拯救模式（或使用Knoppix工 具光盘）启动系统后，在server2上进行类似的监听动作：1nc -l -p 1234 | dd of=/dev/sda server1上执行传输，即可完成从server1克隆sda硬盘到server2的任务：1dd if=/dev/sda | nc 192.168.228.222 1234 完成上述工作的前提，是需要落实光盘的拯救模式支持服务器上的网卡，并正确配置IP。 端口扫描 12nc -v -w 1 192.168.228.222 -z 1-1000localhost2 [192.168.228.222] 22 (ssh) open 保存Web页面 123while true; do nc -l -p 80 -q 1 &lt; somepage.html;done 聊天 nc还可以作为简单的字符下聊天工具使用，同样的，server2上需要启动监听：1[root@localhost2 tmp]# nc -lp 1234 server1上传输：1[root@localhost1 ~]# nc 192.168.228.222 1234 这样，双方就可以相互交流了。使用Ctrl+D正常退出。 传输目录 从server1拷贝nginx-0.6.34目录内容到server2上。需要先在server2上，用nc激活监听，server2上运行：1[root@localhost2 tmp]# nc -l 1234 | tar xzvf - server1上运行：123[root@localhost1 ~]# ll -d nginx-0.6.34drwxr-xr-x 8 1000 1000 4096 12-23 17:25 nginx-0.6.34[root@localhost1 ~]# tar czvf – nginx-0.6.34 | nc 192.168.228.222 1234 - ssss命令用来显示处于活动状态的套接字信息。ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。但ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。 当服务器的socket连接数量变得非常大时，无论是使用netstat命令还是直接cat /proc/net/tcp，执行速度都会很慢。可能你不会有切身的感受，但请相信我，当服务器维持的连接达到上万个的时候，使用netstat等于浪费 生命，而用ss才是节省时间。 天下武功唯快不破。ss快的秘诀在于，它利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux 内核中第一手的信息，这就确保了ss的快捷高效。当然，如果你的系统中没有tcp_diag，ss也可以正常运行，只是效率会变得稍慢。 语法：ss [选项] 选项 作用 -h 显示帮助信息； -V 显示指令版本信息； -n 不解析服务名称，以数字方式显示； -a 显示所有的套接字； -l 显示处于监听状态的套接字； -o 显示计时器信息； -m 显示套接字的内存使用情况； -p 显示使用套接字的进程信息； -i 显示内部的TCP信息； -4 只显示ipv4的套接字； -6 只显示ipv6的套接字； -t 只显示tcp套接字； -u 只显示udp套接字； -d 只显示DCCP套接字； -w 仅显示RAW套接字； -x 仅显示UNIX域套接字。 实例： 显示ICP连接 12345678[root@localhost ~]# ss -t -aState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 0 *:3306 *:* LISTEN 0 0 *:http *:* LISTEN 0 0 *:ssh *:* LISTEN 0 0 127.0.0.1:smtp *:* ESTAB 0 0 112.124.15.130:42071 42.156.166.25:http ESTAB 0 0 112.124.15.130:ssh 121.229.196.235:33398 显示Sockets 摘要 1234567891011[root@localhost ~]# ss -sTotal: 172 (kernel 189)TCP: 10 (estab 2, closed 4, orphaned 0, synrecv 0, timewait 0/0), ports 5Transport Total ip IPv6* 189 - - RAW 0 0 0 UDP 5 5 0 TCP 6 6 0 INET 11 11 0 FRAG 0 0 0 列出当前的established, closed, orphaned and waiting TCP sockets 列出所有打开的网络连接端口 123456[root@localhost ~]# ss -lRecv-Q Send-Q Local Address:Port Peer Address:Port 0 0 *:3306 *:* 0 0 *:http *:* 0 0 *:ssh *:* 0 0 127.0.0.1:smtp *:* 查看进程使用的socket 123456[root@localhost ~]# ss -plRecv-Q Send-Q Local Address:Port Peer Address:Port 0 0 *:3306 *:* users:(("mysqld",1718,10))0 0 *:http *:* users:(("nginx",13312,5),("nginx",13333,5))0 0 *:ssh *:* users:(("sshd",1379,3))0 0 127.0.0.1:smtp *:* us 找出打开套接字/端口应用程序 12[root@localhost ~]# ss -pl | grep 33060 0 *:3306 *:* users:(("mysqld",1718,10)) 显示所有UDP Sockets 1234567[root@localhost ~]# ss -u -aState Recv-Q Send-Q Local Address:Port Peer Address:Port UNCONN 0 0 *:syslog *:* UNCONN 0 0 112.124.15.130:ntp *:* UNCONN 0 0 10.160.7.81:ntp *:* UNCONN 0 0 127.0.0.1:ntp *:* UNCONN 0 0 *:ntp *:* OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统日志介绍]]></title>
    <url>%2F2018%2F01%2F24%2FLinux%2F017.%20Linux%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[GO 日志记录了系统每天发生的各种各种的事情，比如监测系统状况、排查系统故障等。你可以通过日志来检查错误发生的原因，或者收到攻击时攻击者留下的痕迹。日志的主要功能是审计和监测，还可以实时地监测系统状态，监测和追踪侵入者等。所以，在以后的工作中，遇到问题，查看日志，才能找到线索，来解决问题。 1. 日志配置文件日志的配置文件，CentOS6默认改为/etc/rsyslog.conf，之前的版本是/etc/syslog.conf。该配置文件的主要信息为：记录哪些服务和需要记录什么等级的信息。（在工作中若没有特殊需求，不要修改这个配置文件） 日志的格式如下： 格式 含义 auth pam产生的日志 authpriv ssh、FTP等登陆的验证信息 cron 时间任务相关 kern 内核 lpr 打印 mail 邮件 mark(syslog) rsyslog服务内部的信息，时间标识 news 新闻组 user 用户程序产生的相关信息 uucp unix to unix copy，unix主机之间相关的通讯 local 1~7 自定义的日志设备 日志的级别如下： 级别 含义 debug 有调试信息的，日志信息最多 info 一般信息的日志，最常用 notice 最艰苦有重要性的普通条件的信息 warning 警告级别 err 错误级别，阻止某个功能或者模块不能正常工作的信息 crit 严重级别，阻止整个系统或者真整个软件不能正常工作的信息 alert 需要立刻修改的信息 emerg 内核崩溃等严重信息 none 什么都不记录 说明 从上到下，级别从低到高，记录的信息越来越少 连接符号如下： 符号 含义 . 表示大于或等于xxx级别的信息 .= 表示等于xxx级别的信息 .! 表示在xxx之外的等级信息 2. 常用日志文件 /var/log/messages 系统最核心的日志文件，包含了系统启动时的i难道消息，以及系统运行时的其它状态消息。I/O错误、网络错误和其它系统错误都会记录到这个文件中。其它信息，比如某个人的身份切换为root，以及用户自定义安装的软件（apache）的日志也会在这里列出。假如某个服务没有定义日志，那么该服务产生的日志就会到这个文件中。该日志每周归档一次。它是如何归档的，是根据/etc/logrotate.conf来控制的。这个文件也就是该日志的配置文件，而且很容易看明白，如果没有特殊需求，不要更改这个配置文件。/var/log/messages由syslogd这个守护进程产生的，如果停掉这个服务则系统不会产生/var/log/messages。 /var/log/wtmp 用来记录用户登陆历史，但是这个文件不能用cat直接查看，只能用last查看。 /var/log/btmp 用来记录无效登陆历史，和wtmp类似，也不能用cat直接查看，只能用lastb查看。 /var/log/maillog 用来记录邮件相关的信息，比如发给谁邮件，是否发送成功等信息。mailq可以查看发送邮件的状态。 /var/log/secure 是一个安全认证相关的日志，比如系统用户登陆时，正常登陆或者登陆失败都会记录，另外ftp服务相关的登陆日志也会记录到这里面来。 dmesg 这是一个命令，主要用来查看系统实时的硬件设备抛出的信息，如果硬盘异常或者网络异常在或者内核异常都会记录下来，只不过这些信息是存到内存里面的，系统重启后就消失了。（这个还是很有用的） /var/log/dmesg 这是一个日志，记录系统启动时硬件相关的信息。（在启动完成之后不会再有信息记录到这个文件） 3. 查看登陆历史记录3.1. last命令last命令用于显示用户最近登录信息。单独执行last命令，它会读取/var/log/wtmp的文件，并把该给文件的内容记录的登入系统的用户名单全部显示出来。 语法：last [选项] [参数] 选项 意义 -a 把从何处登入系统的主机名称或IP地址，显示在最后一行 -d 将IP地址转换成主机名称 -f file 指定记录文件 -R 不显示登入系统的主机名称或IP地址 -x 显示系统关机、重新开机，以及执行等级的改变等信息 参数： 用户名：显示用户登陆列表 终端：显示从指定终端的登陆列表 last命令示例如下：1234$ lasttheshu tty8 :0 Sat Oct 7 09:42 gone - no logoutreboot system boot 4.4.0-53-generic Sat Oct 7 09:41 still runningwtmp begins Sat Oct 7 09:41:18 2017 last命令用来查看登陆Linux历史信息，从左到右依次为账户名称、登陆终端、登陆客户端ip、登陆日期及时长。 3.2. lastblastb命令用于显示用户错误的登录列表，此指令可以发现系统的登录异常。单独执行lastb命令，它会读取位于/var/log目录下，名称为btmp的文件，并把该文件内容记录的登入失败的用户名单，全部显示出来。 语法：lastb 选项 参数 选项 作用 -a 把从何处登入系统的主机名称或ip地址显示在最后一行 -d 将IP地址转换成主机名称 -f&lt;记录文件&gt; 指定记录文件 -n&lt;显示列数&gt;或-&lt;显示列数&gt; 设置列出名单的显示列数 -R： 不显示登入系统的主机名称或IP地址 -x： 显示系统关机，重新开机，以及执行等级的改变等信息 参数 意义 用户名 显示中的用户的登录列表 终端 显示从指定终端的登录列表 实例： 首次运行lastb命令会报下的错误：12lastb: /var/log/btmp: No such file or directoryPerhaps this file was removed by the operator to prevent logging lastb info. 只需建立这个不存在的文件即可。1touch /var/log/btmp 使用ssh的登录失败不会记录在btmp文件中。1234567891011lastb | headroot ssh:notty 110.84.129.3 Tue Dec 17 06:19 - 06:19 (00:00)root ssh:notty 110.84.129.3 Tue Dec 17 04:05 - 04:05 (00:00)root ssh:notty 110.84.129.3 Tue Dec 17 01:52 - 01:52 (00:00)root ssh:notty 110.84.129.3 Mon Dec 16 23:38 - 23:38 (00:00)leonob ssh:notty 222.211.85.18 Mon Dec 16 22:18 - 22:18 (00:00)leonob ssh:notty 222.211.85.18 Mon Dec 16 22:18 - 22:18 (00:00)root ssh:notty 110.84.129.3 Mon Dec 16 21:25 - 21:25 (00:00)root ssh:notty 110.84.129.3 Mon Dec 16 19:12 - 19:12 (00:00)root ssh:notty 110.84.129.3 Mon Dec 16 17:00 - 17:00 (00:00)admin ssh:notty 129.171.193.99 Mon Dec 16 16:52 - 16:52 (00:00) 3.3. lastlogastlog命令用于显示系统中所有用户最近一次登录信息。 lastlog文件在每次有用户登录时被查询。可以使用lastlog命令检查某特定用户上次登录的时间，并格式化输出上次登录日志/var/log/lastlog的内容。它根据UID排序显示登录名、端口号（tty）和上次登录时间。如果一个用户从未登录过，lastlog显示Never logged。注意需要以root身份运行该命令。 语法：lastlog 选项 选项 意义 -b 天数 显示指定天数前的登陆信息 -h 显示召集令的帮助信息 -t 天数 显示指定天数以来的登陆信息 -u 用户名 显示指定用户的最近登陆信息 例子：1234567891011121314151617181920212223242526[root@www ~]# lastlogUsername Port From Latestroot pts/0 221.6.45.34 Tue Dec 17 09:40:48 +0800 2013bin **Never logged in**daemon **Never logged in**adm **Never logged in**lp **Never logged in**sync **Never logged in**shutdown **Never logged in**halt **Never logged in**mail **Never logged in**news **Never logged in**uucp **Never logged in**operator **Never logged in**games **Never logged in**gopher **Never logged in**ftp **Never logged in**nobody **Never logged in**vcsa **Never logged in**ntp **Never logged in**sshd **Never logged in**nscd **Never logged in**ldap **Never logged in**postfix **Never logged in**www **Never logged in**mysql **Never logged in** 4. 关于日志使用的建议在日常的管理工作中要养成多看日志的习惯，尤其是一些应用的日志，比如apache、mysql、php等常用的软件，看它们的日志（错误日志）可以帮助排查问题以及监控它们的运行状况是否良好。 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux数据备份技术]]></title>
    <url>%2F2018%2F01%2F24%2FLinux%2F016.%20Linux%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[GO 1. scp工具scp用来拷贝用的，可远程和本地相互之间都可以，与rsync差不多，但是它不支持增量备份。 用法如下： scp是由openssh-clients包支持的，安装这个包就可以使用scp了，但是远程备份的时候双方都必须安装这个包。 scp -r a/ 192.168.1.12:/tmp/b/ 把a目录拷贝到IP的/tmp/下更名为b，IP前不加用户名默认使用当前用户。 scp -r a/ root@192.168.1.12&quot;/tmp/a/&quot; 从本地拷贝到远程 scp -r 192.168.1.12:/tmp/a/ ./a/ 从远程拷贝到本地 2. rsync工具2.1. 介绍在Linux 系统下的数据备份的工具有很多，但其实只用一种就可以满足所有的备份工作，那就是rsync这个工具。从字面上的意思可以理解为remote sync（远程同步），这样可以理解的更深刻一些。 rsync工具不仅可以远程同步数据（类似于scp)，当然还可以本地同步数据（类似于cp）。但不同于两者的是，rsync工具不会覆盖以前的数据（如果数据已经存在），它会先判断已经存在的数据和新数据有什么不同，只有不同时才会把不同的部分覆盖掉。远程备份和增量备份是它的优势。 如果Linux系统中没有这个工具，请先安装它：yum install -y rsync。 2.2. 使用使用格式： rsync [选项] 源 目标 ——————–//本地同步文件 rsync [选项] 源 userbname@ip:目标 ——-//从本地上传到远程去 rsync [选项] username@ip:源文件 目标 —-//从远程下载到本地来 rsync [选项] 源 username@ip::模块名 rsync [选项] username@ip::模块名 目标 后两种的两种格式中使用了两个冒号，这种方式和前面的方式的不同在于验证方式的不同。后面会再详细介绍。 常用选项： (常用)-a 归档模式，表示以递归方式传输文件，并保持所有属性。相当于选项 -rlptgoD。这个选项后面可以跟一个--no-OPTION这个表示关闭-rlptgoD中的某一个，例如-a --no-l 在a选项中去除l选项 (常用)-v 显示信息，显示文件拷贝的速率、文件数量等状态信息 (常用)-z 压缩传输 (常用)--delete 删除那些DST中SRC没有的文件 (常用)--exclude=PATTERN 指定排除不需要传输的文件，等号后面跟文件名，支持通配符（如*.txt) (常用)--password-file=filename 指定密码文件 (常用)rsync --daemon 后台模式启动 rsync --daemon --help 可查看帮助文件 rsync --daemon --config=/etc/rsyncd.conf 指定配置文件，默认使用/etc/rsyncd.conf配置文件 -r 针对目录，对子目录以递归模式处理 -l 针对软链接文件来使用，保持软链接文件的本身类型 -L 像对待常规文件一样处理软链接，如果SRC中有软链接文件，则把软链接所指向的源文件拷贝 -u 加上这个选项后将会把DST中比SRC还新的文件排除掉，不会覆盖 -p 保留权限 -t 保留时间属性 -g 保留所属组信息 -o 保留所属主信息 -D 保持设备文件信息（只针对超级用户使用，目前还不理解） -P或--progress 在同步的过程中可以看到同步的过程状态，比如统计要同步的文件数量、同步的文件传输速度等等。 --bwlimit=100 限速，最大传输速度为100kb 2.3. 一些重要的实验 建立目录以及文件 mkdir rsync cd rsync mkdir test1 cd test1 touch 1 2 3 /root/123.txt ln -s /root/123.txt ./123.txt ls -l 建立这些文件的目的就是为了做实验做一些准备工作。 使用-a选项 rsync -a test1 test2 ls test2 ls test2/test1/ 这里有一个问题，就是本想把test1目录直接拷贝成test2目录，可结果rsync却新建了test2目录然后把test1放到了test2当中。为了避免这样的情况发生，可以这样做： rm -rf test2 rsync -a test1/ test2/ ls -l test2/ 加一个斜杠就好了，所以我建议你在使用rsync备份目录时要养成加斜杠的习惯。 在上面讲了-a选项等同于-rlptgoD，而且-a还可以和–no-OPRIN一并使用。 下面来看看-l选项的作用 rsync -av --no-l test1/ test2/ 使用-v选项看来就是很方便，上例告诉我们跳过了非普通文件123.txt，其实123.txt是一个软链接文件，如果不使用-l选项则不理会软链接文件。 虽然加上-l选项会把软链接文件给拷贝过去，但是软链接的目标文件却没有拷贝过去，有时候咱们指向拷贝软链接文件所指向的目标文件，那这时候该怎么办呢？ 使用-L选项 rsync -avL test1/ test2/ ls -l test2/ 加上-L选项就可以把SRC中软链接的目标文件给拷贝到DST。 使用-u选 首先查看一下test/1和test2/1的创建时间（肯定是一样的），然后使用touch修改一下test2/1的创建时间（此时test2/1要比/test1/1的创建时间晚了一些）。如果不加-u选项的花，会把test2/1的创建时间变成和test1/1的创建时间一样。这样讲也许会让人迷糊，不妨看一看： ll test1/1 test2/1 两者之间的创建时间是一样的，下面修改test2/1的创建时间，然后不加-u同步 touch test2/1 ll test2/1 rsync -av test1/ test2/ ll test2/1 test2/1的创建时间又变成和test1/1的创建时间一样了。下面加上-u选项再看看结果是怎样的 touch test2/1 ll test2/1 rsync -avu test1/ test2/ ll test1/1 test2/1 加上-u选项后，不会再把test1/1同步为test2/1了，这就是-u选项的妙用。 使用--delete选项 首先删除test1/123.txt rm -rf test1/123.txt `ls test1/ 然后把test1/目录同步到test2/目录下 rsync -av test1/ test2/ ls test2/ test2/目录下并没有删除掉123.txt，下面加上–delete选项 rsync -av --delete test1/ test2/ ls test2/ test2/目录下的123.txt也被删除了，这就是–delete选项的用处。 还有一种情况就是如果在DST增加文件，而SRC当中没有这些文件，同步时加上–delete选项后同样会删除新增的文件。 touch test2/4 ls test1/ test2/ rsync -a --delete test1/ test2/ ls test1/ test2/ 使用–exclude选项 touch test1/4 rsync -a --exclude=&quot;4&quot; test1/ test2/ ls test1/ test2/ 另外还可以使用匹配字符* touch test1/1.txt test1/2.txt ls test1/ test2/ rsync -a --progress --exclude=&quot;\*.txt&quot; test1/ test2/ ls test2/ 上例中，连带着使用了–progress选项，这个主要是用来观察rsync同步过程的状态的。 最后简单总结一下，在平时使用rsync同步数据的时候，使用-a选项基本上就可以达到我们想要的效果了，只是有时候有个别的需求，会用到-a -no-OPTION、-u、-L、–delete、–exclude以及–progress这些选项，还有些选项虽然没有介绍，但是在以后的工作中遇到特殊需求了，就去查一下rsync的man文档吧。 2.4. rsync应用实例：通过ssh隧道的方式（干货）在之前介绍的5种方式当中，第二、第三（一个冒号）就属于通过ssh的方式，这种方式其实就是让用户去登陆到远程机器，然后执行rsync的任务。这就需要准备两台Linux机器，因为用到了ssh，所以必须要安装openssh-clients包才可以，两台机器都安装一下：yum install -y openssh-clients。 rsync -avL test1/ www@192.168.0.101:/tmp/test2/ 这种方式就是前面介绍的第二种方式了，是通过ssh拷贝的数据，需要输入192.168.0.101那台机器WWW账户的密码。 rsync -avL www@192.168.0.101:/tmp/test2/ ./test3/ 这种方式就是第三种拷贝的方式了。 如果ssh服务的默认端口该成别的了，那么如何给rsync指定ssh的端口呢？用这个方式：rsync -avPL -e &quot;ssh -p 端口&quot; 源 目的 以上两种方式如果写到脚本里，备份起来就有麻烦看了，因为要输入密码，脚本本来就是自动的，不可能做到。但是不代表没有解决办法，那就是通过密钥验证，密钥不设立密码就ok了。方法如下： 在操作之前我们先讲明主机信息：192.168.0.10（主机名Aming-1）和192.168.0.101（主机名Aming），需要从Aming-1上拷贝数据到Aming上。首先确认一下Aming-1上是否有这个文件/root/.ssh/id_rsa.pub 如果没有这个文件，按照下面的方法生成： ssh-keygen 在这个过程中会有一些交互的过程，它首先提示要输入这个密钥的密码，出于安全考虑应该定义个没密码，但是我们的目的就是为了自动化同步数据，所以这里不输入任何密码，直接回车，即密码为空。最后则生成了私钥（/root/.ssh/id_rsa）和公钥（/root/.ssh/id_rsa.pub）。 把公钥文件的内容拷贝到目标机器上：cat .ssh/id_rsa.pub，复制内容 复制主机Aming-1的/root/.ssh/id_rsa.pub文件内容，并粘贴到主机Aming的/home/www/.ssh/authorized_keys中： vi /home/www/.ssh/authorized_keys 在这一步也许您会遇到/home/www/.ssh目录不存在的问题，可以手动创建，并修改目录权限为600,也可以执行ssh-keygen命令生成这个目录。 保存/home/.ssh/authorized_keys文件后，再到主机Aming-1上执行： ssh www@192.168.0.101 现在不用输入密码也可以登陆主机Aming了。 下面先从Aming主机退出来，再从主机Aming-1上执行一下rsync命令试试吧： rsync -av rsync/test1/ www@192.168.0.101:/tmp/test4/ 2.5. rsync应用实例：通过后台服务的方式（干货）这种方式可以理解成这样，在远程主机上建立一个rsync的服务器，在服务器上配置好rsync的各种应用，然后本机作为rsync的一个客户端去连接远程的rsync服务器。 如何去配置一台rsync服务器呢？如下所示： 建立并配置rsync的配置文件/etc/rsyncd.conf vi /etc/rsyncd.conf 加入如下内容： 123456789101112131415#port=873log file=/var/log/rsync.logpid file=/var/run/rsyncd.pid#address=192.168.0.10[test]path=/root/rsyncuse chroot=truemax connections=4read only=nolist=trueuid=rootgid=rootauth users=testsecrets file=/etc/rsyncd.passwdhosts allow=192.168.0.101 其中的配置文件分为两部分：全局配置部分和模块配置部分。全局部分就是几个参数而已，就像上例中的port、log file、pid file、address这些都属于全局配置，而[test]以下的部分就是模块配置部分了。 一个配置文件中可以有多个模块，模块名自定义，格式就像上例中的这样。其实模块中的一些参数例如use chroot、max connections、uid、gid、auth users、secrets file以及hosts allow都可以配置成全局的参数。当然上例所给出的参数并不是全部的，你可以通过man rsyncd.cong获得更多帮助信息。 下面简单解释一下这些参数的意义： port 指定在哪个端口启动rsync服务，默认是873端口 log file 指定日志文件 pid file 指定pid文件，这个文件的作用涉及到服务的启动以及停止等进程管理操作 address 指定启动rsyncd服务的IP，假如你的机器有多个IP，就可以指定其中一个启动rsyncd服务，默认是在全部IP上启动 [test] 指定模块名，自定义 path 指定数据存放的路径 use chroot true|false 默认是true，意思是在传输文件以前首先chroot到path参数所指定的目录下。这样做的原因是实现额外的安全防护，但是缺点是需要以root权限，并且不能备份指向外部的符号链接所指向的目录文件。默认情况下chroot值为true，如果你的数据当中有软链接文件的话建议设置成false max connections 指定最大的连接数，默认是0,即没有限制 read only true|false 如果为true则不能上传到该模块指定的路径下 list 指定当用户查询该服务器上的可用模块时，该模块是否被列出，设定true列出，false隐藏 uid和gid 指定传输文件时，以哪个用户和组的身份传输 auth users 至i的嗯传输时要使用的用户名 secrets file 指定密码文件，该参数连同上面的参数如果不指定则不使用密码验证，注意该密码文件的权限一定要是600 hosts allow 指定被允许连接该模块的主机，可以是IP或者网段，如果是多个，之间用空格隔开 编辑secrets file，保存后修改权限为600，如果权限不对，不能完成同步 cat /etc/rsyncd.passwd chmod 600 /etc/rsyncd.passwd 启动rsyncd服务 rsync --daemon --config=/etc/rsyncd.conf 启动后，可以查看一下日志，并查看端口是否启动： cat /var/log/rsync.log netstat -lnp | grep 873 如果想开机启动，请把命令rsync --daemon --config=/etc/rsyncd.conf写入到/etc/rc.d/rc.local文件 到另一台机器上测试： rsync -avL test@192.168.0.10::test/test1/ /tmp/test5/ 有一个选项叫做”use chroot”默认为true，如果是true，同步的文件中如果有软链接，则会有问题，而把主机Aming-1的rsync配置文件修改一下，把该配置语句的值设置为false，这样就没有任何问题了。 另外，修改玩rsyncd.conf配置文件后不需要重启rsyncd服务，这是rsync的一个特定机制，配置文件是即时生效的。 可以通过这个命令列出来服务端可使用的rsync的模块：rsync IP:: 2.6. 最后的说明上面的那个例子中，都有输入密码，这样同样也不能写入到脚本中自动执行，其实这种方式也是可以不用手动输入密码的，它有两种实现方式： 指定密码文件 在客户端上，也就是主机Aming上，编辑一个密码文件：vim /etc/pass，在其中加入test用户的密码，保存，修改密码文件的权限为600 在同步的时候，指定一下密码文件，就可以省去输入密码的步骤了 rsync -avL test@192.168.0.10::test/test1/ /tmp/test8/ --password-file=/etc/pass 在rsync服务端不指定用户 在服务端上，也就是主机Aming-1上，修改配置文件rsyncd.conf，删除关于认证账户的配置项（auth user和secrets file这两行），如下： sed -i &#39;s/auth users/#auth users/;s/secrets file/#secrets file/&#39; /etc/rsyncd.conf 上面这条操作就是在文件/etc/rsyncd中把auth users和secrets file这两行的最前面加一个#号，这表示将这两行作为注释，使其失去意义。然后在到客户端上，也就是Aming上进行测试，如下： rsync -avL test@192.168.0.10::test/test1/ /tmp/test9/ 注意这里不用再加test这个用户了，默认是以root身份复制的。现在登陆时已经不需要输入密码了。 3. rsync扩展知识3.1. rsync只同步指定类型的文件需求：同步某个目录下所有的图片（.jpg），该目录下有很多其它类型的文件，但是只想同步.jpg文件。 rsync有一个–exclude可以排除指定文件，还有个–include选项的作用正好和–exclude相反。那直接使用–include=”*.jpg”是否可以呢？ rsync -av --include=&quot;\*.jpg&quot; /src/ /des/ 实验证明，这样是不对的。而正确答案是：rsync -av --include=&quot;.jpg&quot; --exclude= /src/ /des/ 3.2. rsync如何在远程自动创建目录默认情况下，使用rsync的时候，不能自动创建级联目录。比如rsync -a /data/1/2/3/1.txt 1.1.1.1.:/date/1/2/3/1.txt这样会报错的。 所以改一改上面的命令：rsync -a /data/1/2/3/1.txt 1.1.1.1:/data/这样同样也达不到我们想要的效果，这样虽然不再报错，但是这样只是把1.txt放到了1.1.1.1:/data/目录下。 rsync有个选项那就是-R，这个选项会帮助我们自动创建级联目录。所以，上边的命令应该改成这样：rsync -aR /data/1/2/3/1.txt 1.1.1.1:/data/这样就会在1.1.1.1：/data/目录下创建1/2/3/这样的级联目录，类似mkdir -p 3.3. rsync根据一个文件列表文档来同步有时候，有这样的需求，就是根据一个文档中的文件列表来同步文件。举一个例子，1.txt是文件列表，内容如下：123/data/a/a.txt/data/b.txt/data/c/b/c.txt 那么同步的命令应该是：rsync -av --files-from=1.txt / ip::module/ 需要注意的是，1.txt中如果写全局路径，那么source目录需要写成/ OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统服务管理技术]]></title>
    <url>%2F2018%2F01%2F24%2FLinux%2F015.%20Linux%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[GO 有些服务我们日常用不到则要把它们停掉，一来可以节省资源，二来可以减少安全隐患。下面就介绍一下Linux(尤其是红帽系统Linux系统)中的服务管理工具。 1. ntsysv服务配置工具如果没有这个命令请使用yum install -y ntsysv来安装它。这个工具用来配置哪些服务开启或者关闭，有点类似图形界面，不过是使用键盘来控制的。 直接运行命令ntsysv回车后弹出一个配置界面，如图： 按键盘的上下方向键可以调节红色光标，按空格可以选择开启或者不开启，如果前面的括号内显示有*，则表示开启，否则不开启。通过这个工具也可以查看的到目前系统中所有的服务。 建议除”crond、iptables、network、sshd、syslog、irqbalance、sendmail、microcode_ctl”外的其他服务全部停掉。 选择好后，按tab键选择”确定”，然后回车，需要重启机器才能生效。 2. chkconfig服务管理工具CentOS6上的服务管理工具为chkconfig。在CentOS7上也可以使用这个命令，但是通过这个命令来查看的时候只有屈指可数的服务，这是因为CentOS7已经不再延续CentOS6版本的服务管理方案了。 总结： Linux系统所有的预设服务可以查看/etc/init.d/目录得到：ls /etc/init.d/。 系统预设服务都是可以通过这样的命令实现：service 服务名 &quot;start|stop|restart&quot;来控制。 除了可以使用servuce crond start启动crond外，还可以使用/etc/init.d/crond start来启动。 使用chkconfig --list列出所有的服务以及每个级别事都开启。 注意：该输出结果只显示SysV服务，并不包含CentOS7中原生的systemd服务。SysV配置数据可能被原生systemd配置覆盖。 我们还可以使用grep命令把我们想要查看的服务过滤出来：chkconfig --list | grep cron 更改某个级别下服务的开启（一个例子）：chkconfig --level 3 crond off 用–level指定级别，后面是服务名，然后是off或者on，–level后面还可以跟多个级别：chkconfig --level 345 crond off 另外还可以省略级别，默认是针对2,3,4,5级别操作：chkconfig crond on 关于chkconfig： 还有一个功能就是可以把某个服务加入到系统服务，即可以使用service 服务名 start这样的形式，并且可以在chkconfig --list中查找到。当然也能删除掉。 下面的这个功能常用在把自定义的启动脚本加入到系统服务当中。 chkconfig --del crond chkconfig --list | grep cron chkconfig --add crond chkconfig --list | grep cron 3. systemd 服务管理3.1. 介绍CentOS7不适用SysV而改为systemd了，这是因为systemd支持多个服务并发启动，而SysV只能一个一个地启动，这样最终导致的结果是systemd方式启动会块很多。 可以用这个命令列出系统所有的服务，systemctl list-units --all --type=service，示例如下：12345678910[root@theshu ~]# systemctl list-units --all --type=serviceUNIT LOAD ACTIVE SUB DESCRIPTIONaegis.service loaded active running LSB: aegis update.agentwatch.service loaded active exited SYSV: Starts and stops galiyun.service loaded active running auto run aliyunservice oatd.service loaded active running Job spooling toolsauditd.service loaded active running Security Auditing Servicbrandbot.service loaded inactive dead Flexible Branding Serviccloud-config.service loaded active exited Apply the settings speci内容省略... 那么这些服务对应的启动脚本文件在哪里呢？是在/usr/lib/systemd/system/这个目录下面。1234567891011121314151617[root@theshu ~]# ls /usr/lib/systemd/systemsystem/ systemd-quotachecksystemd systemd-random-seedsystemd-ac-power systemd-readaheadsystemd-activate systemd-remount-fssystemd-backlight systemd-reply-passwordsystemd-binfmt systemd-rfkillsystemd-bootchart systemd-shutdownsystemd-cgroups-agent systemd-shutdowndsystemd-coredump systemd-sleepsystemd-cryptsetup systemd-socket-proxydsystemd-fsck systemd-sysctlsystemd-hibernate-resume systemd-sysv-installsystemd-hostnamed systemd-timedatedsystemd-importd systemd-udevdsystemd-initctl systemd-update-done内容省略... 3.2. 与服务相关的命令下面是一些常用的与服务相关的命令的整理： systemctl enable crond.service 让某个服务开机启动（.service可以省略） systemctl disable crond.service 不让开机启动 systemctl status crond.service 查看服务状态 systemctl start crond.service 启动某个服务 systemctl stop crond.service 停止某个服务 systemctl restart crond.service 重启某个服务 systemctl is-enabled crond 查看某个服务是否开机启动 其实关于服务的用法还有不少，但是有上面这些就足够了，足以应对日常的运维工作。 3.3. 一个重要的概念-unit介绍一个很重要的概念，那就是unit。刚刚在上面执行命令ls /usr/lib/systemd/system/的时候，下面有很多文件，其实可以把它们归类为下面这几大类： service：系统服务 target：多个unit组成的组 device：硬件设备 mount：文件系统挂载点 automount：自动挂载点 path：文件或路径 scope：不是由systemd启动的外部进程 slice：进程组 snapshot：systemd快照 socket：进程间通信的套接字 swap：swap文件 timer：定时器 以上每种类型的文件都为一个unit，正是这些unit才组成了系统的各个资源（各个服务，各个设备等）。 下面介绍几个和unit相关的命令（关于unit，在工作中几乎用不到它，所以不多做介绍）： systemctl list-units 列出正在运行（active）的unit systemctl list-units --all 列出所有的unit（包括失败的、inactive的） systemctl list-units --all --state=inactive 列出所有inactive的unit systemctl list-units --all --type=service 列出所有状态的service systemctl list-units --type=service 列出状态为active的service suytemctl is-active crond.service 查看某个unit是否active 3.4. target再来介绍target的概念。target类似与CentOS6里面的启动级别，但target支持多个target同时启动。target其实是多个unit的组合，系统启动说白了就是启动多个unit，而乐管理方便，就使用target来管理这些unit。 查看当前系统的所有target：systemctl list-unit-files --type=target1234567[root@theshu ~]# systemctl list-unit-files --type=targetUNIT FILE STATEbasic.target staticbluetooth.target staticcloud-config.target staticcryptsetup-pre.target static后面省略... 查看一个target包含的所有unit：systemctl list-dependencies *.target12345678910111213141516171819202122[root@theshu ~]# systemctl list-dependencies multi-user.targetmulti-user.target● ├─aegis.service● ├─agentwatch.service● ├─atd.service● ├─auditd.service● ├─brandbot.path● ├─cloud-config.service● ├─cloud-final.service● ├─cloud-init-local.service● ├─cloud-init-upgrade.service● ├─cloud-init.service● ├─crond.service● ├─dbus.service● ├─ecs_mq.service● ├─eni.service● ├─irqbalance.service● ├─kdump.service● ├─network.service● ├─ntpd.service● ├─plymouth-quit-wait.service后面省略... 下面还有几个关于target的命令： systemctl get-default 查看系统默认的target systemctl set-default multi-user.target 设置默认的target 上面提到的multi-user.target等同于CentOS6中的运行级别3，其实还有其他几个target对应0-6运行级别，如下表所示： sysvinit运行级别 systemd目标名称 作用 0 runlevel0.target,poweroff.target 关机 1 runlevel1.target,rescue.target 单用户模式 2 runlevel2.target,multi-user.target 等同于级别3 3 runlevel3.target,multi-user.target 多用户的文本界面 4 runlevel4.target,multi-user.target 等同于级别3 5 runlevel5.target,graphical.target 多用户的图形界面 6 runlevel6.target,reboot.target 重启 emergency emergency.target 紧急Shell 3.5. service、unit与target之间的联系 一个service属于一种unit 多个unit一起组成了一个target 一个target里面包含了多个service 可以查看文件/usr/lib/systemd/system/sshd.service里面[install]部分的内容，它就定义了该service属于哪一个target。 4. 6和7版本对比在RHEL6之前的系统管理系统服务的命令是service、chkconfig等，而在RHEL7系统中则是systemctl命令。其用法如以下表所示： systemctl管理服务的启动、重启、停止、重载、查看状态的命令： Sysvinit命令（红帽RHEL6系统） Systemctl命令（红帽RHEL7系统） 作用 service foo start systemctl start too.service 启动服务 service foo restart systemctl restart foo.service 重启服务 service foo stop systemctl stop foo.service 停止服务 service foo reload systemctl reload foo.service 重新加载配置文件（不终止服务） service foo status systemctl status foo.service 查看服务状态 systemctl设置服务的开机启动、不启动、查看各级别下服务启动状态的命令： Sysvinit命令（红帽RHEL6系统） Systemctl命令（红帽RHEL7系统） 作用 chkconfig foo on systemctl enable foo.service 开机自动启动 chkconfig foo off systemctl disable foo.service 开机不自动启动 chkconfig foo systemctl is-enabled foo.service 查看特定服务是否为开机自启动 chkconfig –list systemctl list-unit-files –type=service 查看各个级别下服务的启动与禁用情况 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux防火墙的简单管理]]></title>
    <url>%2F2018%2F01%2F24%2FLinux%2F014.%20Linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%9A%84%E7%AE%80%E5%8D%95%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[GO 1. SELinux介绍SELinux是RedHat和CentOS系统特有的安全机制。如果能够正确使用它，会使网站非常健壮。不过因为这个东西限制太多，配置也特别繁琐，所以几乎没有人真正应用它（包括腾讯公司也不用）。所以装完系统后，我们一般都要把SELinux关闭，以免引起不必要的麻烦。 关闭SELinux的方法如下： 临时关闭：setenforce 0 永久关闭：编辑配置文件/etc/selinux/config，使”SELinux=disabled”（默认为enforcing）。保存该配置文件后，需要重启LInux系统才能生效。 获取当前SELinux的状态的方法如下： getenforce 如果没有这个命令，需要安装这个包：libselinux-utils。 该命令默认会输出”enforcing”。若是已经永久关闭SELinux了，则会显示”Disabled”。 当使用setenforce 0临时关闭SELinux之后，再使用getendorce会输出”permissive”。 2. 防火墙详解在之前的CentOS版本（比如5或6）的防火墙为netfilter，CentOS7的防火墙为firewalld。而ipdables（netfilter相对应的）只是它的一个实现工具。它的功能非常丰富，但是在日常的管理工作中仅仅会用到一两个应用，这并不代表它不重要。作为一个网络管理员，iptables的各种应用规则是必须要熟练掌握的。但是作为系统管理员，我们也应该会最基本的操作，认识iptables的基本规则。对于CentOS7上的为firewalld，同样也支持之前版本的命令用法。所以下面分别介绍一下这两种的实现工具是如何使用的。 2.1. CentOS6的iptables如果你现在所用的系统是CentOS6或以前的版本，那么系统默认使用的就是iptables这个工具来管理防火墙的。如果你所使用的是CentOS7版本的系统，那么默认使用的是firewalld来管理防火墙。这时，可以将firewalld关闭，然后开启之前版本的iptables，那么就可以在CentOS7上面使用iptables了。操作如下： 12345# systemctl stop firewalld // 关闭firewalld服务# systemctl disable firewalld // 禁止firewalld服务开机启动# yum install -y iptables-services // 安装iptables-services，这样就可以使用之前版本的iptables了# systemctl enable iptables // 让它开机启动# systemctl start iptables // 启动iptables服务 2.1.1. 查看、清除和保存规则CentOS上默认是设有iptables规则的，这个规则虽然很安全，但是对于我们来说没有用，反而会造成某些影响，所以建议你先清除规则，然后把清除后的规则保存一下： iptables -nvL 查看规则 iptables -F ; /etc/init.d/iptables save 防火墙规则保存在了/etc/sysconfig/iptables中。 关于上面两条命令的说明：-nvL选项是查看规则，-F是把当前规则清除，但这个只是临时的，重启系统或者重启iptables服务后还会夹在已经保存的规则，所以需要使用/etc/init.d/iptables save保存一下规则。当然，service iptables save的效果是一样的，也是保存防火墙的规则。 iptables -Z 将防火墙中的计数清零 2.1.2. iptables的5个表和5个链五个表如下： filter表 这个表主要用于过滤包的，是系统预设的表，这个表也是工作中用的最多的。 内建三个链：INPUT、OUTPUT、FORWARD。 INPUT作用于进入本机的包，OUTPUT作用于本机送出的包，FORWARD作用于那些跟本机无关的包。 nat表 主要用处是网络地址转换，比如公网IP和内网IP之间的转换。也有三个链。 PREROUTING链的作用是在包刚刚到达防火墙时改变它的目的地址（如果需要的话）。 OUTPUT链的作用是改变本地产生的包的目的地址。 POSTROUTING链的作用是在包就要离开防火墙之前改变其源地址。 这个表在工作中用的不多，但偶尔会用到。 mangle表 这个表主要用于给数据包作标记，然后根据标记去操作哪些包。 这个表几乎不怎么用。除非你想成为高级网络工程师，否则就不需要关注。 raw表 这个表可以实现不追踪某些数据包，默认系统的数据包都会被追踪，但追踪势必消耗一定的资源，所以可以用raw表来指定某些端口的包不被追踪。 只有两个链：OUTPUT、PREROUTING。 这个表从来不用。 security表 这个表在CentOS6中是没有的，它用于强制访问控制（MAC）的网络规则。 这个表也不会被用到，所以不需要关注。 五个链如下： PREROUTING链：数据包进入路由表之前 INPUT链：通过路由表后目的地为本机 FORWARDING链：通过路由表后，目的地不为本机 OUTPUT链：由本机产生，向外转发 POSTROUTING链：发送到网卡接口之前 说明： INPUT 进来的-d：local本地（目标） OUTPUT 出去的-s：local本地（源） 2.1.3. iptables的基本语法查看规则以及清除规则 iptables -t nat -nvL -t后面跟表名，-nvL即查看该表的规则，其中-n表示不针对IP反解析主机名，-L表示列出的意思，而-v表示列出的信息更加详细。 如果不加-t，则打印filter表的相关信息：iptables -nvL（这和加上-t filter选项后打印的信息是一样的） 关于清除规则的命令中，用的最多的就是： iptables -F -F表示把所有规则全部删除 iptables -Z -Z表示把包以及流量计数器置零（这个功能很有用） 增加或删除一条规则 iptables -A INPUT -s 10.72.11.12 -p tcp --sport 1234 -d 10.72.137.159 --dport 80 -j DROP 这就是增加了一条规则，省略-t所以针对的是filter表。 -A表示增加一条规则（放到最后），另外还有-I（大写i）表示插入一条规则（放到嘴前），-D表示删除一条规则。 后面的INPUT即链名称，还可以是OUTPUT或者FORWARD。 -s后面跟源地址。（来处） -p 协议（tcp、udp、icmp） –sport/–dport 后跟源端口/目标端口。（–dport/–sport必须要和-p选项一起使用，否则会出错）。 -d 后面跟目的IP（主要针对内网或者外网）。 -j 后跟动作（DROP即把包丢掉，ERJECT即包拒绝，ACCEPT即允许包）。 几个例子： iptables -I INPUT -s 1.1.1.1 -j DROP表示：插入一条规则，把来自1.1.1.1的所有数据包丢掉。 iptables -D INPUT -s 1.1.1.1 -j DROP表示：删除刚刚插入的规则。注意，要删除一条规则时，必须和插入的规则一直，也就是说，两条iptables命令，除了-I和-D选项不一样之外，其他地方都一样。 iptables -I INPUT -s 2.2.2.2 -p tcp --dport 80 -j DROP表示：把来自2.2.2.2并且是TCP协议到本机的80端口的数据包丢掉。 iptables -I OUTPUT -p tcp --dport 22 -d 10.0.1.14 -j DROP表示：把发送到10.0.1.14的22端口的数据包丢掉。 iptables -A INPUT -s 192.168.1.0/24 -i eth0 -j ACCEPT表示：把来自192.168.1.0/24这个网段的并且作用在eth0网卡上的包放行。 规则总结： -A/-D ：增加或删除一条规则 -I ：插入一条规则，其实跟-A的效果差不多（如果想让一条规则最优先生效，那么就用-I插入一条规则） -p ：指定协议，可以是tcp、udp、icmp –dport ：跟-p一起使用，指定目标端口 –sport ：跟-p一起使用，指定源端口 -s ：指定源IP（可以是一个IP段） -d ：指定目的IP（可以是一个IP段） -j ：后跟动作，其中ACCEPT表示允许包，DROP表示丢掉包，REJECT表示拒绝包 -i ：指定网卡（不常用，但有时候能够用到） 2.1.4. 删除一条规则的简便方法当iptables的规则过多时，想删除某一条规则时，又不容易掌握当时创建时的规则。其实有一种比较简单的方法，如下所示： iptables -nvL --line-numbers 查看规则的内容和编号 iptables -D INPUT 1 删除编号为1的规则 -D后面跟链名，然后是规则编号n，这个n就是查看iptables规则时第一列的值。 2.1.5. iptables的-P（大写）选项iptables还有一个选项经常用到，就是-P（大写），表示预设策略。用法如下： iptables -P INPUT DROP 说明：-P后面跟链名，策略内容或者为DROP或者为ACCEPT，默认是ACCEPT。 注意：如果你在远程链接服务器，千万不要随便敲这个命令，因为一旦敲完回车后你就会断掉。 这个策略一旦设定后，只能使用iptables -P INPUT ACCEPT才能回复成原始状态，而不能使用-F参数。 下面针对一个小需求讲解一下这个iptables规则如何设定：、 需求：之针对filter表，预设策略INPUT链DROP，其他两个ACCEPT，然后针对192.168.137.0/24开通22端口，对所有网段开放80端口，对所有网段开放21端口。 解决方法：这个需求不算复杂，但是因为有很多条规则，所以最好写成脚本的形式。脚本内容如下： 123456789# cat /usr/local/sbin/iptables.sh#!/bin/bashipt="/sbin/iptables"$ipt -P INPUT DROP$ipt -P OUTPUT ACCEPT$ipt -P FORWARD ACCEPT$ipt -A INPUT -s 192.168.137.0/24 -p tcp --dport 22 -j ACCEPT$ipt -A INPUT -p tcp --dport 80 -j ACCEPT$ipt -A INPUT -p tcp --dport 21 -j ACCEPT 完成脚本的编写后，直接运行/bin/sh /usr/local/sbin/iptables.sh即可。 如果想开机启动时初始化防火墙规则，则需要在/etc/rc/d/rc.local中添加一行/bin/sh /usr/local/sbin/iptables.sh 2.1.6. 关于icmp的包的一个常见应用iptables -I INPUT -p icmp --icmp-type 8 -j DROP 说明：--icmp-type这个选项要跟-p icmp一起使用的，后面指定类型编号。这个8指的是能在本机ping通其他机器，而其他机器不能ping通本机。这个有必要记一下。 2.1.7. nat表的应用引言：在日常生活中相信你接触过路由器吧，它的功能就是分享上网。本来一根网线过来（其实只有一个公网IP），通过路由器后，路由器分配了一个网段（私网IP），这样连接路由器的多台设备就都能够连接网络了。而远端的设备认为你的IP就是那个连接路由器的公网IP。这个luyouqi的功能其实就是由Linux的netfilter的nat表实现的。 需求：假设你的机器上有两块网卡eth0和eth1，其中eth0的IP为10.0.2.68，eth1的IP为192.168.1.1。eth0连接了网络，但eth1没有连接，现在有另一台机器（192.168.1.2）和eth1是互通的，那么如何设置也能够让连接eth1的这台机器能够连上网络呢（即能和10.0.2.68互通）？ 解决方法如下： echo &quot;1&quot; &gt; /proc/sys/net/ipv4/ip forward iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -o eth0 -j MASQUERADE 说明： 就是这样简单的两条命令就能实现上面的需求。第一个命令涉及到了内核参数相关的配置文件，它的目的是为了打开路由转发的功能，否则无法实现我们的应用。 第二个命令则是对nat表做了一个IP转发的操作，-o选项后面跟设备名，表示出口的网卡，MASQUERADE表示伪装的意思。 关于nat表，暂时先不讲太多内容，只需要学会这个路由转发即可。 2.1.8. 保存以及备份iptables规则 保存： 设定的防火墙规则只是保存在内存中，并没有保存到某一个文件中，也就是说当系统重启后以前设定的规则就没有了，所以设定规则后要先保存一下。、 service iptables save 它会提示防火墙规则保存在了/etc/sysconfig/iptables文件内，这个文件就是iptables的配置文件了。 备份： 所谓防火墙的备份就是把防火墙的配置文件/etc/sysconfig/iptables备份一下 有时候我们会需要把防火墙的所有规则都清除，使用iptables -F命令虽然可以，但是最好的办法是把防火墙服务停止： service iptables stop 说明：这样防火墙就失效了，但是一旦重新设定规则后（哪怕只有一条），防火墙服务就会自动开启。 一个用来备份和还原防火墙规则的命令： 备份：iptables-save &gt; myipt.rule 还原：iptables-restore &lt; myipt.rule 2.1.9. iptables的扩展内容 iptables应用在一个网段： 一个例子：iptables -I INPUT -m iprange --src-range 61.4.176.0-61.4.191.255 -j DROP 2.2. CentOS7的firewalldCentOS7版本中集成了多款防火墙管理工具，其中firewalld（Dynamic Firewall Manager of Linux system，Linux系统的动态防火墙管理器）服务是默认的防火墙配置管理工具，它拥有基于CLI（命令行界面）和基于GUI（图形用户界面，工具是firewall=config）的两种管理方式。 相较于传统的防火墙管理配置工具，firewalld支持动态更新技术并加入了区域（zone）的概念，还有一个service的概念。简单来说，区域就是firewalld预先准备了几套防火墙策略集合（策略模板），用户可以根据生产场景的不同而选择合适的策略集合，从而实现防火墙策略之间的快速切换。 2.2.1. 9个zone介绍firewalld中常见的区域名称（默认为public）以及相应的策略规则如下表所示： 区域 默认策略规则 trusted(信任) 允许所有的数据包 home(家庭) 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、mdns、ipp-client、amba-client与dhcpv6-client服务相关，则允许流量 internal(内部) 等同于home work(工作) 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、ipp-client与dhcpv6-client服务相关，则允许流量 public(公共) 拒绝流入的流量，除非与流出的流量相关；而如果流量与ssh、dhcpv6-client服务相关，则允许流量 external(外部) 特别是为路由器启用了伪装功能的外部网。你不能信任来自网络的其它计算，不能相信它们不会对你的计算机造成危害，只能接受经过选择的连接 dmz(非军事区) 用于你的非军事区内的计算机，此区域内可公开访问，可以有限地进入你的内部网络，仅仅接收经过选择的连接 block(限制) 任何接收的网络连接都被IPv4的icmp-host-prohibited信息和IPv6的icmp6-adm-prohibited信息所拒绝 drop(丢弃) 任何接收的网络数据包都被丢弃，没有任何回复。仅能有发送出去的网络连接 对于以上9个zone简单了解即可，因为这些在日常工作中使用它们的机会不会太多。下面是一些关于zone的命令： firewall-cmd --set-default-zone=work 设定默认的zone为work firewall-cmd --get-zone-of-interface=ens33 查看指定网卡所在的zone firewall-cmd --zone=public --add-interface=lo 给指定网卡设置zone firewall-cmd --zone=dmz --change-interface=lo 针对网卡更改zone firewall-cmd --zone=dmz --remove-interface=lo 针对网卡删除zone firewall-cmd --get-active-zones 查看系统所有网卡所在的zone firewall-cmd --get-zones 查看系统所有的zone firewall-cmd --get-default-zone 查看系统默认的zone 2.2.2. service介绍其实，之所以有9种zone，是因为每一个zone里面都使用了不同的service，而service就是针对一个服务（端口）做的iptables规则。 这个命令可以列出系统所有的service：firewall-cmd --get-service123456789101112131415[root@theshu ~]# firewall-cmd --get-serviceRH-Satellite-6 amanda-client amanda-k5-client bacula bacula-clientbitcoin bitcoin-rpc bitcoin-testnet bitcoin-testnet-rpc ceph ceph-mon cfengine condor-collector ctdb dhcp dhcpv6 dhcpv6-client dns docker-registry dropbox-lansync elasticsearch freeipa-ldap freeipa-ldaps freeipa-replication freeipa-trust ftp ganglia-client ganglia-master high-availability http https imap imaps ipp ipp-client ipsec iscsi-target kadmin kerberos kibana kloginkpasswd kshell ldap ldaps libvirt libvirt-tls managesieve mdns mosh mountdms-wbt mssql mysql nfs nrpe ntp openvpn ovirt-imageio ovirt-storageconsole ovirt-vmconsole pmcd pmproxy pmwebapi pmwebapis pop3 pop3s postgresql privoxy proxy-dhcp ptp pulseaudio puppetmaster quassel radius rpc-bind rsh rsyncd sambasamba-client sane sip sips smtp smtp-submission smtps snmp snmptrap spideroak-lansync squid ssh synergy syslog syslog-tls telnet tftp tftp-client tinc tor-socks transmission-client vdsm vnc-server wbem-https xmpp-bosh xmpp-client xmpp-local xmpp-server 这些service都是由一个个配置文件定义的，配置文件的模板在/usr/lib/firewalld/services/目录下，真正生效的配置是在/etc/firewalld/service/目录下面（默认为空）12345678910111213141516171819202122232425262728293031323334353637[root@theshu ~]# ls /usr/lib/firewalld/services/amanda-client.xml kadmin.xml quassel.xmlamanda-k5-client.xml kerberos.xml radius.xmlbacula-client.xml kibana.xml RH-Satellite-6.xmlbacula.xml klogin.xml rpc-bind.xmlbitcoin-rpc.xml kpasswd.xml rsh.xmlbitcoin-testnet-rpc.xml kshell.xml rsyncd.xmlbitcoin-testnet.xml ldaps.xml samba-client.xmlbitcoin.xml ldap.xml samba.xmlceph-mon.xml libvirt-tls.xml sane.xmlceph.xml libvirt.xml sips.xmlcfengine.xml managesieve.xml sip.xmlcondor-collector.xml mdns.xml smtp-submission.xmlctdb.xml mosh.xml smtps.xmldhcpv6-client.xml mountd.xml smtp.xmldhcpv6.xml mssql.xml snmptrap.xmldhcp.xml ms-wbt.xml snmp.xmldns.xml mysql.xml spideroak-lansync.xmldocker-registry.xml nfs.xml squid.xmldropbox-lansync.xml nrpe.xml ssh.xmlelasticsearch.xml ntp.xml synergy.xmlfreeipa-ldaps.xml openvpn.xml syslog-tls.xmlfreeipa-ldap.xml ovirt-imageio.xml syslog.xmlfreeipa-replication.xml ovirt-storageconsole.xml telnet.xmlfreeipa-trust.xml ovirt-vmconsole.xml tftp-client.xmlftp.xml pmcd.xml tftp.xmlganglia-client.xml pmproxy.xml tinc.xmlganglia-master.xml pmwebapis.xml tor-socks.xmlhigh-availability.xml pmwebapi.xml transmission-client.xmlhttps.xml pop3s.xml vdsm.xmlhttp.xml pop3.xml vnc-server.xmlimaps.xml postgresql.xml wbem-https.xmlimap.xml privoxy.xml xmpp-bosh.xmlipp-client.xml proxy-dhcp.xml xmpp-client.xmlipp.xml ptp.xml xmpp-local.xmlipsec.xml pulseaudio.xml xmpp-server.xmliscsi-target.xml puppetmaster.xml 因为每个zone里面都有不同的service，可以用如下命令来查看一个zone下面有哪些service： firewall-cmd --list-services 查看当前zone下有哪些service firewall-cmd --zone=public --list-services 查看指定zone下有哪些service 1234[root@theshu ~]# firewall-cmd --list-servicessh dhcpv6-client[root@theshu ~]# firewall-cmd --zone=public --list-servicesssh dhcpv6-client 一个zone下面有某个service，意味着这个service是被信任的。比如，当前zone下面有ssh，那么ssh服务（也就是22）端口是方形的。我们可以给一个zone添加一个service，命令如下： firewall-cmd --zone=public --add-service=http 把http添加到public zone下面1234[root@theshu ~]# firewall-cmd --zone=public --add-service=httpsuccess[root@theshu ~]# firewall-cmd --list-servicesssh dhcpv6-client http 对于每个zone来说，都有自己的配置文件，你可以查看目录/usr/lib/firewalld/zones/下面对应的文件，这些就是zone的配置文件：123[root@theshu ~]# ls /usr/lib/firewalld/zones/block.xml drop.xml home.xml public.xml work.xmldmz.xml external.xml internal.xml trusted.xml 上面所说的可以在一个zone里面添加一个service的方法，仅仅是在内存中生效，并没有修改配置文件，如果想修改配置文件，需要加一个选项--permanent，如下：12[root@theshu ~]# firewall-cmd --zone=public --add-service=http --permanentsuccess 一旦更改了某个zone的配置文件，则会在/etc/firewalld/zones/目录下面生成对应zone的配置文件（.xml后缀的文件），其实这个目录下面的配置文件才是真正的配置文件。而上面所介绍的目录，可以说是所有zone的模板配置文件。 2.2.3. firewalld的一个示例通过这个示例可以更方便的理解zone和service这两个概念。 需求：假如服务器上配置了一个FTP服务，但端口并非默认的21，而是1121，并且需要在woek zone下面放行FTP。 具体做法如下：12345678910111213# cp /usr/lib/firewalld/services/ftp.xml /etc/firewalld/services/ # vi /etc/firewalld/services/ftp.xml //把里面的21改为1121# cp /usr/lib/firewalld/zones/work.xml /etc/firewalld/zones/# vi /etc/firewalld/zones/work.xml //在里面添加一行FTP相关的配置，内容如下：&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;zone&gt; &lt;short&gt;Work&lt;/short&gt; &lt;description&gt;For use in work areas. You mostly trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted.&lt;/description&gt; &lt;service name="ssh"/&gt; &lt;service name="ftp"/&gt; &lt;service name="dhcpv6-client"/&gt;&lt;/zone&gt;# firewall-cmd --reload //重新加载 再来验证一下work zone里面的service是否有FTP：12# firewall-cmd --zone=work --list-servicesssh ftp dhcpv6-client 2.2.4. firewall-cmd命令及其常用参数总结 参数 作用 –get-zones 查看系统所有可用的zone –get-default-zone 查看系统默认的zone –set-default-zone=work 设定默认的zone为work –get-services 显示预先定义的服务 –get-active-zones 查看系统所有网卡所在的zone –add-source= 将源自此IP或子网的流量导向某个指定区域 –remove-source= 不再将源自此IP或子网的流量导向某个指定区域 –add-interface=网卡名称 将源自该网卡的所有流量都导向某个指定区域 –change-interface=网卡名称 将某个网卡与区域进行关联 –remove-interface=网卡名称 将某个网卡与区域取消关联 –get-zone-of-interface=ens33 查看指定网卡所在的zone –zone=public –add-interface=lo 给指定网卡设置zone –zone=dmz –change-interface=lo 针对网卡更改zone –zone=dmz –remove-interface=lo 针对网卡删除zone –list-all 显示当前区域的网卡配置参数、资源、端口以及服务等信息 –list-all-zones 显示所有区域的网卡配置参数、资源、端口以及服务等信息 –add-service=服务名 设置默认区域允许该服务的流量 –add-port=端口号/协议 设置默认区域允许该端口的流量 –remove-service=服务名 设置默认区域不再允许该服务的流量 –remove-port=端口好/协议 设置默认区域不再允许该端口的流量 –permanent 让配置的防火墙策略永久生效 –reload 让“永久生效”的配置规则立即生效，并覆盖当前的配置规则 –panic-on 开启应急状态模式 –panic-off 关闭应急状态模式 2.2.5. firewalld的一些实验 查看firewalld服务当前所使用的区域：firewall-cmd get-default-zone 显示public 查询eno16777728网卡在firewalld服务中的区域：firewall-cmd --get-zone-of-interface=eno16777728 显示public 把firewalld服务中eno16777728网卡的默认区域修改为external，并在系统重启后生效。分别查看当前与永久模式下的区域名称： firewall-cmd --permanent --zone=external --change-interface=eno16777728 显示success firewall-cmd --get-zone-of-interface=eno16777728 显示public firewall-cmd --permanent --get-zone-of-interface=eno16777728 显示external 把firewalld服务的当前默认区域设置为public： firewall-cmd --set-default-zone=public 显示success firewamm-cmd --get-default-zone 显示public 启动/关闭firewalld防火墙服务的应急状况模式，阻断一切网络连接（当远程控制服务器时请慎用）： firewall-cmd --panic-on 显示success firewall-cmd --panic-off 显示success 查询public区域是否允许请求SSH和HTTPS协议的流量： firewall-cmd --zone=public --query-service=ssh 显示yes firewall-cmd --zone=public --query-service=https 显示no 把firewalld服务中请求HTTPS协议的流量设置为永久允许，并立即生效： firewall-cmd --zone=public --add-service=https 显示success firewall-cmd --permanent --zone=public --add-service=https 显示success firewall-cmd --reload 显示success 把firewalld服务中请求HTTP协议的流量设置为永久拒绝，并立即生效： firewall-cmd --permanent --zone=public --remove-service=http 显示success firewall-cmd --reload 显示success 把在firewalld服务中访问8080和8081端口的流量策略设置为允许，但仅限当前生效： firewall-cmd --zone=public --add-port=8080-8081/tcp 显示success firewall-cmd --zone=public --list-ports 显示8080-8081/tcp 把原本访问本机888端口的流量转发到22端口，且要求当前和长期均有效： 注意：流量转发的命令格式为firewall-cmd --permanent --zone=区域 --add-forward-port=port=源端口号:proto=协议:toport=目标端口号:toaddr=目标IP地址 firewall-cmd --permanent --zone=public --add-forward-port=port=888:proto=tcp:toport=22:toaddr=192.168.10.10 显示success firewall-cmd --reload 显示success firewalld中锋富规则表示更细致、更详细的防火墙策略配置，它可以针对系统服务、端口号、源地址和目标地址等诸多信息进行更有针对性的策略配置。它的优先级在所有的防火墙策咯中也是最高的。比如，我们可以在firewalld服务中配置一条富规则，使其拒绝192.168.10.0/24网段的所有用户访问本机的ssh服务（22端口），如下所示：1234# firewall-cmd --permanent --zone=public --add-rich-rule="rule family="ipv4" source address="192.168.10.0/24" service name="ssh" reject"success# firewall-cmd --reloadsuccess 在客户端使用ssh命令尝试访问192.168.10.10主机的ssh服务（22端口）：123# ssh 192.168.10.10Connecting to 192.168.10.10:22...Could not connect to '192.168.10.10' (port 22): Connection failed. 3. 服务的访问控制列表服务的访问控制列表指的是这两个文件： /etc/hosts.allow：允许控制列表文件 /etc/hosts.deny：拒绝控制列表文件 TCP Wrappers 是 CentOS7系统中默认启用的一款流量监控程序，它能够根据来访主机的地址与本机的目标服务程序做出允许或拒绝的操作。换句话说，Linux系统中其实有两个层面的防火墙，第一种是前面讲到的基于TCP/IP协议的流量过滤工具，而TCP Wrappers服务则是能允许或禁止Linux系统提供服务的防火墙，从而在更高层面保护了Linux系统的安全运行。 TCP Wrappers服务的防火墙策略由两个控制列表文件所控制，用户可以编辑允许控制列表文件来放行对服务的请求流量，也可以编辑拒绝控制列表文件来阻止对服务的请求流量。控制列表文件修改后会立即生效，系统将会先检查允许控制列表文件（/etc/hosts.allow），如果匹配到相应的允许策略则放行流量；如果没有匹配，则会进一步匹配拒绝控制列表文件（/etc/hosts.deny），若找到匹配项则拒绝该流量。如果这两个文件都没有匹配到，则默认放行流量。 3.1. 常用参数和原则TCP Wrappers服务的控制列表文件配置起来并不复杂，常用参数如下表所示： 客户端类型 示例 满足示例的客户端列表 单一主机 192.168.10.10 IP地址为192.168.10.10的主机 指定网段 192.168.10. IP段为192.168.10.0/24的主机 指定网段 192.168.10.0/255.255.255.0 IP段为192.168.10.0/24的主机 指定DNS后缀 .theshu.top 所有DNS后缀为.theshu.top的主机 指定主机名称 www.theshu.top 主机名称为www.theshu.top的主机 指定所有客户端 ALL 所有主机全部包括在内 在配置TCP Wrappers服务时需要遵循两个原则： 编写拒绝策略规则时，填写的是服务名称，而非协议名称 建议先编写拒绝策略规则，再编写允许策略规则，以便直观地看到相应的效果 3.2. 示例下面编写拒绝策略规则文件，禁止访问本机sshd服务的所有流量（无需/etc/hosts/deny文件中修改原有的注释信息）：123456789101112131415161718192021[root@theshu ~]# vim /etc/hosts.deny## hosts.deny This file contains access rules which are used to# deny connections to network services that either use# the tcp_wrappers library or that have been# started through a tcp_wrappers-enabled xinetd.## The rules in this file can also be set up in# /etc/hosts.allow with a 'deny' option instead.## See 'man 5 hosts_options' and 'man 5 hosts_access'# for information on rule syntax.# See 'man tcpd' for information on tcp_wrappers#####SSH BlackList START##### NEU SSH Black list + sshbl.org + Dragon Research Group (DRG) hosts.deny# Mon Feb 5 12:57:42 CST 2018#sshd:*[root@theshu ~]# ssh 192.168.10.10ssh_exchange_identification: read: Connection reset by peer 接下来，在允许策咯规则文件中添加一条规则，使其放行源自192.168.10.0/24网段，访问本机sshd服务的所有流量。可以看到，服务器立刻就放行了访问sshd服务的流量。，效果非常直观：1234567891011121314[root@theshu ~]# vim /etc/hosts.allow## hosts.allow This file contains access rules which are used to# allow or deny connections to network services that# either use the tcp_wrappers library or that have been# started through a tcp_wrappers-enabled xinetd.## See 'man 5 hosts_options' and 'man 5 hosts_access'# for information on rule syntax.# See 'man tcpd' for information on tcp_wrappers#sshd:192.168.10.//ssh连接步骤省略，可以连上。 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux程序管理技术]]></title>
    <url>%2F2018%2F01%2F20%2FLinux%2F013.%20Linux%E7%A8%8B%E5%BA%8F%E7%AE%A1%E7%90%86%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[GO 1. 什么是进程（process）在Linux系统中，触发任何一个事件时，系统都会将它定义为一个进程，并且给予这个进程一个ID，称为PID，同时依据触发这个进程的用户与相关属性关系，给予这个PID一组有效的权限设置。从此以后，这个PID能够在系统上面进行的操作，就与这个PID的权限有关了。 1.1. 进程与程序（process &amp; program） 程序（program）：通常为二进制程序放置在存储媒介中（如硬盘、光盘等），以物理文件的形式存在。 进程（process）：程序被触发后，执行者的权限与属性、程序的程序代码与所需数据等都会被加载到内存中，操作系统并给予这个内存内的单元一个标识符（PID），可以说，进程就是一个正在运行中的程序。 父进程与子进程：举例说明，原本运行中的bash就是父进程，被父进程触发的另一个bash就是子进程。 过程调用的流程：在Linux的过程调用中通常称为fork-and-exec的流程。进程都会通过父进程以复制（fork）的方式产生一个一模一样的子进程，然后被复制出来的子进程再以exec的方式来执行实际要进行的进程，最终就成为一子进程的存在。 服务：常驻内存的进程称为服务（daemon）。 1.2. Linux的多用户、多任务环境 多用户：系统中有一个root用户具有所有的权限。其它的用户都有各自的UID。多个用户可同时的登陆到系统上进行工作。 多任务：由于Linux的特性，运行多个任务同时进行（属于CPU调度）。 多重登陆：用一个用户可重复登陆多个终端，方便管理工作。 特殊的进程管理行为：进程管理和工作管理，能够很好的为管理人员提供很方便的管理方式。 2. 工作管理（job control）这个管理工作（job control）是用在bash环境下的，也就是说：当我们登陆系统取得bash shell之后，在单一终端下同时进行多个工作的行为管理。 2.1. 什么是工作管理在进行工作管理的行为中，其实每个工作都是目前bash的子进程，即彼此之间是有相关性的。我们无法以 job control 的方式由 tty1 的环境去管理 tty2 的bash。 我们可以在/etc/security/limits.conf里面设置用户同时可以登陆的连接数，在这样的情况下，某些用户可能仅能以一个连接来工作！ 由于假设我们只有一个终端，因此在可以出现提示符让你操作的环境就称为前台（foreground），至于其它工作就可以让你放入后台（background）去暂停或运行。要注意的是，放入后台的工作想要运行时，它必须不能够与用户互动。而且放入后台的工作是不能使用Ctrl+C的方式来终止的。 总之，要进行 bash 的 job control 必须要注意到的限制是： 这些工作所触发的进程必须来自于你shell的子进程（只管理自己的bash）。 前台：你可以控制与执行命令的这个环境称为前台（foreground）的工作。 后台：可以自行运行的工作，你无法使用Ctrl+C来终止它，可使用bg/fg调用该工作。 后台中执行的进程不能等待terminal/shell的输入（input） 2.2. job control的管理bash只能够管理自己的工作而不能管理其它bash的工作，此外，又分为前台和后台，而后台里面的工作状态又可以分为暂停（stop）、运行中（running）。实际进行的job控制的命令如下： 2.2.1. &amp; 直接将命令丢到后台中执行使用方式：conmmand &amp; 一个例子：将/etc/整个备份成为/tmp/etc.tar.gz且不要等待，可以这样做：123[root@AmingLinux-105 ~]# tar -zpcf /tmp/etc.tar.gz /etc &amp;[1] 1693[root@AmingLinux-105 ~]# tar: Removing leading `/' from member names 说明： 在括号内的号码为工作号码（job number），该号码与bash的控制有关。但它既然是个命令触发的，所以当然一定是一个进程，因此还会查看到有 job number 也搭配一个PID。 后续的 1693 则是这个工作在系统中的 PID。至于后续出现的数据是 tar 执行的数据流。 由于我们没有加上数据流重定向，所以会影响界面，但是却不会影响前台的操作。 当这个后台运行的程序完成的时候，会出现类似下面的信息：1[1]+ 完成 tar -zpcf /tmp/etc.tar.gz /etc 为了防止这个后台运行的程序的数据流会出现在屏幕上，妨碍我们的继续的操作，可以这样做，就是利用重定向将数据流重定向到文件，如下：12[root@AmingLinux-105 ~]# tar -zpcvf /tmp/etc.tar.gz /etc &gt; /tmp/log.txt 2&gt;&amp;1 &amp;[1] 1943 如此一来，输出的信息都传送到/tmp/log.txt当中，就不会影响到前台的工作了。 2.2.2. Ctrl+Z 将目前的工作丢到后台中暂停使用Ctrl+Z可以把当前工作的进程暂停掉并将它丢到后台，这样我们又取得了前台的操控权。示例如下：12345678[root@AmingLinux-105 ~]# vim ~/.bashrc# 在Vim的一般模式下，按下 Ctrl+Z 这两个键[1]+ Stopped vim ~/.bashrc[root@AmingLinux-105 ~]# &lt;==顺利取得了前台的控制权[root@AmingLinux-105 ~]# sleep 100^Z &lt;==继续按 Ctrl+Z 暂停这个工作[2]+ Stopped sleep 100[root@AmingLinux-105 ~]# 说明： 当按下 Ctrl+Z 后，屏幕上会出现[1]，表示这是第一个工作。 那个+代表最近一个被丢进后台的工作，且目前在后台下默认会被取用的那个工作（与fg这个命令有关）。 Stopped则代表目前这个工作的状态，在默认的情况下，使用Ctrl+Z丢到后台当中的工作都是“暂停”的状态。 2.2.3. Ctrl+C 将目前的工作终止掉使用Ctrl+C可以终止正在前台运行的进程，它并不能终止后台暂停或后台运行的进程。 2.2.4. job 查看目前的后台工作状态jobs的使用方法：jobs [-lrs] 选项 意义 -l 除了列出 job number 与命令串之外，同时列出 PID 的号码 -r 仅列出正在后台 run 的工作 -s 仅列出正在后台当中暂停（stop）的工作 范例：查看目前的bash当中，所有的工作，与对应的PID：123[root@AmingLinux-105 ~]# jobs -l[1]- 1949 停止 vim ~/.bashrc[2]+ 1950 停止 sleep 100 说明： 一般来说，直接执行jobs即可 若是想要知道该 job number 的PID号码，可以加上-l这个参数 在输出信息中，那个+代表默认的取用工作，如果我目前有两个工作在后台当中，两个工作都是暂停的，而如果我仅输入fg时，那么哪个[2]所代表的工作会被拿到前台当中来处理 其实+代表最近被放到后台的工作号码，-代表最近最后第二个被放置到后台中的工作号码。而如果超过最后三个以后的工作，就不会有+/-了 2.2.5. fg 将后台工作拿到前台来处理使用方法：fg %jobnumber %jobnumber : jobnumber为工作号码（数字），注意，那个%是可有可无的。 范例：先以 jobs 查看工作，再将工作取出：12345678910[root@AmingLinux-105 ~]# jobs[1]- 已停止 vim ~/.bashrc[2]+ 已停止 sleep 100[root@AmingLinux-105 ~]# fgsleep 100 &lt;==再按下Ctrl+Z[root@AmingLinux-105 ~]# fg %1vim ~/.bashrc &lt;==再按下Ctrl+Z[1]+ 已停止 vim ~/.bashrc[root@AmingLinux-105 ~]# 2.2.6. bg 让工作在后台下的状态变成运行中使用方法：bg %jobnumber %jobnumber : jobnumber为工作号码（数字），注意，那个%是可有可无的。 使用这个命令后，再用jobs查看后台进程就会发现后台的进程的状态变为Running了。 2.2.7. kill 管理后台当中的工作可以用 kill 工具来管理后台当中的工作。用法：kill -signal %jobnumber 通常我们在管理工作的用法是这样的：kill -9 %jobnumber 说明： -9的意思是强制删除一个不正常的工作。 kill后面接的数字默认是PID，如果想要管理bash的工作控制，就得加上%数字了。 kill的详细用法参考下面的进程管理章节。 2.3. 脱机管理问题其实，我们在工作管理当中提到的“后台”指的是在终端机模式下可以避免Ctrl+C中断的一个情境，并不是放到系统的后台去。所以，工作管理的后台依旧与终端机有关。在这样的情况下，如果是以远程连接的方式连接到Linux主机，并且将工作以&amp;的方式放到后台去，这样，在工作尚未结束的情况下脱机了，该工作就会被中断掉。 那如何解决这个问题？如果我的工作需要进行一大段时间，我又不能防止在后台下面，那该如何处理？ 首先，我们可以利用at等工具来处理即可，因为at是将工作放置到系统后台，而与终端机无关。 另外，可以尝试使用nohup这个命令来处理。这个nohup可以让你在脱机或注销系统后，还能够让工作继续进行。它的语法如下： nohup [命令与参数] 在终端机前台中工作 nohup [命令与参数] &amp; 在终端机后台中工作 上面需要注意的是，nohup并不支持bash内置的命令，因此你的命令必须要是外部命令才行。下面是一个例子：12345678910111. 先编辑一个会“睡着500秒”的程序：[root@theshuhost ~]# vim sleep500.sh#!/bin/bash/bin/sleep 500s/bin/echo "I have slept 500 seconds."2. 丢到后台去执行，并且立刻注销系统：[root@theshuhost ~]# chmod a+x sleep500.sh[root@theshuhost ~]# nohup ./sleep500.sh &amp;[1] 4701[root@theshuhost ~]# nohup: ignoring input and appending output to ‘nohup.out’[root@theshuhost ~]# exit 如果你再次登陆系统的话，再使用ps查看你的进程，会发现sleep500.sh还在执行中，并不会被中断掉。由于我们的进程最后会输出一个信息，但是nuhup与终端机其实无关了，因此这个信息的输出就会被定向“~/nohup.out”，所以你才会看到上述命令中，当你输入nohup后，会出现那个提示信息。 如果你想要让在后台的工作在你注销后还能够继续执行吗，那么使用nuhup搭配&amp;是不错的运行情境。 3. 进程管理进程管理非常的重要，这是因为： 首先，我们在操作系统中的各项工作其实都是经过某个PID来达成的（包括你的bash环境），因此，能不能进行某项工作就与该进程的权限有关了。 再来，如果你的Linux系统是个很忙碌的系统，那么当整个系统资源快要被使用光时，你是否能够找出最耗系统的那个进程，然后删除该进程，让系统恢复正常呢？ 此外，如果由于某个程序写的不好，导致产生一个有问题的进程在内存当中，你又该如何找出它，然后将它删除？ 如果同时有五六项工作在你的系统当中运行，但其中有一项工作才是最重要的，该如何让那一项重要的工作被最优先执行呢？ 所以说，一个称职的系统管理员，必须要熟悉进程的管理流程才行，否则当系统发生问题时，还真是很难解决问题呢。下面的内容会先介绍如何查看程序与程序的状态，然后再加以过程控制。 3.1. 进程的查看3.1.1. ps 静态查看系统进程作为系统管理员，一定要知道您所管理的系统都有哪些进程在运行，除了上面所介绍的top可以简单查看之外，还有一个专门显示系统进程的命令，就是ps命令。示例如下：12345678910111213141516# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.2 24324 5444 ? Ss 09:02 0:07 /sbin/init splaroot 2 0.0 0.0 0 0 ? S 09:02 0:00 [kthreadd]root 3 0.0 0.0 0 0 ? S 09:02 0:00 [ksoftirqd/0]root 5 0.0 0.0 0 0 ? S&lt; 09:02 0:00 [kworker/0:0H]root 7 0.0 0.0 0 0 ? S 09:02 0:11 [rcu_sched]root 8 0.0 0.0 0 0 ? S 09:02 0:00 [rcu_bh]root 9 0.0 0.0 0 0 ? S 09:02 0:00 [migration/0]root 10 0.0 0.0 0 0 ? S 09:02 0:00 [watchdog/0]root 11 0.0 0.0 0 0 ? S 09:02 0:00 [watchdog/1]root 12 0.0 0.0 0 0 ? S 09:02 0:00 [migration/1]root 13 0.0 0.0 0 0 ? S 09:02 0:00 [ksoftirqd/1]root 15 0.0 0.0 0 0 ? S&lt; 09:02 0:00 [kworker/1:0H]root 16 0.0 0.0 0 0 ? S 09:02 0:00 [kdevtmpfs]root 17 0.0 0.0 0 0 ? S&lt; 09:02 0:00 [netns] ps aux命令内容说明： USER、PID、%CPU、%MEM、VSZ虚拟内存使用大小、RSS内存的使用量、TTY、STAT状态、TIME进程运行时间、COMMAAND命令 USER：该进程属于哪个用户账号 PID：该进程的进程标识符 %CPU：该进程使用掉的CPU资源百分比 %MEM：该进程所占用的物理内存百分比 VSZ：该进程使用掉的虚拟内存两（kb） RSS：该进程占用的固定的内存量（kb） TTY：该进程是在哪个终端机上面运行，若如终端机无关则显示?，另外，tty1~tty6是本机上面的登陆者程序，若为pts/0等的，则表示为由网络连接进主机的进程 STAT：该进程目前的状态，状态显示与ps -l的S标识相同（R/S/T/Z） START：该进程被触发启动的时间 TIME：该进程实际使用CPU运行的时间 COMMAND：该进程的实际命令 关于STAT状态的说明 S：休眠sleep s：父进程（主进程） &lt;：高优先级 N：低优先级 +：前台 R：正在运行的 l（小写的L）：多线程 L：lock锁 X：已经死掉的进程 Z：僵尸进程（即不能杀死的进程，只能通过重启才能去掉） T：被暂停的 D：不能中断的 W：这个好像是说，从内核2.6xx以后，表示为没有足够的内存页分配 另外一个类似与ps aux的使用方式为ps -elf，两者的功能差不多。其选项说明如下: -l：把当前终端下运行的程序列出来 -e：把后台所有的程序都列出来 -f：显示Stime 示例如下：123456789101112131415# ps -elfF S UID PID PPID C PRI NI ADDR SZ WCHAN STIME TTY TIME CMD4 S root 1 0 0 80 0 - 6327 - 09:41 ? 00:00:07 /sbin1 S root 2 0 0 80 0 - 0 - 09:41 ? 00:00:00 [kthr1 S root 3 2 0 80 0 - 0 - 09:41 ? 00:00:00 [ksof1 S root 5 2 0 60 -20 - 0 - 09:41 ? 00:00:00 [kwor1 S root 7 2 0 80 0 - 0 - 09:41 ? 00:00:08 [rcu_1 S root 8 2 0 80 0 - 0 - 09:41 ? 00:00:00 [rcu_1 S root 9 2 0 -40 - - 0 - 09:41 ? 00:00:00 [migr5 S root 10 2 0 -40 - - 0 - 09:41 ? 00:00:00 [watc5 S root 11 2 0 -40 - - 0 - 09:41 ? 00:00:00 [watc1 S root 12 2 0 -40 - - 0 - 09:41 ? 00:00:00 [migr1 S root 13 2 0 80 0 - 0 - 09:41 ? 00:00:00 [ksof1 S root 15 2 0 60 -20 - 0 - 09:41 ? 00:00:00 [kwor....... ps -elf命令内容说明：系统整体的进程运行是非常多的，但如果使用ps -l则仅列出与你的操作环境（bash）有关的进程而已，即最上层的父进程会是你自己的bash而没有扩展到init这个进程去，那么ps -elf显示出的数据都是什么意思？如下： F：代表这个进程标志（process flags），说明这个进程的权限，常见号码有： 若为4表示次进程的权限为root 若为1则表示此子进程仅可进行复制（fork）而无法实际执行（exec） S：代表这个进程的状态（STAT），主要的状态有： R（Running）：该进程正在运行中 S（Sleep）：该进程目前正在睡眠状态（idle），但可以被唤醒（signal） D：不可被唤醒的睡眠状态，通常这个进程可能在等待I/O的情况（ex&gt;打印） T：停止状态（stop），可能是在工作控制（后台暂停）或除错（traced）状态 Z（Zombie）：僵尸状态，进程已经终止但却无法被删除至内存外 UID/PID/PPID：代表此进程被该UID所拥有/进程的PID号码/次进程的父进程PID号码 C：代表CPU的使用率，单位为百分比PRI/NI：Priority/Nice的缩写，代表次进程被CPU所执行的优先级，数值越小代表该进程越快被CPU执行。详细的PRI与NI在下一小节说明 ADDR/SZ/WCHAN：都与内存有关，ADDR是kernel function，指出该进程在内存的哪个部分，如果是个running的进程，一般就会显示“-”。SZ代表此进程用掉多少内存/WCHAN表示目前进程是否运行中，同样，若为“-”表示正在运行中 STIME：运行该进程时系统的时间 TTY：登陆者的终端机位置，若为远程登陆则使用动态终端接口（pts/0） TIME：使用掉的CPU时间，注意，是此进程实际花费CPU运行的时间，而不是系统时间 CMD：就是command的缩写，造成次程序的触发进程的命令是什么 关于ps命令，以上两个用法就足够了。在工作中，经常把ps命令和管道父结合使用，用来查看某个进程或者它的数量，如下所示：1234# ps aux | grep -c mingetty1# ps aux | grep mingettytheshu 4454 0.0 0.0 6864 812 pts/1 S+ 12:16 0:00 grep --color=auto mingetty 3.1.2. pstree 程序树查看程序之间的关系若是没有这个命令，则用这个命令来安装它：yum install -y psmisc pstree的用法如下：pstree [-A|U] [-up] 参数 意义 -A 各进程树之间的连接以 ASCII 字符来连接 -U 各进程树之间的连接以 utf8 码的字符来连接，在某些终端接口下可能会有错误 -p 同时列出每个进程的PID -u 同时列出每个进程的所属账号名称 示例如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364[theshu@theshuhost ~]$ pstreesystemd─┬─AliYunDun───14*[&#123;AliYunDun&#125;] ├─AliYunDunUpdate───3*[&#123;AliYunDunUpdate&#125;] ├─agetty ├─aliyun-service───6*[&#123;aliyun-service&#125;] ├─atd ├─auditd───&#123;auditd&#125; ├─crond ├─dbus-daemon ├─dhclient ├─ntpd ├─polkitd───5*[&#123;polkitd&#125;] ├─rsyslogd───2*[&#123;rsyslogd&#125;] ├─sshd───sshd───sshd───bash───pstree ├─systemd-journal ├─systemd-logind ├─systemd-udevd └─tuned───4*[&#123;tuned&#125;][theshu@theshuhost ~]$ pstree -upsystemd(1)─┬─AliYunDun(1148)─┬─&#123;AliYunDun&#125;(1149) │ ├─&#123;AliYunDun&#125;(1150) │ ├─&#123;AliYunDun&#125;(1396) │ ├─&#123;AliYunDun&#125;(1397) │ ├─&#123;AliYunDun&#125;(1398) │ ├─&#123;AliYunDun&#125;(1399) │ ├─&#123;AliYunDun&#125;(1400) │ ├─&#123;AliYunDun&#125;(1448) │ ├─&#123;AliYunDun&#125;(1464) │ ├─&#123;AliYunDun&#125;(1465) │ ├─&#123;AliYunDun&#125;(1466) │ ├─&#123;AliYunDun&#125;(1467) │ ├─&#123;AliYunDun&#125;(1468) │ └─&#123;AliYunDun&#125;(31019) ├─AliYunDunUpdate(891)─┬─&#123;AliYunDunUpdate&#125;(894) │ ├─&#123;AliYunDunUpdate&#125;(895) │ └─&#123;AliYunDunUpdate&#125;(915) ├─agetty(879) ├─aliyun-service(7725)─┬─&#123;aliyun-service&#125;(7728) │ ├─&#123;aliyun-service&#125;(7729) │ ├─&#123;aliyun-service&#125;(7730) │ ├─&#123;aliyun-service&#125;(7731) │ ├─&#123;aliyun-service&#125;(7732) │ └─&#123;aliyun-service&#125;(7733) ├─atd(484) ├─auditd(440)───&#123;auditd&#125;(441) ├─crond(485) ├─dbus-daemon(467,dbus) ├─dhclient(752) ├─ntpd(833,ntp) ├─polkitd(466,polkitd)─┬─&#123;polkitd&#125;(487) │ ├─&#123;polkitd&#125;(488) │ ├─&#123;polkitd&#125;(496) │ ├─&#123;polkitd&#125;(499) │ └─&#123;polkitd&#125;(501) ├─rsyslogd(477)─┬─&#123;rsyslogd&#125;(494) │ └─&#123;rsyslogd&#125;(497) ├─sshd(1536)───sshd(5322)───sshd(5324,theshu)───bash(5325)───pstree(+ ├─systemd-journal(326) ├─systemd-logind(463) ├─systemd-udevd(344) └─tuned(815)─┬─&#123;tuned&#125;(1450) ├─&#123;tuned&#125;(1451) ├─&#123;tuned&#125;(1452) └─&#123;tuned&#125;(1458) 3.1.3. top 动态查看系统进程top的使用方式：top [-d 数字] 或 top [-bnp] 参数： 参数 意义 -d 后面可以接秒数，就是整个进程界面更新的秒数，默认是3秒 -b 以批次的方式执行top，还有更多的参数可以使用。 通常会搭配数据流重定向来将批处理的结果输出成为文件 -n 与-b搭配，意义是，需要进行几次 top 的输出结果 -p 指定某些个PID来进行查看检测而已 在top执行过程中可以使用的按键命令： 按键 意义 ? 显示在top当中可以输入的按键命令 P 以CPU的使用资源排序显示 M 以内存的使用资源排序显示 N 以PID来排序 T 由该进程使用的CPU时间积累（TIME+）排序 k 给予某个PID一个信号（signal） r 给予某个PID重新制定一个nice值 q 离开top软件的按键 大于 向下翻看 小于 向上翻看 示例如下：123456789101112131415161718192021# toptop - 17:37:05 up 2:25, 1 user, load average: 0.00, 0.01, 0.05Tasks: 91 total, 1 running, 90 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 1008176 total, 507628 free, 135092 used, 365456 buff/cacheKiB Swap: 4194300 total, 4194300 free, 0 used. 684136 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 128164 6848 4076 S 0.0 0.7 0:01.38 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.02 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:02.17 ksoftirqd/0 5 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H 7 root rt 0 0 0 0 S 0.0 0.0 0:00.10 migration/0 8 root 20 0 0 0 0 S 0.0 0.0 0:00.00 rcu_bh 9 root 20 0 0 0 0 S 0.0 0.0 0:01.30 rcu_sched 10 root rt 0 0 0 0 S 0.0 0.0 0:00.15 watchdog/0 11 root rt 0 0 0 0 S 0.0 0.0 0:00.18 watchdog/1 12 root rt 0 0 0 0 S 0.0 0.0 0:00.06 migration/1 13 root 20 0 0 0 0 S 0.0 0.0 0:00.15 ksoftirqd/1 15 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/1:0H 17 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kdevtmpfs top命令用于动态监控进程所占的系统资源，每隔5秒变一次。它的特点是把占用系统资源（CPU、内存、磁盘I/O等）最高的进程放到最前面。 如例所示，top命令打印出很多信息，包括系统负载（load average）、进程数（Tasks）、CPU使用情况、内存使用情况以及交换分区使用情况。这些内容其实可以通过其它命令来查看，用top的重点查看的还是下面的进程使用系统资源的详细状况，其中需要关注的是%CPU、%MEM和COMMAND这几项所代表的意义。RES这一项为进程所占用的内存大小，而%MEM这一项为使用内存的百分比。在top状态下，默认按CPU的使用百分比情况排序，按Shift+M可以按照内存使用大小来排序。按数字1可以列出所有核CPU的使用状态，按q可以推出top。 top的内容说明： 第一行（top，综述）：同w命令的第一行（或uptime命令）所示的一样，只不过是动态的（默认3s刷新一次状态）。这一行显示的信息分别为： 目前的时间，即是 17:37:05 内容 开机到目前位置所经过的时间，即是 up 2:25 内容 已经登陆系统的用户人数，即是1 user内容 系统在1、5、15分钟的平均工作负载，意思是在1、5、15分钟系统平均要负责运行几个进程（工作）的意思。越小代表系统越闲置，若高于1得要注意你的系统压力是否太过繁复了。 第二行（Tasks，进程）：显示的是目前进程的总量与个别进程在什么状态（running，sleeping，stopped，zombie）。比较需要注意的是最后的zombie那个数值，如果不是0，好好看看到底是哪个process变成僵尸了吧。这一行显示的信息分别为： 进程总数 91 total 正在运行进程数 1 running 休眠进程数 90 sleeping 被停止进程数 0 stopped 僵尸进程数 0 zombie 第三行（%Cpus）：显示的是CPU的整体负载，每个选项可使用?查阅。需要特别注意的是%wa，那个选项代表的是I/O wait，通常你的系统变慢都是I/O产生的问题比较大。因此这里得要注意这个选项耗用CPU的资源。另外，如果是多内核的设备，可以按下数字键“1”来切换成不同CPU的负载率。这一行的内容分别为： %us 用户态进程，用户空间占用CPU百分比 %sy 内核态进程，内核空间占用CPU百分比 %ni 用户进程空间内改变过优先级的进程占用CPU百分比 %id 空闲CPU百分比 %wa等待（I/O）等待输入输出的CPU时间百分比 %hi %si %st 第四行（内存）：总大小、已使用的、空闲的、缓冲量大小 第五行（Swap）：总大小、已使用的、空闲的、缓存量大小 要注意的是，swap的使用量要尽量少，如果swap被大量使用，表示系统的物理内存实在不足。 缓冲和缓存的区别： 缓冲（buffer）：是为了提高内存和硬盘（或其他I/O设备）之间的数据交换的速度而设计的（内存–硬盘） 缓存（cache）：是为了提高CPU和内存之间的数据交换速度而设计的（内存–CPU） 第六行：这个是当在top进程当中输入命令时显示状态的地方。这一行的内容为： PID：进程ID，PPID：父进程ID RUSER：Real user name USER：进程使用者的用户名 PR优先级 NI优先值（Nice值，从-20到19,数值越低，优先级越高） VIRT：虚拟内存大小 RES：真正内存使用大小 SHR：共享内存大小 S：表示状态 %CPU：上次更新到现在的CPU时间占用百分比 %MEM：进程使用的物理内存百分比 TIME+：进程使用的CPU时间总计，单位1/100秒 COMMAND：命令 在日常工作中常用到命令 top -bn1，它表示非动态打印系统资源的使用情况，和top命令的唯一区别就是，它一次性输出所有信息而非动态显示。这条命令可以用在shell脚本中。示例如下：1234567891011]# top -bn1 | headtop - 17:42:27 up 2:31, 1 user, load average: 0.00, 0.01, 0.05Tasks: 92 total, 1 running, 91 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 1008176 total, 508100 free, 134564 used, 365512 buff/cacheKiB Swap: 4194300 total, 4194300 free, 0 used. 684652 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 128164 6848 4076 S 0.0 0.7 0:01.38 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.02 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:02.17 ksoftirqd/0 top -c 这个命令是使 COMMAND那一列显示的更全一些。 例子：指定PID查看指定的进程查看。如下：123456789101112我们自己的bash PID可由 $$ 变量取得，请使用 top 持续查看该 PID：[root@theshuhost ~]# echo $$5683[root@theshuhost ~]# top -d 2 -p 5683top - 21:00:06 up 24 days, 23:51, 2 users, load average: 0.00, 0.01, 0.05Tasks: 1 total, 0 running, 1 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.0 us, 0.5 sy, 0.0 ni, 99.5 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 1016164 total, 299240 free, 80928 used, 635996 buff/cacheKiB Swap: 2097148 total, 2097148 free, 0 used. 771796 avail Mem--- PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 5683 root 20 0 115392 1984 1600 S 0.0 0.2 0:00.00 bash 例子：修改NI数值来达到调控进程的目的。如下： 承上题，上面的NI值是0，想要改成10该怎么版呢？在上例的top界面中直接按下r之后，会出现如下的图样：12345678top - 21:03:57 up 24 days, 23:55, 2 users, load average: 0.00, 0.01, 0.05Tasks: 1 total, 0 running, 1 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 1016164 total, 301492 free, 78736 used, 635936 buff/cacheKiB Swap: 2097148 total, 2097148 free, 0 used. 774072 avail MemPID to renice [default pid = 5683] &lt;&lt;==按下r后在这里输入PID号码 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 5683 root 20 0 115392 2028 1636 S 0.0 0.2 0:00.00 bash 完成上面的操作后，在状态栏会出现如下的信息：123Renice PID 5683 to value 10 &lt;&lt;==这是nice值 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 5683 root 20 0 115392 2028 1636 S 0.0 0.2 0:00.00 bash 接下来你就会看到如下的显示界面（注意，NI值已经发生改变）：12345678top - 21:06:56 up 24 days, 23:58, 2 users, load average: 0.00, 0.01, 0.05Tasks: 1 total, 0 running, 1 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 1016164 total, 301364 free, 78864 used, 635936 buff/cacheKiB Swap: 2097148 total, 2097148 free, 0 used. 773944 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 5683 root 30 10 115392 2028 1636 S 0.0 0.2 0:00.00 bash 3.2. 进程的管理3.2.1. 信号进程之间是可以相互控制的。那么程序是如何相互管理的呢？其实是通过给予该进程一个信号（signal）去告知该进程你想要让它做什么。因此这个信号就很重要了。 要给予某个已经存在后台中的工作某些操作时，直接给予一个信号给该工作号码即可。那到底有多少signal呢？可以使用kill -l(小写的L)或man 7 signal都可以查询到。 主要的信号代号与名称对应及内容如下表所示： 代号 名称 内容 1 SIGHUP 启动被终止的进程，可让该PID重新读取自己的配置文件，类似重新启动 2 SIGINT 相当于用键盘输入Ctrl+C来中断一个进程的进行 9 SIGKILL 代表强制中断一个进程的进行，如果该进程进行到一半，那么尚未完成的部分可能会有“半成品”产生，类似vim会有.filename.swp保留下来 15 SIGTERM 以正常的结束来终止该进程。由于是正常的终止，所以后续的操作会将它完成。不过，如果该进程已经发生问题，就是无法使用正常的方法终止时，输入这个signal也是没用的 17 SIGSTOP 相当于用键盘输入Ctrl+Z来暂停一个进程的进行。 上表中的1、9、15一定要记下来。那么我们如何传送一个信号给某个进程呢？就是通过kill和killall来实现。 3.2.2. kill用法：kill -signal PID 说明： kill可以帮我们将这个signal传送给某个工作（%jobnumber）或者是某个PID（直接输入数字）。kill后面接的数字默认会是PID，所以想要管理bash的工作控制，就要加上%数字了。 强调：kill后面直接加数字与加上%number的情况是不同的。这个很重要。一定要记得那个%是专门用在工作控制的。 signal除了以数值来表示之外，也可以使用信号名称。 接下来我们就活用一下kill与刚才上面提到的ps来做个简单的练习吧： 题目：以ps找出syslog这个进程的PID后，再使用kill传递信号，使得syslog可以重新读取配置文件。 由于需要重新读取配置文件，因此signal是1号。至于找出syslog的PID可以这样做：ps aux | grep &#39;syslog&#39; | grep -v &#39;grep&#39; | awk &#39;{print $2}&#39; 接下来则是实际使用kill -1 PID，因此，整串命令会是这样：kill -SIGHUP $(ps aux | grep &#39;syslog&#39; | grep -v &#39;grep&#39; | awk &#39;{print $2}&#39;) 如果要确认有没有重新启动syslog，可以参考日志文件的内容，使用如下命令查阅：tail -5 /var/log/messages。如果有看到类似“www syslogd 1.4.1: restart”之类的字样，就是表示 syslogd已经重启了。 了解了这个用法以后，如果将来你要想将某个莫名其妙的登陆者的连接删除的话，就可以通过使用pstree -p找到相关进程，然后再以kill -9将该进程删除，该连接就会被踢掉了。 3.2.3. killall用法：killall -signal 命令名称 和 killall [-iIe] [command name] 参数 意义 -i interactive的意思，交互式的，若需要删除时，会出现提示符给用户 -e exact的意思，表示后面接的 command name 要一致，但整个完整的命令不能超过15个字符 -I 命令名称（可能含参数）忽略大小写 说明： 由于kill命令后面必须要加上PID（或者是job number），所以，通常kill都会配合ps,pstree等命令，因为我们必须要找到对应的那个进程的ID。 而killall命令可以利用“执行命令的名称”来给予信号。所以很方便。 示例如下：123456示例一：给予syslogd这个命令启动的PID一个 SIGHUP 的信号# killall -1 syslogd示例二：强制终止所有以 httpd 启动的进程# killall -9 httpd示例三：依次询问每个bash进程是否需要被终止运行# killall -i -9 bash 3.2.4. 进程管理的总结 要删除某个进程，我们可以使用PID或者是启动该进程的命令名称。 如果要删除某个服务，最简单的方法就是利用killall，因为它可以将系统当中所有以命令名称启动的进程全部删除。 3.3. 关于进程的执行顺序Linux是多用户、多任务的系统，由top命令的输出结果我们也发现，系统同时间有非常多的进程在运行中，只是绝大部分的进程都在休眠（sleeping）状态而已。试想一下，如果所有的进程同时被唤醒，那么CPU应该要先处理哪个进程呢？也就是说，哪个进程被执行的优选序比较高？这就得考虑到程序的优先执行序（Priority）与CPU调度。 CPU调度与例行性工作调度（也就是计划任务）不一样，CPU调度指的是每个程序被CPU运行的演算规则，而例行性工作调度则是将某个程序安排在某个时间再交由系统执行。CPU调度与操作系统较具有相关性。 3.3.1. Priority 与 Nice值有时Linux系统下的任务需要分清楚什么进程任务比较重要，什么可以暂缓执行，优先执行什么。为了达到这个目的，Linux给予进程一个所谓的优先执行序（Priority，PRI），这个PRI值越低代表越优先的意思。不过这个PRI值是由内核动态调整的，用户是无法直接调整PRI值的。可以用ps等命令来查看到PRI值。（ps -l） 因为PRI值我们无法直接调整，那么我们想要调整进程的优先序时，就得要通过Nice值了。Nice值一般都在PRI值的旁边，ps等命令的界面中的NI值。 一般来说，PRI与NI的相关性如下：PRI (new) = PRI(old) + NICE 说明： 注意，如果原本的PRI是50，并不是我们给予一个Nice=5，就会让PRI变成55。因为PRI是系统“动态”决定的，所以，虽然Nice值可以影响PRI，不过最终的PRI仍然要经过系统分析后才会决定的。另外，Nice值是有正负的，而既然PRI越小越早被执行，所以，当Nice值为负时，那么该进程就会降低PRI值，即会变得较优先被处理。 Nice值可以调整的范围是 -20——19 root可随意调整自己或他人进程的Nice值，且范围是 -20——19 一般用户仅可调整自己进程的Nice值，且范围仅为 0——19（避免一般用户抢占系统资源） 一般用户仅可将Nice值越调越高，例如本来Nice为5，则将来仅能调整到大于5 综上所述，要调整某个进程的优先执行序，就是调整该进程的Nice值。那么如何给予某个进程Nice值呢？有以下两种方式： 一开始执行程序就立即给予一个特定的Nice值：用nice命令实现。 调整某个已经存在的PID的Nice值：用renice命令实现。 3.3.2. nice 新执行的命令即给予新的nice值使用方法：nice [-n 数字] command 参数： -n：后面接一个数值，数值的范围是-20到19 例子：用root给一个Nice值为-5，用于执行vi，并查看该进程，最后退出它：12345678910111213[root@theshuhost ~]# nice -n -5 vi &amp;[1] 7142[root@theshuhost ~]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD4 S 0 7123 7102 0 80 0 - 49420 poll_s pts/0 00:00:00 sudo4 S 0 7124 7123 0 80 0 - 47402 do_wai pts/0 00:00:00 su4 S 0 7125 7124 0 80 0 - 28848 do_wai pts/0 00:00:00 bash4 T 0 7142 7125 0 75 -5 - 31002 do_sig pts/0 00:00:00 vi0 R 0 7143 7125 0 80 0 - 37235 - pts/0 00:00:00 ps# 原本的bash PRI为80，所以vi默认应为80，不过由于给予Nice值为-5，# 因此vi的PRI降低了。但有时候做这个实验你会看，并非会降低到75，因为内核还会动态调整。[root@theshuhost ~]# kill -9 %1 &lt;==测试完毕将vi关闭[1]+ Stopped nice -n -5 vi 通常什么时候需要将Nice值调大呢？举例来说，系统的后台工作中，某些比较不重要的进程在运行，例如备份工作，由于备份工作相当消耗系统资源，这个时候就可以将备份的命令的Nice值调大一些，可以使系统的资源分配得更为公平。 3.3.3. renice 已存在进程的nice重新调整使用方法：renice [number] PID 例子：找出自己的bash的PID，并将该PID的Nice调整到101234567891011121314[root@theshuhost ~]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD4 S 0 7123 7102 0 80 0 - 49420 poll_s pts/0 00:00:00 sudo4 S 0 7124 7123 0 80 0 - 47402 do_wai pts/0 00:00:00 su4 S 0 7125 7124 0 80 0 - 28848 do_wai pts/0 00:00:00 bash0 R 0 7154 7125 0 80 0 - 37235 - pts/0 00:00:00 ps[root@theshuhost ~]# renice 10 71257125 (process ID) old priority 0, new priority 10[root@theshuhost ~]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD4 S 0 7123 7102 0 80 0 - 49420 poll_s pts/0 00:00:00 sudo4 S 0 7124 7123 0 80 0 - 47402 do_wai pts/0 00:00:00 su4 S 0 7125 7124 0 90 10 - 28848 do_wai pts/0 00:00:00 bash0 R 0 7156 7125 0 90 10 - 37235 - pts/0 00:00:00 ps 说明： 如果要调整的是已经存在的某个进程的话，那么就得要使用renice这个命令了。使用的方法很简单。renice后面接上数值和PID即可。因为后面接的是PID，所以要使用ps等命令来找出这个进程的PID才行。 由上面的例子我们也可以看得出来，虽然修改的是bash这个进程，但是该进程所触发的ps命令当中的Nice也会继承而为10。整个Nice值是可以在父进程->子进程之间传递呢。 另外，除了renice之外，其实哪个top也同样可以调整Nice值的。 3.4. 系统资源的查看除了系统的进程之外，我们还必须就系统的一些资源进行检查。如以下的这些命令。 3.4.1. free 查看内存使用情况示例如下：1234# free total used free shared buff/cache availableMem: 2052900 366112 605324 209940 1081464 1245724Swap: 2085884 0 2085884 只需要敲一个free然后回车就可以知道当前系统的总内存大小以及使用内存的情况。另外我们还可以加-m或者-g选项分别以M或G为单位打印内存使用状况（默认单位是kb）。如下所示：12345678# free -m total used free shared buff/cache availableMem: 2004 351 596 205 1057 1222Swap: 2036 0 2036# free -g total used free shared buff/cache availableMem: 1 0 0 0 0 0Swap: 1 0 1 3.4.2. uname 查看系统与内核相关信息uname命令可以列出当前系统的内核版本、主要硬件平台以及CPU类型等信息。 使用方法：uname [-asrmpi] 参数 意义 -a 所有系统相关的信息，包括下面的数据都会被列出来 -s 系统内核名称 -r 内核的版本 -m 本系统的硬件名称，例如i686或x86_64等 -p CPU的类型，与-m类似，只是显示的是CPU的类型 -i 硬件的平台（ix86） 例子：输出系统的基本信息12[theshu@theshuhost ~]$ uname -aLinux theshuhost 3.10.0-693.11.1.el7.x86_64 #1 SMP Mon Dec 4 23:52:40 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux 另外还有两个查看系统的发行版本的命令： cat /etc/issur cat /etc/redhat-release 3.4.3. w 查看系统负载Linux系统管理员最常用的命令就是这个w了。用来查看系统整体上的负载，通过查看这些信息就可以知道当前系统有没有压力。其具体用法如下：1234# w 15:40:14 up 28 min, 1 user, load average: 0.00, 0.01, 0.05USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 192.168.1.105 15:25 6.00s 0.06s 0.01s w 关于w命令的说明： 第一行从左到右一次显示的信息是：时间-系统运行时间-登陆用户数-平均负载 从第二行开始的所有行则是：当前登陆的用户名，其登陆终端（tty表示本地终端，pts\0表示远程终端），IP地址、登陆时间、WHAT所使用的命令。 在这些信息中，最应该关注的就是第一行中的load average：后面的三个数值了 关于load average的说明： 第一个数值表示一分钟内系统的平均负载值，第二个数值表示五分钟内系统的平均负载值，第三个数值表示十五分钟内系统的平均负载值。 我们着重看第一个值，它表示单位时间内使用CPU的活动进程数（在这里其实就是指一分钟内），该值越大说明服务器压力越大。一般情况下，这个值只要不超过服务器的CPU数量就没有关系。（如果服务器的CPU数量为8，那么值小于8就说明当前服务器没有压力，否则就需要关注一下了） 查看服务器有几个CPU的方法如下： cat /proc/cpuinfo 查看/proc/cpuinfo这个文件的内容，该文件记录了CPU的详细信息。 目前市面上的服务器有很多是2颗多核CPU，在Linux看来，它就是2*n个CPU（这里的n为单颗物理CPU上有几核）。 假如n是4，则查看这个文件时会显示8段类似的信息，而最后一段信息的processor：后面会显示7。 所以查看当前系统有几个CPU，可以用这个命令：grep -c &#39;processor&#39; /proc/cpuinfo。 然而查看有几颗物理CPU时，则需要查看关键字”physical id”：grep -c &#39;physical&#39; /proc/cpuinfo。 补充内容： ab -n 10000 -c 100 网址 用来对网站进行压力测试：访问10000次，并发量100.。 uptime 显示w命令的第一行内容 3.4.4. uptime 查看系统启动时间与工作负载示例如下：12[root@theshuhost ~]# uptime 19:40:20 up 24 days, 22:31, 1 user, load average: 0.00, 0.01, 0.05 上例所示，uptime命令所展示的内容可简单地查看到系统负载。 3.4.5. netstat 跟踪网络命令作用：netstat命令的作用是显示IP、TCP、UDP、ICMP等协议相关的统计信息和当前的TCP/IP网络连接状况。这个命令比较常用在网络的监控方面，不过，在进程管理方面也是需要了解的。这个命令的使用方法如下： netstat 参数 参数 意义 -a或–all 将目前系统上所有的连接、监听、Socket数据都列出来 -A [网络类型] 列出该网络类型连线中的相关地址。网络类型可以选择inet、unix、ipx、ax25、netrom和ddp –网络类型 同上 -e 或 –extend 显示网络其他相关信息 -g 或 –groups 显示多重广播功能群组组员名单 -h 或 –help 在线帮助 -i 或 –interfaces 显示指定网络接口的所有信息 -l 或 –listening 显示监控中的服务器的Socket -n 或 –numeric 不列出进程的服务名称，以端口号（port number）来显示 -o 或 –timers 显示计时器 -r 或 –route 显示内核路由表信息 -s 或 –statistice 显示个网络协议的统计信息 -t 或 –tcp 列出 tcp 网络数据包的数据 -u 或 –udp 列出 udp 网络数据包的数据 -v 或 –verbose 显示命令执行过程 -V 或 –version 显示版本信息 -p 列出该网络服务的进程PID 命令示例如下： 查看本机的网络连接状况以及各协议的相关统计信息：netstat 查看本机内核路由表信息：netstat -nr 查看本机网络接口的当前配置信息：netstat -i 查看本机TCP传输协议的连接状况：netstat -ta 每隔10秒显示一次活动的TCP连接的连线状况：netstat -o 10 -t 显示以太网网络接口的统计信息和所有协议的统计信息：netstat -es 查看监听中的服务器套接字：netstat -l 查看多播组成员信息：netstat -g 示例如下：列出目前系统已经新建的网络连接与 unix socket状态12345678910111213[root@theshuhost ~]# netstatActive Internet connections (w/o servers) 《==与网络相关的部分Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 64 theshuhost:ssh 1.31.240.177:6150 ESTABLISHEDtcp 0 0 theshuhost:49254 106.11.68.13:http ESTABLISHEDActive UNIX domain sockets (w/o servers) 《==与本机的进程自己的相关性（非网络）Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 9655 /run/systemd/shutdowndunix 2 [ ] DGRAM 6864 /run/systemd/notifyunix 2 [ ] DGRAM 6866 /run/systemd/cgroups-agentunix 5 [ ] DGRAM 6877 /run/systemd/journal/socketunix 10 [ ] DGRAM 6879 /dev/log……（中间省略）…… 如上，netstat的输出分为两大部分，分别是网络与系统自己的进程相关性部分： 与网络相关的部分： Proto：网络的数据包协议，主要分为TCP与UDP数据包 Recv-Q：非由用户进程连接到此socket的复制的总字节数 Send-Q：非由远程主机传送过来的acknowledge总字节数 Local Address：本地的IP端口情况 Foreign Adress：远程主机的IP端口情况 State：连接状态，主要有建立（ESTABLISED）及监听（LISTEN） 除了网络上的连接之外，其实Linux系统上面的进程可以接收不通进程所发送来的信息，那就是Linux上面的socket file。socket file 可以沟通两个进程之间的信息，因此进程可以取得对方传送过来的数据。上面的socket file的输出字段有： Proto：一般就是unix RefCnt：；连接到此 socket 的进程数量 Flags：连接的标识 Type：socket访问的类型。主要有确认连接的STREAM与不需确认的DGRAM两种 State：若为CONNECTED表示多个进程之间已经建立连接 Path：连接到此socket的相关程序的路径，或者是相关数据输出的路径 netstat命令用来打印网络连接状况、系统所开放的端口、路由表等信息。关于这个命令最常用的两种方式就是netstat -lnp（打印当前系统启动哪些端口）和netstat -an（打印网络连接状况），请一定要记住。示例如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# netstat -lnp（并非所有进程都能被检测到，所有非本用户的进程信息将不会显示，如果想看到所有信息，则必须切换到 root 用户）激活Internet连接 (仅服务器) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:3689 0.0.0.0:* LISTEN 4186/rhythmbox tcp 0 0 127.0.1.1:53 0.0.0.0:* LISTEN - tcp6 0 0 :::3689 :::* LISTEN 4186/rhythmbox udp 0 0 127.0.1.1:53 0.0.0.0:* - udp 0 0 0.0.0.0:68 0.0.0.0:* - udp 0 0 0.0.0.0:37475 0.0.0.0:* - udp 0 0 0.0.0.0:631 0.0.0.0:* - udp 0 0 192.168.43.247:123 0.0.0.0:* - udp 0 0 127.0.0.1:123 0.0.0.0:* - udp 0 0 0.0.0.0:123 0.0.0.0:* - udp 0 0 0.0.0.0:5353 0.0.0.0:* - udp6 0 0 :::50784 :::* - udp6 0 0 fe80::3e92:1783:1f3:123 :::* - udp6 0 0 ::1:123 :::* - udp6 0 0 :::123 :::* - udp6 0 0 :::5353 :::* - raw6 0 0 :::58 :::* 7 - 活跃的UNIX域套接字 (仅服务器) Proto RefCnt Flags Type State I-Node PID/Program name 路径 unix 2 [ ACC ] 流 LISTENING 23756 1632/systemd /run/user/1000/systemd/private unix 2 [ ACC ] SEQPACKET LISTENING 1896 - /run/udev/control unix 2 [ ACC ] 流 LISTENING 22839 - /run/user/1000/keyring/control.......# netstat -an激活Internet连接 (服务器和已建立连接的) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:3689 0.0.0.0:* LISTEN tcp 0 0 127.0.1.1:53 0.0.0.0:* LISTEN tcp 0 0 192.168.43.247:46792 123.58.182.252:80 ESTABLISHED tcp6 0 0 :::3689 :::* LISTEN udp 0 0 127.0.1.1:53 0.0.0.0:* udp 0 0 0.0.0.0:68 0.0.0.0:* udp 0 0 0.0.0.0:37475 0.0.0.0:* udp 0 0 0.0.0.0:631 0.0.0.0:* udp 0 0 192.168.43.247:123 0.0.0.0:* udp 0 0 127.0.0.1:123 0.0.0.0:* udp 0 0 0.0.0.0:123 0.0.0.0:* udp 0 0 0.0.0.0:5353 0.0.0.0:* udp6 0 0 :::50784 :::* udp6 0 0 fe80::3e92:1783:1f3:123 :::* udp6 0 0 ::1:123 :::* udp6 0 0 :::123 :::* udp6 0 0 :::5353 :::* raw6 0 0 :::58 :::* 7 活跃的UNIX域套接字 (服务器和已建立连接的) Proto RefCnt Flags Type State I-Node 路径 unix 2 [ ] 数据报 23755 /run/user/1000/systemd/notify unix 2 [ ACC ] 流 LISTENING 23756 /run/user/1000/systemd/private unix 2 [ ACC ] SEQPACKET LISTENING 1896 /run/udev/control unix 2 [ ACC ] 流 LISTENING 22839 /run/user/1000/keyring/control unix 2 [ ACC ] 流 LISTENING 24162 /run/user/1000/keyring/ssh ...... 关于netstat -an命令内容中连接状态的说明： TIME_WAIT 等待 ESTALISHED 已连接 LISHEN 监听 netstat -an | wc -l 可简单查看一下机器的并发量 如果你所管理的服务器是一台提供Web服务（80端口）的服务器，那么就可以使用netstat -an | grep 80来查看当前连接Web服务的有哪些IP了 3.4.6. dmesg 分析内核产生的信息系统在开机的时候，内核会去检测系统的硬件，你的某些硬件到底有没有被识别出来，那就与这个时候的检测有关。但是这些检测的过程要不是没有显示在屏幕上，就是很飞快地在屏幕上一闪而过。能不能把内核检测的信息找出来看看？当然是可以的，就是用dmesg这个命令。 所有内核检测的信息，不管是开机时候还是系统运行过程中，反正只要是内核产生的信息都会被记录到内存中的某个保护区段。dmesg这个命令就能够将该区段的信息读出来。因为信息实在太多了，所以执行时可以加入管道命令| more或| less来方便阅读。 示例如下：12345678910例一：输出所有的内核开机时的信息[root@theshuhost ~]# dmesg | less---例二：查找开机的时候硬盘的相关信息[root@theshuhost ~]# dmesg | grep -i vd[ 1.088226] ata2.00: ATAPI: QEMU DVD-ROM, 2.1.2, max UDMA/100[ 1.088921] scsi 1:0:0:0: CD-ROM QEMU QEMU DVD-ROM 2.1. PQ: 0 ANSI: 5[ 1.185527] vda: vda1[ 1.286350] EXT4-fs (vda1): mounted filesystem with ordered data mode. Opts: (null)[ 2.591818] EXT4-fs (vda1): re-mounted. Opts: (null) 由例二就可以得知该Linux主机的硬盘的格式是什么了。如果是查找网卡的信息，可以试一试：dmesg | grep -i eth 3.4.7. vmstat 检测系统资源变化命令w查看的是系统整体上的负载，通过查看那个数值就可以知道当前系统有没有压力，但它无法判断究竟具体是哪里（CPU、内存、磁盘等）有压力。所以这就用到了vmstat这个命令。 使用方式： vmstat [-a] [延迟 【总计检测次数] CPU/内存等信息 vmstat [-fs] 内存相关 vmstat [-S 单位] 设置显示数据的单位 vmstat [-d] 与磁盘有关 vmstat [-p 分区] 与磁盘有关 参数 意义 -a 使用 inactive/active（活跃与否）代替 buffer/cache 的内存输出信息 -f 开机到目前为止系统复制（fork）的进程数 -s 将一些事件（开机至目前为止）导致的内存变化情况列表说明 -S 后面可以接单位，让显示的数据有单位，例如：K/M 取代bytes -d 列出磁盘的读写总量统计表 -p 后列接分区名，可显示该分区的读写总量统计表 其常用的用法如下：1234# vmstatprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 522200 2076 349976 0 0 30 34 51 47 0 0 99 0 0 vmstat命令打印的结果共分为6个部分：procs、memory、swap、io、system、cpu。请重点关注一下r、b、si、so、bi、bo这几列信息。 说明： procs显示进程的相关信息 r（run）：表示运行或等待CPU时间片的进程数。不要误认为等待CPU时间片意味着这个进程没有运行，实际上某一时刻1个CPU只能有一个进程占用，其他进程只能排着队等着，此时这些排队等待CPU资源的进程依然是运行状态。该数值如果长期大于服务器CPU的个数，则说明CPU的资源不够用了。 b（block）：表示等待资源的进程数，这个资源指的是I/O、内存等。举个例子，当磁盘读写非常频繁时，写数据就会非常慢，此时CPU运算很快就结束了，但进程需要把计算的结果写入磁盘，这样进程的任务才算完成，那此时这个进程只能慢慢地等待磁盘了，这样这个进程就是这个状态。该数值如果长时间大于1，则需要关注一下了。 memory显示内存的相关信息 swap：表示切换到交换分区中的内存数量，单位kb。 free：表示当前空闲的内存数量，单位kb。 buff：表示（即将写入磁盘的）缓冲大小，单位kb。 cache：表示（从磁盘中读取的）缓存大小，单位kb。 swap显示内存的交换情况 si：表示由交换区写入内存的数据量，单位kb。 so：表示由内存写入交换区的数据量，单位kb。 io显示磁盘的使用情况 bi：表示从块设备读取数据的量（读磁盘），单位kb。 bo：表示从块设备写入数据的量（写磁盘），单位kb。 system显示采集间隔内发生的中断次数 in：表示再某一段时间间隔内观测到的每秒设备的中断次数。 cs：表示每秒产生的上下文切换次数。 cpu显示CPU的使用状态 us：显示用户下所花费CPU的时间百分比。 sy：显示系统花费CPU的时间百分比。 id：表示CPU处于空闲状态的时间百分比。 wa：表示I/O等待所占用CPU的时间百分比。 st：表示被偷走的CPU所占百分比（一般都为0，不用关注） 以上所介绍的各个参数中，再运维工作中经常会关注r、b、wa这三列。io部分的bi和bo也是要经常参考的对象，如果磁盘io压力大，这两列的数值就会比较高。另外，当si和so两列的数值比较高并且不断变化时，说明内存不够了，内存中的数据会频繁交换到交换分区中，这往往对系统性能影响极大。 我们使用vmstat查看系统状态时，通常都是使用如下形式： vmstat 1 5 表示每隔1秒输出一次状态，共输出5次。 cmstat 1 表示每隔1秒输出一次状态且一直输出，知道按下Ctrl+C结束。 4. 几个其它的运维工具在这一节包含了除了上一节所介绍的工具之外的其它几个常用的工具。它们都是在运维工作中经常使用到的，所以要必须掌握。 4.1. 监控系统状态4.1.1. sar 监控系统状态sar命令很强大，它可以监控系统几乎所有资源的状态，比如平均负载、网卡流量、磁盘状态、内存使用等。与其它系统状态监控工具不同，它可以打印历史信息，可以显示当天从零点开始到当前时刻的系统状态信息。如果你的系统没有安装这个命令，请使用yum install -y sysstat安装。 初次使用sar命令会报错，这是因为sar工具还没有生成相应的数据库文件（无需实时监控，因为不用去查询那个库文件）。它的数据库文件再/var/log/sa/目录下。因为这个命令太复杂，下面仅仅介绍最常用的两个方面的用法。 用法1. 查看网卡流量 sar -n DEV具体用法如下：12345678910# sar -n DEVLinux 2.6.32-358.el6.i686 (localhost.localdomain) 2013年05月25日 _i686_ (1 CPU)00时00分01秒 IFACE rxpck/s txpck/s rxKB/s txKB/s rxcmp/s txcmp/s rxmcst/s00时10分01秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.0000时10分01秒 eth0 31.94 0.09 3.89 0.02 0.00 0.00 0.00 00时20分01秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.0000时20分01秒 eth0 32.40 0.04 3.96 0.01 0.00 0.00 0.0000时30分01秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.0000时30分01秒 eth0 31.18 0.09 3.76 0.02 0.00 0.00 0.00 说明： 在上面所示的例子里并没有把全部信息贴出来，因为太多了。 IFACE这列表示设备名称。 rxpck/s表示每秒进入收取的包的数量（单位Byte）。 txbyt/s表示每秒发送的数据量。 后面几列不需要关注。 如果有一天您所管理的服务器丢包非常严重,那么您就应该看一看这个网卡流量是否异常了,如果rxpck/s 那一列的数值大于4000,或者rxbyt/s那列大于5,000,000，则很有可能是被攻击了,正常的服务器网卡流量不会高于这么多,除非是您自己在拷贝数据。 上面的命令是查看网卡流量历史的，如何实时查看网卡流量呢？用下面的命令：1234567891011121314151617181920212223242526272829303132$ sar -n DEV 1 5Linux 4.4.0-53-generic (theshu-Latitude-D530) 2017年10月06日 _i686_ (2 CPU)11时33分05秒 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil11时33分06秒 wlp12s0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分06秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分06秒 enp9s0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分06秒 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil11时33分07秒 wlp12s0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分07秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分07秒 enp9s0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分07秒 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil11时33分08秒 wlp12s0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分08秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分08秒 enp9s0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00c11时33分08秒 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil11时33分09秒 wlp12s0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分09秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分09秒 enp9s0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分09秒 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil11时33分10秒 wlp12s0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分10秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时33分10秒 enp9s0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil平均时间: wlp12s0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: enp9s0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 上面的命令是很常用的，用来查看网卡流量，一秒钟显示1次，共显示5次。着重查看rxpck/s（数据包量）和rxbyt/s（数据量） 另外也可以查看某一天的网卡流量历史，使用-f选项，后面跟文件名，如果你的系统为CentOS或者是RedHat，那么sar的库文件一定是在/var/log/sa/目录下的：123456789101112# sar -n DEV -f /var/log/sa/sa24Linux 2.6.32-358.el6.i686 (localhost.localdomain) 2013年05月25日 _i686_ (1 CPU)10时49分36秒 LINUX RESTART11时00分01秒 IFACE rxpck/s txpck/s rxKB/s txKB/s rxcmp/s txcmp/s rxmcst/s11时10分01秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时20分01秒 eth0 31.94 0.09 3.89 0.02 0.00 0.00 0.0011时30分01秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时40分01秒 eth0 32.40 0.04 3.96 0.01 0.00 0.00 0.0011时50分01秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.0011时60分01秒 eth0 31.18 0.09 3.76 0.02 0.00 0.00 0.00 ls /var/log/sa/ 你会看到两种不同的文件，一个是以sa开头加日期，一个是sar开头加日期，其中sa加日期的文件是不能直接用cat查看的，只能使用sar -f来查看，另外一种sar加日期的文件是可以直接用cat等工具查看的。他们都是记录系统状态历史信息。 用法2. 查看历史负载示例如下：1234567891011# sar -qLinux 2.6.32-358.el6.i686(localhost.localdomain) 2013年05月25日 _i686_(1 CPU)00时00分01秒 runq-sz plist-sz ldavg-1 ldavg-5 ldavg-1500时10分01秒 0 142 0.00 0.00 0.0000时20分01秒 0 143 0.00 0.00 0.0000时30分01秒 0 143 0.00 0.01 0.0000时40分01秒 0 143 0.05 0.01 0.0000时50分01秒 0 143 0.00 0.00 0.0001时00分01秒 0 143 0.00 0.00 0.0001时10分01秒 0 143 0.08 0.03 0.00 说明： 要使用这个命令，前提是要开启服务/etc/init.d/sysstat服务。 可以指定历史文件：sar -q -f /var/log/sa/sa10 这个命令有助于我们查看服务器在过去的某个时间的负载状况。 补充一个sar的用法：sar -b 用来查看磁盘的读写。 关于sar初学着掌握以上这两个用法即可。如果以后工作中用到，就man一下吧。 4.1.2. nload 查看网卡流量sar命令虽然可以查看网卡流量，但是不够直观，还有一个更好的工具，那就是nload。 使用方法：直接运行nload命令。然后会出现如下的动态界面。1234567891011121314Device eth0 [172.17.97.250] (1/2):================================================================================Incoming: Curr: 856.00 Bit/s Avg: 1.05 kBit/s Min: 856.00 Bit/s Max: 2.52 kBit/s Ttl: 83.53 MByteOutgoing: Curr: 8.08 kBit/s Avg: 8.02 kBit/s Min: 6.02 kBit/s Max: 9.03 kBit/s Ttl: 46.12 MByte 最上面一行为网卡名字以及IP地址，按向右箭头可以查看其它网卡的网络流量。输出结果分为两个部分，Incoming为进入网卡的流量，Outgoing为网卡出去的流量，我们关注的当然是Curr那行的数据，其单位也是可以动态调整的，非常人性化。按q退出该界面。 4.2. 抓包工具接下来介绍的两个抓包工具tcpdump和tshark，都需要用root权限去执行。而且，作为运维人员，我们抓包主要是看数据的流向。 4.2.1. tcpdump工具如果没有这个命令，需要用yum install -y tcpdump命令去安装一下。下面是关于这个命令的两个常用的方式： tcpdump -nn -i eth0 -i选项后面跟设备名称，如果想抓eth1网卡的包，后面则要跟eth1。至于-nn选项的作用则是让第三列和第四列显示成”IP+端口号”的形式，如果不加-nn则显示的是”主机名+服务名称”。 这里需要关注的只是第三列和第四列，显示的信息为哪一个IP+Port在连接哪一个IP+Port。 tcpdump -nn -i eth0 host 192.168;.1.100 and port 80 -c 100 -w 1.cap 可以用host指定ip，用port指定端口，-c指定包数量，-w写入指定文件里。这样1.cap文件里面是包的内容，而如果不加-w则直接在屏幕上显示的不是数据包，而是数据流向。这个1.cap可以下载到Windows系统上，然后使用wireshark查看。 -s0选项是抓取全部包 如果在网卡名后面加上tcp，则只会抓取tcp的包 and表示并且，not表示取反 strings 可简单查看二进制的包 4.2.2. wireshark工具默认CentOS是没有这个命令的，请使用这个命令来安装它yum install -y wireshark。关于这个工具只需要掌握一个用法即可，如下所示： tshark -n -t a -R http.request -T fields -e &quot;frame.time&quot; -e &quot;ip.src&quot; -e &quot;http.host&quot; -e &quot;http.request.uri&quot; 说明： 这条命令用于Web服务器，可以显示诸如下面的信息： Mar 21,2014 15:37:08.857507000 199.30.20.38 k168.123.com GET /thread-4861-1-1.html 。 这类似于Web访问日志，有时候若是服务器没有配置访问日志，可以临时使用该命令查看一下当前服务器上的web请求。通俗的说，也就是显示访问http请求的域名以及url。 这个命令，知道你Ctrl+C才会显示出结果 其它的用法： 抓取MySQL的查询： tshark -n -i eth0 -R &#39;mysql.query&#39; -T fileds -e &quot;ip.src&quot; -e &quot;mysql.query&quot; tshark -i eth0 port 3307 -d tcp.port==3307,mysql -z &quot;proto,colinfo,mysql.query,mysql.query&quot; 抓取指定类型的MySQL查询：tshark -n -i eth0 -R &#39;mysql matches &quot;SELECT|INSERT|DELETE|UPDATE&quot;&#39; -T fields -e &quot;ip.src&quot; -e &quot;mysql.query&quot; 统计HTTP的状态：tshark -n -q -z http,stat, -z http,tree这个命令，知道你Ctrl+C之后才会显示结果 5. 特殊文件与程序在这一节将介绍 SUID/SGIN/SBIT 这些权限对于程序到底是如何影响的，程序可能会使用到系统资源（举例来说，磁盘就是其中一项资源）。 5.1. 具有SUID/SGID权限的命令执行状态SUID的权限其实与程序的相关性非常大。这是为什么呢？先来看看SUID的程序是如何被一般用户执行，且具有什么特色呢？ SUID权限仅对二进制程序（binary program）有效 执行者对于该程序需要具有x的可执行权限 本权限仅在执行程序的过程中有效（run-time） 执行者将具有该程序所有者（owner）的权限 所以说，整个SUID的权限会生效是由于具有该权限的程序所触发，而我们知道一个程序被触发会变成进程。所以，执行者可以具有程序所有者的权限就是在该程序变成进程的那个时候。比如，passed这个命令，它被触发的时候，就会获取一个新的进程与PID，该PID产生时通过SUID来给予该PID特殊的权限设置。可以通过下面的例子来理解一下：12345678910111213141516171819202122232425[theshu@theshuhost ~]$ passwd更改用户 theshu 的密码 。为 theshu 更改 STRESS 密码。（当前）UNIX 密码： &lt;==在这里按下Ctrl+Z，再按下Enter键[1]+ 已停止 passwd[theshu@theshuhost ~]$ pstree -usystemd─┬─AliYunDun───14*[&#123;AliYunDun&#125;] ├─AliYunDunUpdate───3*[&#123;AliYunDunUpdate&#125;] ├─agetty ├─aliyun-service───6*[&#123;aliyun-service&#125;] ├─atd ├─auditd───&#123;auditd&#125; ├─crond ├─dbus-daemon(dbus) ├─dhclient ├─ntpd(ntp) ├─polkitd(polkitd)───5*[&#123;polkitd&#125;] ├─rsyslogd───2*[&#123;rsyslogd&#125;] ├─sshd───sshd───sshd(theshu)───bash─┬─passwd(root) │ └─pstree ├─systemd-journal ├─systemd-logind ├─systemd-udevd └─tuned───4*[&#123;tuned&#125;] 那么怎样查询整个系统的SUID/SGID的文件呢？使用find命令：find / -perm +6000 5.2. /proc/* 代表的意义其实，我们之前提到的所谓进程都是在内存当中，而内存的当中的数据又是写入到/proc/这个目录下的，所以，我们可以直接查看/proc/这个目录当中的文件。查看如下：123456789101112[root@theshuhost ~]# ll /proc/total 0dr-xr-xr-x 9 root root 0 Dec 28 05:08 1dr-xr-xr-x 9 root root 0 Dec 28 05:08 10dr-xr-xr-x 9 root root 0 Dec 27 21:08 1148dr-xr-xr-x 9 root root 0 Dec 28 05:08 12....（中间省略）.....-r--r--r-- 1 root root 0 Jan 23 22:10 uptime-r--r--r-- 1 root root 0 Jan 23 22:10 version-r-------- 1 root root 0 Jan 23 22:10 vmallocinfo-r--r--r-- 1 root root 0 Jan 23 22:10 vmstat-r--r--r-- 1 root root 0 Jan 23 22:10 zoneinfo 基本上，目前主机上面的各个进程的PID都是以目录的类型存于/proc/目录当中的。举例来说，我们开机所执行的第一个进程systemd(低版本为init)的PID是1，这个PID的所有相关信息都写入在/proc/1/目录下面。我们来直接查看PID为1的数据：123456789101112131415[root@theshuhost ~]# ll /proc/1/total 0dr-xr-xr-x 2 root root 0 Jan 23 22:16 attr-rw-r--r-- 1 root root 0 Jan 23 22:16 autogroup-r-------- 1 root root 0 Jan 23 22:16 auxv-r--r--r-- 1 root root 0 Dec 28 05:08 cgroup--w------- 1 root root 0 Jan 23 22:16 clear_refs-r--r--r-- 1 root root 0 Dec 28 05:08 cmdline &lt;==就是命令串-rw-r--r-- 1 root root 0 Dec 28 05:08 comm-rw-r--r-- 1 root root 0 Jan 23 22:16 coredump_filter-r--r--r-- 1 root root 0 Jan 23 22:16 cpusetlrwxrwxrwx 1 root root 0 Jan 23 22:16 cwd -&gt; /-r-------- 1 root root 0 Dec 28 05:08 environ &lt;==一些环境变量lrwxrwxrwx 1 root root 0 Dec 28 05:08 exe -&gt; /usr/lib/systemd/systemd &lt;==实际执行的命令....（一下省略）.... 里面的数据很多，不过，比较有趣的其实是这两个文件，分别是： cmdline：这个进程被启动的命令串 environ：这个进程的环境变量内容 查阅一下cmdline这个文件，发现它的内容如下：12[root@theshuhost ~]# cat /proc/1/cmdline/usr/lib/systemd/systemd--switched-root--system--deserialize21 就是这个命令、参数启动systemd的。这还是跟某个特定的PID有关的内容。如果是针对整个Linux系统相关的参数呢？那就是在/proc/目录下面的文件。相关文件与对应的内容如下表： 文件名 文件内容 /proc/cmdline 加载kernel时所执行的相关参数。查阅此文件，可了解系统是如何启动的 /proc/cpuinfo 本机的CPU的相关信息，包含频率、类型与运算功能等 /proc/devices 这个文件记录了系统各个主要设备的主要设备代号，与mknod有关 /proc/filesystems 目前系统已经加载的文件系统 /proc/interrupts 目前系统上面的IRQ分配状态 /proc/ioports 目前系统上面各个设备所配置的I/O地址 /proc/kcore 这个就是内存的大小。好大对吧？但是不要读它啦 /proc/loadavg top和uptime命令的上头的三个平均负载值就是记录在这里的 /proc/meminfo 使用free列出的内存信息，在这里也能够查阅到 /proc/modules 目前我们的Linux已经加载的模块列表，也可以想成是驱动程序 /proc/mounts 系统已经挂载的数据，就是用mount这个民工调出来的数据 /proc/swaps 到底系统加载的内存在哪里？使用的分区记录在此 /proc/partitions 使用fdisk -l会出现目前所有的分区吧，在这个文件当中也有记录 /proc/pci 在PCI总线上面每个设备的详细情况，可用lspci来查阅 /proc/uptime 就是用uptime的时候会出现的信息 /proc/version 内核的版本，就是用uname -a显示的内容 /proc/bus/* 一些总线的设备，还有USB的设备也记录在此 其实，上面的这些文件都可以使用cat等命令来查阅，不必深入了解。不过，查看文件内容后，毕竟会比较有感觉。如果将来你想要自行编写某些工具软件，那么这个目录下的相关文件可能会对你有点帮助。 5.3. 查询已打开文件或已执行程序打开的文件还有一些与程序相关的命令可以值得参考与应用。如下。 5.3.1. fuser 通过文件（或文件系统）找出正在使用该文件的程序有时候我想要知道我的进程到底在这次启动过程中打开了多少文件，可以利用fuser来查看。举例来说，你如果卸除时发现系统通知“device is busy”，那表示这个文件系统正在忙碌中，表示有某个进程有利用该文件系统。那么你就可以利用fuser来跟踪。fuser语法优点像这样： fuser [-umv] [-k [i] [-signal]] file/dir 参数 意义 -u 除了进程的PID之外，同时列出该进程的所有者 -m 后面接的哪个文件名会主动上提到该文件系统的所顶层，对 umount 不成功很有效 -v 可以列出每个文件与程序还有命令的完整相关性 -k 找出使用该文件或目录的PID，并试图以SIGKILLz这个信号给予该PID -i 必须与-k配合，在删除PID之前先询问用户意愿 -signal 例如 -1 -15 等，若不加的话，默认是 SIGKILL（-9） 范例一：找出目前所在目录的使用 PID/所属账号/权限123[root@theshuhost ~]# fuser -uv . USER PID ACCESS COMMAND/root: root 11086 ..c.. (root)bash 说明： 观察输出结果，它说’.’下面有个PID为11086的程序，该程序属于root并且命令为bash。 比较有趣的是哪个ACCESS的选项，那个选项代表的意义为： c：此进程在当前的目录下（非子目录） e：可被触发为执行状态 f：是一个被打开的文件 r：代表顶层目录（root directory） F：该文件被打开了，不过在等待回应中 m：可能为分享的动态函数库 那如果你想要查看某个文件系统下面有多少进程正在占用该文件系统时，那个-m的参数就很有帮助了。请看下面的例子。 范例二：查看一下/proc/的文件系统有多少进程正在利用它12345678910[root@theshuhost ~]# fuser -uv /proc USER PID ACCESS COMMAND/proc: root kernel mount (root)/proc其实我们需要用到的是/proc下面的文件，所以应该要这样做：[root@theshuhost ~]# fuser -muv /proc USER PID ACCESS COMMAND/proc: root kernel mount (root)/proc root 1 f.... (root)systemd root 326 f.... (root)systemd-journal这样就可以看到有几个进程在进行/proc文件系统的访问。 既然可以针对整个文件系统，那么能不能仅针对单一文件呢？当然可以，请看下面的例子。 范例三：找到 /var/ 下面属于 FIFO 类型的文件，并且找出访问该文件的进程1234567[root@www ~]# find /var -type p/var/gdm/.gdmfifo &lt;==我们针对这个玩意即可！/var/run/autofs.fifo-misc/var/run/autofs.fifo-net[root@www ~]# fuser -uv /var/gdm/.gdmfifo USER PID ACCESS COMMAND/var/gdm/.gdmfifo: root 4892 F.... (root)gdm-binary 范例四：同范例三，但试图删除该PID且“不要”删除123[root@www ~]# fuser -ki /var/gdm/.gdmfifo/var/gdm/.gdmfifo: 4892Kill process 4892 ? (y/N) n 看吧，通过这个fuser我们可以找出使用该文件、目录的程序，以便查看。它的重点与ps，pstree不同。fuser可以让我们了解到某个文件（或文件系统）目前正在被哪些进程所利用。 5.3.2. lsof：列出被进程所打开的文件名相对于fuser是由文件或者设备去找出使用该文件或设备的进程，反过来说，如何查出某个进程打开或者使用的文件与设备呢？那就是使用lsof。 lsof [-aUu] [+d] 参数 意义 -a 多项数据需要“同时成立”才显示出结果 -U 仅列出Unix like 系统的socket文件类型 -u 后面接username，列出该用户相关进程所打开的文件 +d 后面接目录，即找出某个目录下面已经被打开的文件 示例如下： 范例一：列出目前系统上面所有已经被打开的文件与设备123456789[root@theshuhost ~]# lsofCOMMAND PID TID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsystemd 1 root cwd DIR 253,1 4096 2 /systemd 1 root rtd DIR 253,1 4096 2 /systemd 1 root txt REG 253,1 1523624 1053844 /usr/lib/systemd/systemdsystemd 1 root mem REG 253,1 20040 1050451 /usr/lib64/libuuid.so.1.3.0systemd 1 root mem REG 253,1 261336 1051898 /usr/lib64/libblkid.so.1.1.0systemd 1 root mem REG 253,1 90664 1050435 /usr/lib64/libz.so.1.2.7....下面省略.... 说明： 注意，在默认的情况下，lsof会将目前系统上面已经打开的文件全部列出来。所以，界面多得吓人啊！ 你可以注意到，第一个文件systemd执行的地方就在根目录，而根目录所在的inode也有显示出来。 范例二：仅列出关于root的所有进程打开的socket文件1234567891011[root@theshuhost ~]# lsof -u root -a -UCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsystemd 1 root 12u unix 0xffff880036a09800 0t0 9607 /run/systemd/privatesystemd 1 root 14u unix 0xffff88003ca1a000 0t0 389584 socketsystemd 1 root 23u unix 0xffff8800368fa800 0t0 6864 /run/systemd/notifysystemd 1 root 27u unix 0xffff8800368fb000 0t0 6866 /run/systemd/cgroups-agentsystemd 1 root 36u unix 0xffff88003617ac00 0t0 11251 socketsystemd 1 root 37u unix 0xffff88003db9f000 0t0 6874 /run/systemd/journal/stdoutsystemd 1 root 38u unix 0xffff8800369b4000 0t0 6877 /run/systemd/journal/socketsystemd 1 root 39u unix 0xffff8800369b4400 0t0 6879 /dev/log....下面省略.... 说明： 注意到那个-a选项了把，如果你分别输入lsof -u root 及 lsof -U，会有什么信息？ 使用 lsof -u root -U 及 lsof -u root -a -U，呵呵，都不同的。 -a 的用途就是解决同时需要两个选项都成立。 范例三：请列出目前系统上面所有的被启动的周边设备123456789[root@theshuhost ~]# lsof +d /devCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsystemd 1 root 0u CHR 1,3 0t0 4856 /dev/nullsystemd 1 root 1u CHR 1,3 0t0 4856 /dev/nullsystemd 1 root 2u CHR 1,3 0t0 4856 /dev/nullsystemd 1 root 21r CHR 10,235 0t0 6516 /dev/autofssystemd 1 root 39u unix 0xffff8800369b4400 0t0 6879 /dev/logkdevtmpfs 12 root cwd DIR 0,5 3060 3 /dev....下面省略.... 说明： 因为设备都在/dev/里面，所以查找目录即可。 范例四：显示出属于root的bash这个进程所打开的文件123456789101112131415[root@theshuhost ~]# lsof -u root | grep bashbash 11086 root cwd DIR 253,1 4096 131073 /rootbash 11086 root rtd DIR 253,1 4096 2 /bash 11086 root txt REG 253,1 960608 1050319 /usr/bin/bashbash 11086 root mem REG 253,1 106070960 1058409 /usr/lib/locale/locale-archivebash 11086 root mem REG 253,1 62184 1050006 /usr/lib64/libnss_files-2.17.sobash 11086 root mem REG 253,1 2127336 1049988 /usr/lib64/libc-2.17.sobash 11086 root mem REG 253,1 19776 1049994 /usr/lib64/libdl-2.17.sobash 11086 root mem REG 253,1 174576 1050317 /usr/lib64/libtinfo.so.5.9bash 11086 root mem REG 253,1 164112 1049977 /usr/lib64/ld-2.17.sobash 11086 root mem REG 253,1 26254 1050290 /usr/lib64/gconv/gconv-modules.cachebash 11086 root 0u CHR 136,0 0t0 3 /dev/pts/0bash 11086 root 1u CHR 136,0 0t0 3 /dev/pts/0bash 11086 root 2u CHR 136,0 0t0 3 /dev/pts/0bash 11086 root 255u CHR 136,0 0t0 3 /dev/pts/0 这个命令可以找出你想要知道的某个进程是否有打开哪些信息，例如上面的范例四的执行结果。 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式实用技术]]></title>
    <url>%2F2018%2F01%2F19%2FLinux%2F012.%20%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%AE%9E%E7%94%A8%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[GO 1. 正则表达式入门1.1. 定义正则表达式是处理字符串的方法，它是以行为单位来进行字符串的处理行为，通过一些特殊符号的辅助，可以轻易达到查找、删除、替换某特定字符的目的。它是一种规则，只要某工具支持正则表达式，便可以使用这种规则。（支持正则的工具有：vi、grep、awk、sed等） 注意： 使用正则表达式时，需要注意当时环境的语系是什么，否则结果会有所不同。 正则表达式的特殊字符与一般在命令行输入命令的通配符并不相同。 1.2. 特殊符号 特殊符号 代表意义 [:alnum:] 英文大小写字符及数字，即0-9，A-Z，a-z [:alpha:] 英文大小写字符，即A-Z，a-z [:lower:] 小写字母，即a-z [:upper:] 大写字母，即A-Z [:digit:] 数字，即0-9 [:blank:] 空格键与[Tab]按键 [:cntrl:] 键盘上面的控制按键，即包括CR，LF，Tab，Del等 [:graph:] 除了空格符（空格键与[Tab]按键）外的其它所有按键 [:print:] 任何可以被打印出来的字符 [:punct:] 标点符号（punctuation symbol），即” ‘ ? ! ; : # $ [:space:] 任何会产生空白的字符，包括空格键[Tab]CR等 [:xdigit:] 十六进制的数字类型，包括0-9，A-F，a-f的数字与字符 上表最常用的是前五个，要熟记！ 1.3. 基础正则表达式 RE字符 意义 ^word 待查找的字符串（word）在行首 word$ 待查找的字符串（word）在行尾 . 点 代表一定有一个任意字符的字符 \ 转义字符，将特殊符号的特殊意义去除 *星号 重复零个到无穷多个的前一个字符 .* 表示任意个字符（包含空行） [list] 从字符集合的RE字符里找出想要选取的字符 [n1-n2] 从字符集合的RE字符里面找出想要选取的字符范围 [^list] 从字符集合的RE字符里面找出不要的字符串或范围 {n,m} 连续n到m的前一个RE字符，若为{n}则是连续n个前一个RE字符，若为{n,}则是连续n个以上的前一个RE字符 1.4. 扩展正则表达式 RE字符 意义 + 重复一个或一个以上的前一个RE字符 ? 零个或一个的前一个RE字符 “竖杠” 用或（or）的方式找出数个字符串 () 找出 “组”字符串 ()+ 多个重复组的判别 1.5. 注意 {}、+、-、|等在grep中使用时需要加反斜杠脱义，而在egrep直接使用即可。 egrep 和 grep -E 的效果是一样的。 sed -r 是使用扩展正则表达式的参数。 2. 支持正则的常用工具 2.1. grep 和 egrep2.1.1. grepgrep是以行为单位，在数据中进行字符串对比，并打印出所匹配到的字符串及其整行内容。 常用参数 参数说明 -A 后面可加数字，为after之意，列出匹配到的行及后面的n行 -B 后面可加数字，为before之意，列出匹配到的行及前面的n行 -C 综合-A和-B的功能 -n 显示出所匹配到的行的行号 -v 反向匹配 -i 忽略字母的大小写 -c 打印符合要求的行的个数 -o 打印符合要求的关键字出现的字数 -r 会把目录下面所有的文件全部遍历（该目录下的子目录下的文件也会遍历） –color=auto 自动加上颜色显示出关键字 2.1.2. egrepgrep 和 grep -E 是别名的关系，是grep使用扩展正则表达式要用的参数。grep默认只支持基础正则表达式，所以，当使用到扩展正则表达式的时候，就要用这个命令. 2.1.3. 一些例子 过滤出带有某个关键词的行并输出行号 grep -n &#39;root&#39; 1.txt 过滤出不带有某个关键字的行并输出行号 grep -n -v &#39;root; 1.txt 过滤出所有包含数字的行 grep &#39;[0-9]&#39; 1.txt 过滤出所有不包含数字的行 grep -v &#39;[0-9]&#39; 1.txt 去除所有以‘#’开头的行 grep -v &#39;^#&#39; 1.txt 去除所有空行和以‘#’开头的行 grep -v &#39;^$&#39; 1.txt | grep -v &#39;^#&#39; 过滤出以英文字母开头的行 grep &#39;^[a-zA-Z]&#39; 1.txt 过滤出以非数字开头的行 grep &#39;^[^0-9]&#39; 1.txt 过滤任意一个或多个字符 grep &#39;r.o&#39; 1.txt ； grep &#39;r*t&#39; 1.txt ； grep &#39;r.*p&#39; 1.txt . 表示任意一个字符 * 表示零个或多个*前面的字符 .* 表示零个或多个任意字符，空行也包含在内 grep -E &#39;ro?t&#39; 1.txt ？表示匹配零个或一个?前面的字符 grep -E &#39;ro+t&#39; 1.txt +表示匹配一个或多个+前面的字符 指定过滤字符次数 grep &#39;o\{2\}&#39; 1.txt egrep &#39;o+&#39; 1.txt 表示1个或多个前面的字符 egrep &#39;o?&#39; 1.txt 表示0个或1个前面的字符 egrep &#39;roo|body&#39; 1.txt 匹配roo或者匹配body（grep ‘roo\|body’ 1.txt 也可以实现这个功能，即用转义符把|转义） egrep &#39;r(oo)|(at)o&#39; 1.txt 用括号表示一个整体 egrep &#39;(oo)+&#39; 1.txt 表示匹配1个或多个‘oo’ egrep &#39;(oo){2}&#39; 1.txt 表示匹配有两次’oo’ egrep &#39;(oo){1,2}&#39; 1.txt 表示匹配有一次或两次’oo’ 2.2. sed2.2.1. sed 的用法sed是一个很好的文件处理工具，本事是一个管道命令，主要是以行为单位进行处理，可以将数据进行替换、删除、新增、选取等特定工作。sed的用法如下： sed的命令行格式为 sed [-nefri] &#39;command&#39; 输入文本 2.2.2. sed 常用选项 选项 意义 -n 使用安静（silent）模式。在一般的sed的用法中，所有来自stdin的数据都会被列到屏幕上。但如果加上-n选项后，则只有经过sed特殊处理的那一行（或者动作）才会被列出来。 -e 直接在命令行模式上进行sed的动作编辑 -f 直接将sed的动作写在一个文件内，-f filename 则可以执行filename内的sed动作 -r sed在使用扩展正则表达式需要加的参数（默认是基础正则表达式的使用） -i 直接修改读取的文件内容，而不是仅仅显示在屏幕上 2.2.3. sed 常用命令 命令 意义 a 新增，a的后面可以接字符串，而这些字符串会在新的一行出现（当前的下一行） c 取代，c的后面可以接字符串，而这些字符串可以取代n1,n2之间的行 d 删除，因为是删除操作，所以d后面通常不接任何东西 i 插入，i的后面可以接字符串，而这些字符串会在新的一行出现（当前的上一行） p 打印，即将某个选择的数据打印出来。通常p会与参数 sed -n 一起使用 s 替换，可以直接进行替换的工作。通常这个s的动作可以搭配正则表达式。例如 1,20s/old/new/g 2.2.4. sed 一些常用例子1. 打印指定行 打印第10行：sed -n &#39;10p&#39; 1.txt 打印1到4行：sed -n &#39;1,4p&#39; 1.txt 打印5行到最后：sed -n &#39;5,$p&#39; 1.txt 2. 打印包含某个字符串的行 打印出包含root的行：sed -n &#39;/root/p&#39; 1.txt 可以使用正则表达式中的符号，例如^、.、*、$等，-r选项是使用扩展正则表达式时要加的选项（默认是基础正则表达式的使用） 3. -e 可以实现同时进行多个任务的选项 sed -e &#39;/root/p&#39; -e &#39;/body/p&#39; -n 1.txt 匹配root和body的行，如果一行中有root和body，则该行会被打印两次 也可以用分号;实现：sed &#39;/root/p ; /body/p&#39; -n 1.txt 功能同上 4. 删除行 删除包含root的行：sed &#39;/root/d&#39; 1.txt 删除第一行，其它行显示：sed &#39;1d&#39; 1.txt 删除1到10行，其它行显示：sed &#39;1,10d&#39; 1.txt 5. 替换 sed &#39;1,2s/ot/to/g&#39; 1.txt 其中的s就是替换的意思，g为全局替换，否则只替换本行中出现的第一个，/分隔符也可以用#、@等符号 删除所有数字：sed &#39;s/[0-9]//g&#39; 1.txt 删除所有非数字：sed &#39;s/[^0-9]//g&#39; 1.txt 调换两个字符串的位置：head -n2 1.txt | sed &#39;s/\(root\)\(.*\)\(bash\)/\3\2\1/&#39; 或 head -n2 1.txt | sed -r &#39;s/(root)(.*)(bash)/\3\2\1/&#39; 直接修改文件内容：sed -i &#39;s/ot/to/g&#39; 1.txt 2.2.5. sed 练习题和答案 把/etc/passwd 复制到 /root/test.txt，用sed打印所有行：/bin/cp /etc/passwd /root/test.txt ; sed -n &#39;1,$p&#39; test.txt 打印test.txt的3到10行：sed -n &#39;3,10p&#39; test.txt 打印test.txt中包含root的行：sed -n &#39;/root/p&#39; test.txt 删除test.txt的15行以及以后所有行：sed &#39;15,$d&#39; test.txt 删除test.txt中包含bash的行：sed &#39;/bash/d&#39; test.txt 替换test.txt 中’root’为’toor’：sed &#39;s/root/toor/g&#39; test.txt 替换text.txt中/sbin/nologin为/bin/login：sed &#39;s#sbin/login#bin/login#g&#39; test.txt 删除test.txt中5到10行所有的数字：sed &#39;5,10s/[0-9]//g&#39; test.txt 删除test.txt中所有的特殊字符（除了数字以及大小写字母）：sed &#39;s/[^0-9a-zA-Z]//g&#39; test.txt 把test.txt中第一个单词和最后一个单词调换位置：sed -r &#39;s/(^[a-zA-Z]+)([^a-zA-Z].*[^a-zA-Z])([a-zA-Z]+$)/\3\2\1/&#39; test.txt 把test.txt中出现的第一个数字和最后一个单词调换位置：sed -r &#39;s/(^[^0-9]*)([0-9]+)([^0-9].*[^a-zA-Z]+$)/\1\4\3\2/&#39; test.txt 把test.txt中第一个数字移动到行末尾：sed -r &#39;s/(^[^0-9]*)(^[0-9]+)([^0-9].*$)/\1\3\2/&#39; test.txt 在test.txt中20行到末行最前面加”aaa:”：sed &#39;20,$s/^.*$/aaa:&amp;/&#39; test.txt 2.2.6. sed 学习说明sed的常用功能基本上都在上面，这些就足够日常运维工作的使用了，若是遇到复杂的需求，再去查一下资料即可。 2.3. awkawk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说，awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 awk有3个不同版本：awk、nawk和gawk，未作特别说明，一般指gawk，gawk是awk的GNU版本。 awk其名称得自于它的创始人 Alfred Aho、Peter Weinberger和Brian Kernighan 姓氏的首个字母。实际上AWK的确拥有自己的语言：AWK程序设计语言，三位创建组已将它正式定义为”样式扫描和处理语言”。它允许您创建简短的程序，这些程序读取输入文件、为数据排序、处理数据、对输入执行计算以及生成报表，还有无数其他的功能。 2.3.1. awk 初学笔记1. awk的用法awk和sed一样，都是流式编辑器，针对文档中的行来操作，一行一行地执行。awk兼具sed的所有功能，而且更加强大。awk工具其实是很复杂的（有专门的书来介绍它的应用），对于初学者来说，只要能处理日常管理工作中的问题即可。鉴于此，下面的内容仅仅介绍了比较常见的awk应用。 - 截取文档中的某个段 截取文档中的某个段 awk -F&#39;:&#39; &#39;{print $1}&#39; 1.txt 本例中，-F选项的作用是指定分隔符。若不加-F选项，则以空格或者tab为分隔符。print为打印的动作，用来打印某个字段。$1为第一个字段，$2为第2个字段，以此类推。但是$0比较特殊，它表示整行。awk -F&#39;:&#39; &#39;{print $0}&#39; 1.txt 注意awk的格式，-F后面紧跟单引号，单引号里面为分隔符。print的动作要用{}括起来，否则会报错。 print也可以打印自定义的内容，但是自定义的内容要用双引号括起来 awk -F&#39;:&#39; &#39;{print $1&quot;#&quot;$2&quot;#&quot;$3&quot;#&quot;$4}&#39; 1.txt - 匹配字符或者字符串 匹配字符或字符串 awk &#39;/oo/&#39; 1.txt 这种用法跟sed的用法类似，能实现grep的功能，但没有颜色显示，也不如grep用起来方便。 可针对某个段匹配 awk -F&#39;:&#39; &#39;$1~/oo/&#39; 1.txt 这里的~就是匹配的意思。 多次匹配 awk -F&#39;:&#39; &#39;/root/ {print $1,$3}; $1~/test/; $3~/20/&#39; 1.txt - 条件操作符awk中可以用逻辑符号进行判断，比如==就是等于，也可以理解为精确匹配。另外还有&gt;、&gt;=、&lt;、&lt;=、!=等。值得注意的是，在和数字比较时，若把比较的数字用双引号括起来，那么awk不会认为是数字，而会认为是字符，不加双引号会认为是数字。 条件操作符 ==,&gt;,&lt;,!=,&gt;=,&lt;= awk -F&#39;:&#39; &#39;$3==&quot;0&quot;&#39; 1.txt awk -F&#39;:&#39; &#39;$3&gt;=&quot;500&quot;&#39; 1.txt awk -F&#39;:&#39; &#39;$7!=&quot;/sbin/mologin&quot;&#39; 1.txt awk -F&#39;:&#39; &#39;$3&lt;$4&#39; 1.txt awk -F&#39;:&#39; &#39;$3&gt;&quot;5&quot; &amp;&amp; $3&lt;&quot;7&quot;&#39; 1.txt 另外还可以使用&amp;&amp;和||，它们分别表示”并且”和”或者”。 awk -F&#39;:&#39; &#39;$3&gt;&quot;5&quot; &amp;&amp; $7==&quot;/bin/bash&quot;&#39; 1.txt awk -F&#39;:&#39; &#39;$3&gt;&quot;5&quot; || $7==&quot;/bin/bash&quot;&#39; 1.txt - awk的内置变量awk的常用内置变量有OFS、NF和NR。OFS和-F选项有类似的功能，也是用来定义分隔符的，但是它是在输出的时候定义；NF表示用分隔符分隔后一共有多少段，NR表示行号。 OFS的用法： awk -F&#39;:&#39; &#39;{OFS=&quot;#&quot;} {print $1,$3,$4}&#39; 1.txt awk -F&#39;:&#39; &#39;{OFS=&#39;#&#39;} {if ($3&gt;1000) {print $1,$2,$3,$4}}&#39; 1.txt NF的具体用法： head -n3 1.txt | awk -F &#39;:&#39; &#39;{print NF}&#39; head -n3 1.txt | awk -F &#39;:&#39; &#39;{print $NF}&#39; 这里NF是多少段，$NF是最后 一段的值。 NR的用法： head -n3 1.txt | awk -F &#39;:&#39; &#39;{print NR}&#39; 还可以用NR作为判断条件，比如打印20行以后的行 awk &#39;NR&gt;20&#39; 1.txt NR也可以和段匹配一起使用，如 awk -F &#39;:&#39; &#39;NR&gt;20 &amp;&amp; $1 ~/ssh/&#39; 1.txt - awk中的数学运算 awk可以更改段值 awk -F &#39;:&#39; &#39;$1=&quot;root&quot;&#39; 1.txt 也可以对各个段的值进行数学运算，例如把第三段和第四段的值相加并赋予第七段 awk -F &#39;:&#39; &#39;{$7=$3+$4;print $0}&#39; 1.txt 计算第三段的总和 awk -F &#39;:&#39; ‘{(tot=toy+$3)};END {print tot}’ 1.txt awk中也可以使用if 关键词 awk -F &#39;:&#39; &#39;{if ($1==&quot;root&quot;) print $0}&#39; 1.txt ~~~说明：以上介绍的内容仅仅是最基本的内容，这些东西完全可以满足日常工作的需求。若是遇到比较复杂的需求，再去查阅资料学习更深的东西。 2. awk练习题题目： 用awk打印整个test.txt。（以下操作都是针对test.txt的，用awk工具实现） 查找所有包含bash的行。 用:作为分隔符，查找第3个字段等于o的行。 用:作为分隔符，查找第1个字段为root的行，并把该段的root换成toor。（可以连同sed一起使用） 用:作为分隔符，打印最后一个字段。 打印行数大于20的所有行。 用:作为分隔符，打印所有第3个字段小于第4个字段的行。 用:作为分隔符，打印第1个字段以及最后一个字段，并且中间用@连接（例如，第1行应该是这样的形式：root@/bin/bash） 用:作为分隔符，把整个文档的第4个字段相加，求和。 答案： awk &#39;{print $0}&#39; test.txt awk &#39;/bash/&#39; test.txt awk -F&#39;:&#39; &#39;$3==&quot;o&quot;&#39; test.txt awk -F&#39;:&#39; &#39;$1==&quot;root&quot;&#39; test.txt | sed &#39;s/root/toor/&#39; awk -F&#39;:&#39; &#39;{print $NF}&#39; test.txt awk -F&#39;:&#39; &#39;NR&gt;20&#39; test.txt awk -F&#39;:&#39; &#39;$3&lt;$4&#39; test.txt awk -F&#39;:&#39; &#39;{print $1&quot;@&quot;$NF}&#39; test.txt awk -F&#39;:&#39; &#39;{(sum+=$4)}; END {print sum}&#39; test.txt 2.3.2. awk 入门笔记1. 使用方法使用格式为 : awk &#39;{pattern + action}&#39; {filename} 尽管操作可能会很复杂，但语法总是这样，其中pattern表示awk在数据中查找的内容，而action是在找到匹配内容时所执行的一系列命令。花括号（{ }）不需要在程序中始终出现，但它们用于根据特定的模式对一系列指令进行分组。pattern就是要表示的正则表达式，用斜杠括起来。 awk语言的最基本功能是在文件或者字符串中基于指定规则浏览和抽取信息，awk抽取信息后，才能进行其它文本操作。完整的awk脚本通常用来格式化文本文件中的信息。 通常，awk是以文件的一行为处理单位的。awk每接收文件的一行，然后执行相应的命令，来处理文本。 2. 调用awk的三种方式- 命令行方式格式：awk [-F field-separator] &#39;conmmands&#39; input-file(s)其中，commands是真正awk命令，[-F域分隔符]是可选的。input-file(s)是待处理的文件。在awk中，文件的每一行中，由域分隔符分开的每一项称为一个域。通常，在不指定-F域分隔符的情况下，默认的域分隔符是空格。 - shell脚本方式将所有的awk命令插入一个文件，并使awk程序可执行，然后awk命令解释器作为脚本的首行，一遍通过键入脚本名称来调用。相当于shell脚本首行的：#!/bin/sh可以换成：#!/bin/awk - 将所有的awk命令插入一个单独文件，然后调用格式 awk -f awk-script-file input-file(s)其中，-f选项加载awk-script-file中的awk脚本，input-file(s)跟上面的是一样的。 在这里，主要用的是第一种方式：命令行方式。 3. 入门实例假设last -n 5的输出如下：123456[root@www ~]# last -n 5 &lt;==仅取出前五行root pts/1 192.168.1.100 Tue Feb 10 11:21 still logged inroot pts/1 192.168.1.100 Tue Feb 10 00:46 - 02:28 (01:41)root pts/1 192.168.1.100 Mon Feb 9 11:41 - 18:30 (06:48)dmtsai pts/1 192.168.1.100 Mon Feb 9 11:41 - 11:41 (00:00)root tty1 Fri Sep 5 14:09 - 14:10 (00:01) 示例1如果只是显示最近登陆的5个账号123456#last -n 5 | awk '&#123;print $1&#125;'rootrootrootdmtsairoot awk工作流程是这样的：读入有’\n’换行符分割的一条记录，然后将记录按照指定的域分隔符划分域，填充域，$0则表示所有域，$1表示第一个域，$n表示第n个域。默认域分割符是”空白键”或”[tab]键”，所以$1表示登陆用户，$3表示登陆用户ip，以此类推。 示例2如果只是显示/etc/passwd的账户12345#cat /etc/passwd |awk -F ':' '&#123;print $1&#125;' rootdaemonbinsys 这种是awk+action的示例，每行都会执行action{print $1}。-F指定域分隔符为’:’。 示例3如果只是显示/etc/passwd的账户和账户对应的shell，而账户与shell之间以tab键分割12345#cat /etc/passwd |awk -F ':' '&#123;print $1"\t"$7&#125;'root /bin/bashdaemon /bin/shbin /bin/shsys /bin/sh 示例4如果只是显示/etc/passwd的账户和账户对应的shell，而账户与shell之间以逗号分割，而且在所有行添加列明name,shell，在最后一行添加blue,/bin/nosh12345678cat /etc/passwd |awk -F ':' 'BEGIN &#123;print "name,shell"&#125; &#123;print $1","$7&#125; END &#123;print "blue,/bin/nosh"&#125;'name,shellroot,/bin/bashdaemon,/bin/shbin,/bin/shsys,/bin/sh....blue,/bin/nosh awk的工作流程是这样的：先执行BEGiNG，然后读取文件，读入有/n换行符分割的一条记录，然后将记录按指定的域分割符划分域，填充域，$0则表示所有域，$1表示第一个域，$n表示第n个域，随后开始执行模式所对应的动作action。接着开始读入第二条记录……知道所有的记录都读完，最后执行END操作。 示例5搜索/etc/passwd有root关键字的所有行12#awk -F: '/root/' /etc/passwdroot:x:0:0:root:/root:/bin/bash 这种是pattern的使用示例，匹配了pattern（这里是root）的行才会执行action（没有指定action，默认输出每行的内容）。搜索支持正则，例如找root开头的：awk -F: &#39;/^root/&#39; /etc/passwd 示例6搜索/etc/passwd有root关键字的所有行，并显示对应的shell12# awk -F: '/root/&#123;print $7&#125;' /etc/passwd /bin/bash 这里指定了action{print $7} 4. awk 内置变量awk有许多内置变量用来设置环境信息，这些变量可以被改变，下面给出了最常用的一些变量。 变量名 值的意义 ARGC 命令行参数个数 ARGV 命令行参数排列 ENVIRON 支持队列中系统环境变量的使用 FILENAME awk浏览的文件名 FNR 浏览文件的记录数 FS 设置输入域分隔符，等价于命令行 -F 选项 NF 浏览记录的域的个数 NR 已读的记录数 OFS 输出域分隔符 ORS 输出记录分隔符 RS 控制记录分隔符 $0 整条记录 $1 当前行的第一个域 $n 当前行的第n个域 示例如下： 统计/etc/passwd的文件名，每行的行号，每行的列数，对应的完整行内容：12345#awk -F ':' '&#123;print "filename:" FILENAME ",linenumber:" NR ",columns:" NF ",linecontent:"$0&#125;' /etc/passwdfilename:/etc/passwd,linenumber:1,columns:7,linecontent:root:x:0:0:root:/root:/bin/bashfilename:/etc/passwd,linenumber:2,columns:7,linecontent:daemon:x:1:1:daemon:/usr/sbin:/bin/shfilename:/etc/passwd,linenumber:3,columns:7,linecontent:bin:x:2:2:bin:/bin:/bin/shfilename:/etc/passwd,linenumber:4,columns:7,linecontent:sys:x:3:3:sys:/dev:/bin/sh 使用printf替代print，可以让代码更加简洁、易读：1awk -F ':' '&#123;printf("filename:%10s,linenumber:%s,columns:%s,linecontent:%s\n",FILENAME,NR,NF,$0)&#125;' /etc/passwd 5. print 和 printfawk中同时提供了print和printf两种打印输出的函数。 其中print函数的参数可以是变量、数值或者字符串。字符串必须用双引号引用，参数用逗号分隔。如果没有逗号，参数就串联在一起而无法区分。这里，逗号的作用与输出文件的分隔符的作用是一样的，只是后者是空格而已。 printf函数，其用法和C语言中printf基本相似，可以格式化字符串，输出复杂时，printf更加好用，代码更易懂。 6. awk编程变量和赋值除了awk的内置变量，awk还可以自定义变量。 下面统计/etc/passwd的账户人数1234awk '&#123;count++;print $0;&#125; END&#123;print "user count is ", count&#125;' /etc/passwdroot:x:0:0:root:/root:/bin/bash......user count is 40 count是自定义变量。之前的action{}里都是只有一个print，其实print只是一个语句，而action{}可以有多个语句，以;号隔开。 上面的用法里没有初始化count，虽然默认是0，但是妥当的做法还是初始化为0：12345awk 'BEGIN &#123;count=0;print "[start]user count is ", count&#125; &#123;count=count+1;print $0;&#125; END&#123;print "[end]user count is ", count&#125;' /etc/passwd[start]user count is 0root:x:0:0:root:/root:/bin/bash...[end]user count is 40 统计某个目录下的文件占用的字节数12ls -l |awk 'BEGIN &#123;size=0;&#125; &#123;size=size+$5;&#125; END&#123;print "[end]size is ", size&#125;'[end]size is 8657198 如果以M为单位显示：12ls -l |awk 'BEGIN &#123;size=0;&#125; &#123;size=size+$5;&#125; END&#123;print "[end]size is ", size/1024/1024,"M"&#125;'[end]size is 8.25889 M 注意，统计不包括目录的子目录。 条件语句awk中的条件语句是从C语言中借鉴而来的，见如下声明方式：12345678910111213141516171819if (expression) &#123; statement; statement; ... ...&#125;if (expression) &#123; statement;&#125; else &#123; statement2;&#125;if (expression) &#123; statement1;&#125; else if (expression1) &#123; statement2;&#125; else &#123; statement3;&#125; 统计某个目录下的文件占用的字节数，过滤4096大小的文件（一般都是目录）12ls -l |awk 'BEGIN &#123;size=0;print "[start]size is ", size&#125; &#123;if($5!=4096)&#123;size=size+$5;&#125;&#125; END&#123;print "[end]size is ", size/1024/1024,"M"&#125;' [end]size is 8.22339 M 循环语句awk中的循环语句同样借鉴于C语言，支持while、do-while、for、break、continue，这些关键字的语义和C语言中的语义完全相同。 数组因为awk中数组的下表可以是数字和字母，数字的下标通常被称为关键字（key）。值和关键字都存储在内部的一张针对key/value应用hash的表格里。由于hash不是顺序存储，因此在显示数组内容时会发现，它们并不是按照你预料的顺序显示出来的。数组和变量一样，都是在使用时自动创建的，awk也同样会自动判断其存储的是数字还是字符串。一般而言，awk中的数组用来从记录中收集信息，可以用于计算总和、统计单词以及跟踪模板被匹配的次数等等。 显示/etc/passwd的账户12345678awk -F ':' 'BEGIN &#123;count=0;&#125; &#123;name[count] = $1;count++;&#125;; END&#123;for (i = 0; i &lt; NR; i++) print i, name[i]&#125;' /etc/passwd0 root1 daemon2 bin3 sys4 sync5 games...... 这里使用for循环遍历数组。 2.3.3. awk 学习说明以上便是awk最常用的使用方法。但如果想深学awk编程，请参考专业书籍。 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux计划任务管理技术]]></title>
    <url>%2F2018%2F01%2F19%2FLinux%2F011.%20Linux%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[GO 0. 计划任务服务程序Linux系统的计划任务分为三种： 一次性计划任务（用at命令实现，由atd服务提供） 周期性计划任务（用crontab命令实现，由crond服务提供） 系统级别的计划任务及其扩展anacron：在一个指定时间间隔错过后自动执行任务 1. 一次性计划任务1.1. at 命令一次性计划任务只执行一次，一般用于满足临时的工作需求。我们可以用at命令来实现这种功能。用法如下： at 时间 ：添加一次性计划任务 at -l ：查看已设置好但还未执行的一次性计划任务 atrm 任务序号 ：删除一条一次性计划任务（还可以进入到/var/spool/at目录里把计划任务删除，计划任务的文件都保存在该目录里，可以用rm -f 文件名来删除(以文件的形式删除计划任务，因为计划任务是以文件形式保存在该目录中)） 1.2. 关于at的说明在通常情况下，超级用户都可以使用这个命令。对于其他用户来说，能否可以使用就取决于两个文件：/etc/at.allow 和 /etc /at.deny。 如果你要让哪个用户不能使用计划任务，就直接把他的用户名写进去就可以了，一排只能写一个。 同时写入allow 及deny, 允许。 1.3. at的使用示例在使用at命令来设置一次性计划任务时，默认采用的是交互式方法。例如，使用下述命令将系统设置为在今晚23：30分自动重启网站服务：123456[root@theshuhost ~]# at 23:30at&gt; systemctl restart httpdat&gt; &lt;EOT&gt; # 此处请同时按下Ctrl + D组合键来结束编写计划任务job 1 at Fri Jan 19 23:30:00 2018[root@theshuhost ~]# at -l1 Fri Jan 19 23:30:00 2018 a root 也可以利用管道符来达到非交互式的方式创建一次性计划任务的目的：12345[root@theshuhost ~]# echo "systemctl restart httpd" | at 23:40job 2 at Fri Jan 19 23:40:00 2018[root@theshuhost ~]# at -l1 Fri Jan 19 23:30:00 2018 a root2 Fri Jan 19 23:40:00 2018 a root 如果我们不小心设置了两个一次性计划任务，可以使用下面的命令轻松删除其中一个：123456[root@theshuhost ~]# at -l1 Fri Jan 19 23:30:00 2018 a root2 Fri Jan 19 23:40:00 2018 a root[root@theshuhost ~]# atrm 2[root@theshuhost ~]# at -l1 Fri Jan 19 23:30:00 2018 a root 2. 周期性计划任务相对与at，cron的优点就是能够周期性的执行某个命令,at却只能执行一次。 cron的后台进程名字是crond ,cron也是system V的服务，所以我们可以service crond start|stop 来启动和关闭此服务,也可以使用chkconfig或者ntsysv来选择cron服务的默认开启。 2.1. crontab 命令Linux的周期性任务计划功能的操作都是通过这个crontab命令来完成的。常用的选项有： -u：指定某个用户，不加-u选项则为当前用户 -e：制定计划任务 -l：列出计划任务(也可以到/var/spool/cron/目录查看。里面的文件名字就是对应用户的cron任务) -r：删除当前用户的计划任务 在配置文件/etc/crontab中可以查看计划任务配置的规则：123456789101112SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed 以一个例子来说明其设置的格式： crontab -e 回车后输入如下内容： 01 10 05 06 3 echo &quot;ok&quot; &gt; /root/cron.log 这样就增加了一条计划任务，关于计划任务内容的说明如下： 每个字段的数字分别表示（从左到右）：分、时、日、月、周、命令。 上一个例子的含义是：在6月5日（这一天必须是星期三）的10点01分执行命令echo “ok” &gt; /root/cron.log。 crontab -e命令实际上是打开了配置文件/var/spool/cron/username（如果是root用户，则打开的是/var/spool/cron/root）,所使用的编辑器是vi，所以要保存的话则需要在命令模式下输入”:/wq”即可。 注意：千万不要直接去编辑那个文件，因为可能会出错，所以一定要使用命令crontab -e来编辑。 使用该命令的其他常用用法： crontab -l ：查看已经设定的任务计划 crontab -r ：删除任务计划 2.2. 一个问题的说明vim /etc/crontab 与crontab -e写入的定时运行有什么区别? vim /etc/crontab：是系统级别定义的crontab，/etc/crontab的所有者和组都是root crontab -e ：是用户自定义的crontab，是所有的用户都可以写入的 两种方法记录的位置不一样，一个在/etc/ 另一个在/var/ 里面。都被cron服务调用 2.3. 关于任务计划的练习题目如下： 每天凌晨1点20分清除/var/log/slow.log这个文件 每周日3点执行”/bin/sh /usr/local/sbin/backup.sh” 每月14号4点10分执行”/bin/sh /usr/local/sbin/backup_month.sh” 每隔8小时执行”ntpdate time.windows.com” 每天的1点、12点、18点执行”/bin/sh /usr/local/sbin/test.sh” 每天的9点到18点执行”/bin/sh /usr/local/sbin/test2.sh” 答案如下： 20 1 * * * echo &quot;&quot; &gt; /var/lpg/slow.log 0 3 * * 0 /bin/sh /usr/local/sbin/backup.sh 10 4 14 * * /bin/sh /usr/local/sbin/backup_month.sh 0 */8 * * * ntpdate time.windows.com 0 1,12,18 * * /bin/sh /usr/local/sbin/test.sh 0 9-18 * * * /bin/sh /usr/local/sbin/test2.sh 说明： 每隔8小时，就是用全部小时（0-23）去除以8,其实算出来应该是0、8、16三个数。 当遇到多个数（分钟、小时、月、周）例如第5题，则需要用都好隔开。 而时间段是可以用n-m的方式表示的，比如第6题中的9-18 在设置好所有的计划任务后需要查看一下crond服务是否启动：service crond status 3. 系统级别的计划任务及其扩展anacronanacrontab就是系统计划任务的扩展文件：在一个指定时间间隔错过后自动执行任务。 这个是系统设置好了，清理系统垃圾或者是自动执行某些脚本的系统任务，一般我们做了解就行了，不要更改。 配置文件是/etc/anaconrtab123456789# /etc/anacrontab: configuration file for anacron# See anacron(8) and anacrontab(5) for details.SHELL=/bin/shPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root#####格式是这样的：period(频率.天数) delay(延迟,分钟) job- identifier command1 65 cron.daily run-parts /etc/cron.daily7 70 cron.weekly run-parts /etc/cron.weekly30 75 cron.monthly run-parts /etc/cron.monthly 说明： SHELL：就是运行计划任务的解释器，默认是bash PATH：执行命令的环境变量 MAILTO：计划任务的出发者用户 HOME：家目录为/ run-parts是一个脚本，在/usr/bin/run-parts，作用是执行一个目录下的所有脚本/程序。 run-parts /etc/cron.hourly执行目录/etc/cron.hourly/之下的所有脚本/程序. run-parts下面就是运行的命令 第一行的意思是：每天开机65分钟后就检查cron.daily文件是否被执行了，如果今天没有被执行就执行它 第二行的意思是：每隔7天开机后70分钟检查cron.weekly文件是否被执行了,如果一周内没有被执行就执行它 和at差不多，就是/etc/cron.deny这个配置文件来控制, 同时写入allow 及deny, 允许. OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Vim实用技巧》-开始：Vim解决问题的方式]]></title>
    <url>%2F2017%2F12%2F29%2FTool%2F007.%20%E3%80%8AVim%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7%E3%80%8B-%E5%BC%80%E5%A7%8B%EF%BC%9AVim%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%E7%9A%84%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[GO 技巧1 结识 . 命令理想的编辑模式：用一次按键移动，用另一次按键执行。 . 命令可以重复上次修改。 上次修改 可以指很多东西，一次修改的单位可以是字符、整行，甚至是整个文件。 每次进入插入模式时，也会形成一次修改。从进入插入模式的那一刻起（例如，输入i），直到返回普通模式时为止（输入 Esc ）,Vim 会记录每一个按键操作。做出这样一个修改后再用 . 命令，就会重新执行所有的这些按键操作。 补充内容 x 命令会删除光标下的字符 dd 命令会删除光标所在的一整行 &gt;G 命令会增加从当前行到文档末尾处的缩进层级 技巧2 不要自我重复对于在行尾添加内容这样的常见操作，如添加分号，Vim 提供了一个专门的命令，可以把两步操作合并为一步。 减少无关紧要的移动。以下面的一个例子来说明： a 命令在当前光标后添加内容，而 A 命令则在当前行的结尾添加内容。不管光标当前处于什么位置，输入 A 都会进入插入模式，并把光标移动行尾。换句话说，它把 $a 封装成了一个按键操作。 很多Vim的单键命令都可以被看成两个或多个其他命令的组合。下表列出了类似的一些例子： 复合命令 等效的长命令 C c$ s cl S ^c A $a o A O ko 上表所示这些命令的共同点是，它们全都会从普通模式切换到插入模式。 补充内容 $ 命令把光标移到行尾 j 命令使光标下移一行 技巧3 以退为进我们可以用一种常用的 Vim 操作习惯在一个字符前后各添加一个空格。乍一看，这种方法有点古怪，不过其好处是可重复，这将使我们可以事半功倍地完成工作 先后退一步或多步，然后前进一步或多步，这是个奇怪的小花招，看起来可能不够直接。但这样做最大的好处是：我们可以用 . 命令重复这一修改。 与其和 Vim 区分模式的编辑模型做斗争，倒不如与它一起协同工作。然后，你就会发现它能把特定任务变得多么的容易。 补充内容 s 命令把两个操作合并为一个：它先删除光标下的字符，然后进入插入模式 技巧4 执行、重复、回退在面对重复性工作时，我们需要让移动动作和修改都能够重复，这样就可以达到一个最佳编辑模式。Vim对此的支持是：它会记住我们的操作，并使最常用的操作触手可及，所以我们可以很方便地重复执行它们。本节将介绍 Vim 可以重复执行的每个操作，并学习如何回退这些命令。 当 Vim 让一个操作或移动可以很方便地重复时，它总是会提供某种方式，让我们在不小心做过头时能回退回来。下表总结了Vim中可重复执行的命令，以及相应的回退方式。在多数场景中，撤销（Undo）都是很有用的帮助。 目的 操作 重复 回退 做出一个修改 {edit} . u 在行内查找下一指定字符 f{char}/t{char} ; , 在行内查找上一指定字符 F{char}/T{char} ; , 在文档中查找下一出匹配项 /pattern n N 在文档中查找上一项匹配项 ?pattern n N 执行替换 :s/target/replacement &amp; u 执行一系列修改 qx{changes}q @x u 技巧5 查找并手动替换Vim 提供了一个 :substitute 命令专门用于查找替换任务，不过用上面介绍的技术，我们也可以手动修改第一处地方，然后再一个个地查找替换其他匹配项。 . 命令可以把我们从繁重的工作中解放出来，而即将登场的另一个有用的单键命令，则能够让我们方便地在匹配项间跳转。这样才能逐个决定每一个匹配项是否需要操作。 补充内容 *将文档中光标所在单词全部匹配出来并高亮显示 :set hls 设置高亮显示 cw 命令会删除从光标位置到单词结尾的字符，并进入插入模式 技巧6 结识 . 范式理想模式：用一键移动，另一键执行 所有这些例子都利用 . 命令重复上次的修改，不过这不是它们唯一的共同点，另外的共同点是它们都只需要按一次键就能把光标移到下一个目标上。 用一次按键移动，另一次按键执行，没有再比这更好的了，不是吗？这就是我们的理想解决方案。为了方便起见，我们把它叫做“ . 范式”。 总结回顾前面3个 . 命令编辑任务 在技巧 2 中，我们想在一系列行的结尾添加分号。我们先用 A; &lt;Esc&gt; 修改了第一行，做完这步准备后，就可以使用 . 命令对后续行重复此修改。我们使用了 j 命令在行间移动，要完成剩余的修改，只需简单地按足够多次 j. 就可以了。 在技巧 3 中，我们想为每个 + 号的前后各添加一个空格。我们先用 f+ 命令跳到目标字符上，然后用 s 命令把一个字符替换成 3 个，做完这步准备后，我们就可以按若干次 ;. 完成此任务。 在技巧 5 中，我们想把每处出现单词“content”的地方都替换成“copy”。我们使用 * 命令来查找目标单词，然后用 cw 命令修改第一处地方。做完这步准备后，就可以用 n 键跳到下一匹配项，然后用 . 键做相同的修改。要完成这项任务，只需简单地按足够多次 n. 就行了。 OK]]></content>
      <categories>
        <category>Tool</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim的语言性思维]]></title>
    <url>%2F2017%2F12%2F28%2FTool%2F006.%20Vim%E7%9A%84%E8%AF%AD%E8%A8%80%E6%80%A7%E6%80%9D%E7%BB%B4%2F</url>
    <content type="text"><![CDATA[GO 本文内容并非原创，而是整理自别人的技术文章。原文请看这里一起来说 Vim 语 1. Vim的常用三种模式 正常模式（进入vim时处于的就是默认模式） 插入模式（编辑文本时的所处的模式） 命令模式（进行保存退出、查找替换、设置等动作时所处的模式） 2. Vim的语言性思维2.1 动词动词代表了我们打算对文本进行什么样的操作。例如： d 表示删除 delete r 表示替换 replace c 表示修改 change y 表示复制 yank v 表示选取 visual select p 表示粘贴 paste 等等…… 2.2 名词名词代表了我们即将处理的文本。Vim 中有一个专门的术语叫做文本对象 text object。例如： w 表示一个单词 word s 表示一个句子 sentence t 表示一个HTML标签 tag p 表示一个段落 paragraph 引号或各种括号 所包含的文本称作一个 文本块 等等…… 2.3 介词介词界定了待编辑文本的范围或者位置。例如： i 表示“在……之内” inside a 表示“环绕” around t 表示“到……位置前” to f 表示“到……位置上” forward 下面是几个有关范围的示意图： 2.4 组词为句有了这些基本的语言元素，我们就可以着手构造一些简单的命令了。文本编辑命令的基本语法如下： 动词 [介词] 名词 下面是一些例子： 删除一个段落: delete inside paragraph–&gt;dip 选取一个句子: visual select inside sentence–&gt;vis 修改一个单词: change inside word–&gt;ciw 修改一个单词: change around word–&gt;caw 删除文本直到字符“x”（不包括字符“x”）: delete to x–&gt;dtx 删除文本直到字符“x”（包括字符“x”）: delete forward x–&gt;dfx 2.5 数词数词指定了待编辑文本对象的数量，从这个角度而言，数词也可以看作是一种介词。引入数词之后，文本编辑命令的语法就升级成了下面这样： 动词 介词/数词 名词 下面是几个例子： 修改三个单词：change three words–&gt;c3w 删除两个单词：delete two words–&gt;d2w 另外，数词也可以修饰动词，表示将操作执行 n 次。于是，我们又有了下面的语法： 数词 动词 名词 请看示例： 两次删除单词（等价于删除两个单词）: twice delete word–&gt;2dw 三次删除字符（等价于删除三个字符）：three times delete character–&gt;3x 3. 结束语以上内容为一种使用Vim的思维方式。 OK]]></content>
      <categories>
        <category>Tool</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim的配置]]></title>
    <url>%2F2017%2F12%2F27%2FTool%2F005.%20Vim%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[GO 1. Vim配置文件说明 Vim的配置文件有两个，/etc/vimrc是Vim的全局配置文件，~/.vimrc是用户的Vim配置文件。一般我们配置的是自己家目录里的这个配置文件~/.vimrc 在Vim的配置文件里，双引号&quot;是注释符 2. 常用Vim配置选项12345678910set hlsearch "高亮度反白set backspace=2 "可随时用退格键删除set autoindent "自动缩排set ruler "可现实最后一行的状态set showmode "左下角那一行的状态set nu "显示行号set background=dark "显示不同的底色色调set nobackup "不自动建立*.~备份文件syntax on "进行语法检验，颜色显示color murphy 3. Vim7.1在Win下的编码设置1234567891011121314151617181920"设置字体编码"set guifont=Courier_New:h14:cANSI " 设置字体 set fencs=utf-8,ucs-bom,shift-jis,gb18030,gbk,gb2312,cp936set termencoding=utf-8"set encoding=utf-8"set fileencodings=ucs-bom,utf-8,cp936"set fileencoding=utf-8set encoding=utf-8set fileencodings=utf-8,chinese,latin-1if has("win32") set fileencoding=chineseelse set fileencoding=utf-8endif"解决菜单乱码source $VIMRUNTIME/delmenu.vimsource $VIMRUNTIME/menu.vim"解决consle输出乱码"language messages zh_CN.utf-8 4. 显示相关123456789101112set shortmess=atI " 启动的时候不显示那个援助乌干达儿童的提示 set number " 显示行号syntax on " 语法高亮 set showcmd " 输入的命令显示出来，看的清楚些 set ruler " 打开状态栏标尺 set cursorline " 突出显示当前行"set magic " 设置魔术"set guioptions-=T " 隐藏工具栏"set guioptions-=m " 隐藏菜单栏set laststatus=1 " 启动显示状态行(1),总是显示状态行(2) "set statusline=\ \ \ %F%m%r%h%w\ \ \ [FORMAT=%&#123;&amp;ff&#125;]\ \ \ [TYPE=%Y]\ \ \ [POS=%l,%v][%p%%]set statusline=\ %&lt;%F[%1*%M%*%n%R%H]%=\ %y\ %0(%&#123;&amp;fileformat&#125;\ %&#123;&amp;encoding&#125;\ %c:%l/%L%)\ "状态行显示的内容 ~~ 1234567891011"高亮所在行和所在列的设置se cuc " 用浅色高亮当前列 se cul " 用浅色高亮当前行 highlight CursorLine cterm=NONE ctermbg=black ctermfg=green guibg=NONE guifg=NONE"highlight CursorColumn cterm=NONE ctermbg=black ctermfg=green guibg=NONE guifg=NONE"highlght 主要是用来配色的，包括语法高亮等个性化的配置。可以通过:h highlight，查看详细信息"CursorLine 和 CursorColumn 分别表示当前所在的行列"cterm 表示为原生vim设置样式，设置为NONE表示可以自定义设置。"ctermbg 设置终端vim的背景色"ctermfg 设置终端vim的前景色"guibg 和 guifg 分别是设置gvim的背景色和前景色，本人平时都是使用终端打开 vim，所以只是设置终端下的样式 5. 功能相关1234567891011121314151617" 自动缩进 且 统一缩进为4set autoindentset cindentset softtabstop=4set shiftwidth=4set tabstop=4 " Tab键的宽度set nobackup " 从不备份 set autowrite " 自动保存set backspace=2 " 使键（backspace）正常处理indent, eol, start等set history=1000 " 历史记录数set noeb " 去掉输入错误的提示声音set confirm " 在处理未保存或只读文件的时候，弹出确认set noexpandtab " 不要用空格代替制表符set nocompatible " 不要使用vi的键盘模式，而是vim自己的set ignorecase " 搜索忽略大小写set cmdheight=2 " 命令行（在状态行下）的高度，默认为1，这里是2au BufRead,BufNewFile * setfiletype txt " 高亮显示普通txt文件（需txt.vim脚本） 6. 设置自动缩进本文内容转载自 阿铭Linux centos系统，修改vim的配置文件 /etc/vimrc 添加如下内容： 打开 vimrc ，添加以下语句来使得语法高亮显示：syntax on 如果此时语法还是没有高亮显示，那么在 /etc 目录下的profile文件中添加以下语句：export TERM=xterm-color 解决方向键和退格键失效的问题（采用非兼容模式） set nocompatible set backspace=2 设置 Windows 风格的 C/C++ 自动缩进（添加以下 set 语句到 vimrc 中） 设置（软）制表符宽度为 4 ：set tabstop=4 和 set softtabstop=4 设置缩进的空格数为 4：set shiftwidth=4 设置自动缩进 ：即每行的缩进值与上一行相等；使用 noautoindent 取消设置：set autoindent 设置 使用 C/C++ 语言的自动缩进方式：set cindent 设置 C/C++ 语言的具体缩进方式 ：set cinoptions={0,1s,t0,n-2,p2s,(03s,=.5s,&gt;1s,=1s,:1s 如果想在左侧显示文本的行号，可以用以下语句： set nu 最后，如果没有下列语句，就加上吧： 12345if &amp;term=="xterm" set t_Co=8 set t_Sb=^[[4%dm set t_Sf=^[[3%dmendif 7. 按键相关12345678910111213141516" 映射全选 ctrl+amap &lt;C-A&gt; ggVG"map! &lt;C-A&gt; &lt;Esc&gt;ggVGY"map &lt;F12&gt; gg=G---" 选中状态下 Ctrl+c 复制vmap &lt;C-c&gt; "+y---" 选中状态下 Ctrl+x 剪切vmap &lt;C-x&gt; "+d---"列出当前目录文件 map &lt;F3&gt; :tabnew .&lt;CR&gt; ---"打开树状文件目录 map &lt;C-F3&gt; \be 8. 编程相关8.1. 未分类1234567set showmatch " 高亮显示匹配的括号set matchtime=1 " 匹配括号高亮的时间（单位是十分之一秒）set smartindent " 为C程序提供自动缩进filetype on " 侦测文件类型filetype plugin on " 载入文件类型插件filetype indent on " 为特定文件类型载入相关缩进文件 8.2. 自动补全1234567891011121314151617set completeopt=longest,menu "打开文件类型检测, 加了这句才可以用智能补全:inoremap ( ()&lt;ESC&gt;i:inoremap ) &lt;c-r&gt;=ClosePair(')')&lt;CR&gt;:inoremap &#123; &#123;&lt;CR&gt;&#125;&lt;ESC&gt;O:inoremap &#125; &lt;c-r&gt;=ClosePair('&#125;')&lt;CR&gt;:inoremap [ []&lt;ESC&gt;i:inoremap ] &lt;c-r&gt;=ClosePair(']')&lt;CR&gt;:inoremap " ""&lt;ESC&gt;i:inoremap ' ''&lt;ESC&gt;ifunction! ClosePair(char) if getline('.')[col('.') - 1] == a:char return "\&lt;Right&gt;" else return a:char endifendfunctionfiletype plugin indent on 8.3. C、C++ 按F5编译运行，按F8调试1234567891011121314151617181920212223map &lt;F5&gt; :call CompileRunGcc()&lt;CR&gt;func! CompileRunGcc() exec "w" if &amp;filetype == 'c' exec "!g++ % -o %&lt;" exec "! ./%&lt;" elseif &amp;filetype == 'cpp' exec "!g++ % -o %&lt;" exec "! ./%&lt;" elseif &amp;filetype == 'java' exec "!javac %" exec "!java %&lt;" elseif &amp;filetype == 'sh' :!./% endifendfuncmap &lt;F8&gt; :call Rungdb()&lt;CR&gt;func! Rungdb() exec "w" exec "!g++ % -g -o %&lt;" exec "!gdb ./%&lt;"endfunc 8.4. 新建.c、.h、.sh、.java、.py等文件时，自动插入文件头12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879autocmd BufNewFile *.cpp,*.[ch],*.sh,*.py,*.java exec ":call SetTitle()" "定义函数SetTitle，自动插入文件头let $author_name = "Theshu"let $author_email = "theshu@qq.com"func SetTitle() "如果文件类型为.py文件 if &amp;filetype == 'python' call setline( 1,"\#!/usr/bin/python") call append(line("."),"\#########################################################################") call append(line(".")+1, "\# File Name : ".expand("%")) call append(line(".")+2, "\# Program : ") call append(line(".")+3, "\# \t &gt; ") call append(line(".")+4, "\# Author : ".$author_name) call append(line(".")+5, "\# Email : ".$author_email) call append(line(".")+6, "\# Created Time: ".strftime("%c")) call append(line(".")+7, "\# History : ") call append(line(".")+8, "\#########################################################################") call append(line(".")+9, "") endif"如果文件类型为.sh文件 if &amp;filetype == 'sh' call setline( 1,"\#!/bin/bash") call append(line("."),"\#########################################################################") call append(line(".")+1, "\# File Name : ".expand("%")) call append(line(".")+2, "\# Program : ") call append(line(".")+3, "\# \t &gt; ") call append(line(".")+4, "\# Author : ".$author_name) call append(line(".")+5, "\# Email : ".$author_email) call append(line(".")+6, "\# Created Time: ".strftime("%c")) call append(line(".")+7, "\# History : ") call append(line(".")+8, "\#########################################################################") call append(line(".")+9, "") endif"如果文件为C++的*.cpp if &amp;filetype == 'cpp' call setline(1, "/*************************************************************************") call append(line("."), " &gt; File Name: ".expand("%")) call append(line(".")+1, " &gt; Program: ") call append(line(".")+2, "\t\t &gt; ") call append(line(".")+3, " &gt; Author: ".$author_name) call append(line(".")+4, " &gt; Email: ".$author_email) call append(line(".")+5, " &gt; Created Time: ".strftime("%c")) call append(line(".")+6, " ************************************************************************/") call append(line(".")+7, "") call append(line(".")+8, "#include&lt;iostream&gt;") call append(line(".")+9, "using namespace std;") call append(line(".")+10, "") endif"如果文件为C的*.c或*.h if &amp;filetype == 'c' call setline(1, "/*************************************************************************") call append(line("."), " &gt; File Name: ".expand("%")) call append(line(".")+1, " &gt; Program: ") call append(line(".")+2, "\t\t &gt; ") call append(line(".")+3, " &gt; Author: ".$author_name) call append(line(".")+4, " &gt; Email: ".$author_email) call append(line(".")+5, " &gt; Created Time: ".strftime("%c")) call append(line(".")+6, " ************************************************************************/") call append(line(".")+7, "") call append(line(".")+8, "#include&lt;stdio.h&gt;") call append(line(".")+9, "") endif"如果文件为Java的*.java if &amp;filetype == 'java' call setline(1, "/*************************************************************************") call append(line("."), " &gt; File Name: ".expand("%")) call append(line(".")+1, " &gt; Program: ") call append(line(".")+2, "\t\t &gt; ") call append(line(".")+3, " &gt; Author: ".$author_name) call append(line(".")+4, " &gt; Email: ".$author_email) call append(line(".")+5, " &gt; Created Time: ".strftime("%c")) call append(line(".")+6, " ************************************************************************/") call append(line(".")+7, "") call append(line(".")+8, "") call append(line(".")+9, "") endif"新建文件后，自动定位到文件末尾 autocmd BufNewFile * normal Gendfunc OK]]></content>
      <categories>
        <category>Tool</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim的一些问题总结]]></title>
    <url>%2F2017%2F12%2F26%2FTool%2F004.%20Vim%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[GO 本章内容包含了很多在Vim使用中出现的问题以及相应的解决方法。 1. putty或xshell连接linux中Vim的小键盘问题 本内容容转载自 阿铭Linux 在putty上用Vim的时候，开NumLock时按小键盘上的数字并不能输入数字，而是出现一个字母然后换行（实际上时普通模式下对应上下左右的键。解决方法： 选项Terminal-&gt;Features里，找到Disabled application keypad mode，选上就可以了。 在xmanager 4 中也有小键盘的问题。解决方法为： 修改session属性-&gt;终端-&gt;VT模式-&gt;初始数字键盘模式 选择 设置为普通 2. Vim粘贴乱码问题 本节内容转载自 阿铭Linux 用Vim打开一个空白文档，然后把已经复制的代码粘贴进来，发现它有自动缩进功能，最终导致粘贴的文本一行比一行靠右，看起来乱成一团。 比较快的解决办法是： 在粘贴问当前，在命令模式下，输入：:set noai nosi 然后按“i”进入编辑模式，再粘贴已经复制的代码内容，这样就不会有自动缩进了。 有时候，这样的方法不好用，可以尝试这种： :set paste 3. Vim文件加密 本文内容转载自 阿铭Linux 利用Vim给文件加密： 优点：加密后，如果不知道密码，就看不到明文，包括root用户也看不了； 缺点：很明显让别人知道加密了，容易让别人把加密的文件破坏掉，包括内容破坏和删除； Vim里有一个命令是给文件加密的，举个例子： 首先在root主目录/root/下建立一个实验文件text.txt：[root@www ~]# vim/vi text.txt 进到编辑模式，输入完内容后按ESC，然后输入:X（注意是大写的X），回车； 这时系统提示让你输入密码，2次，如下所示： 12输入密码: *******请再输入一次: ******* 保存后退出，现在这个文件已经加密了； 用cat或more查看文件内容，显示为乱码；用 vim/vi 重新编辑这个文件，会提示输入密码，如果输入的密码不正确，同样会显示为乱码！注意：文件加密后，千万别忘了密码！ 解密用vi加密的文件（前提是你知道加密的密码）： 用 vim/vi 打开文件如text.txt，要输入正确的密码，然后在编辑时，将密码设置为空，方法是输入下面的命令：:set key=，然后直接回车，保存文件后，文件已经解密了。 或者这样也行：在正确打开文件后用 “:X” 指令，然后给一个空密码也可以。保存用“wq!”保存。 说明：以上两种方法实际上效果是一样的。 4. Vim中:wq和:x的区别 本节内容转载自 阿铭Linux :x和:wq的区别如下： :wq 强制性写入文件并退出（存盘并退出 write and quit）。即使文件没有被修改也强制写入，并更新文件的修改时间。 :x 写入文件并退出。仅当文件被修改时才写入，并更新文件修改时间，否则不会更新文件修改时间。 说明：这两者一般情况下没有什么不一样，但是在编程方面，对编辑源文件可能会产生重要影响。因为文件即使没有修改，“:wq”强制更新文件的修改时间，这样也会让make编译整个项目时以为文件被修改过了，然后就得重新编译链接生成可执行文件。这可能会产生让人误解得后果，当然也产生了不必要得系统资源花销。不过像是版本控制得软件一般首选还是比较文件内容，修改时间一般不加以理会。 OK]]></content>
      <categories>
        <category>Tool</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[入门Linux运维工程师需要学习的内容]]></title>
    <url>%2F2017%2F12%2F25%2F%E8%BD%AC%E8%BD%BD%2F003.%20%E5%85%A5%E9%97%A8Linux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9C%80%E8%A6%81%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[GO 0. 前言Linux系统的学习，可以选用RedHat或CentOS，特别是CentOS，在企业用得最多，当然还会有其它版本的，但学习者还是以这两个版本学习就行，因为这两个版本是兄弟，没有什么区别。有空还可以再研究一下SUSE，有些公司也喜欢用。 对于刚入门或准备入门Linux运维的来说，我们也整理总结了一下10个必须掌握的技术点和相关工具。 1. Linux系统基础这个是基础中的基础，连这个都不会就别干了。参考书籍，可以看《鸟哥Linux基础篇》，至少要掌握这书60%的内容，没有必要全部都掌握，但基本命令总得会把。 2. 网络服务服务有很多种，没个公司都会用到不同的，但基础的服务肯定要掌握： 如FTP、DNS、SAMBA、邮件，这几个大概学一下就行 LAMP和LNMP是必须要熟练，我所指的不是光光会搭建，而是要很熟悉里面的相当配置才行 因为公司最关键的绝对是Web服务器，所以Nginx和apache要熟悉，特别是Nginx一定要很熟悉才行 至少有些公司还会用Tomcat，这个也最好学一下。 其实网络服务方面不用太担心，一般公司的环境都已经搭建好，就算有新服务器或让你整改，公司会有相应的文档让你参照来弄，不会让你乱来的，但至少相关的配置一定要学熟，而且肯定是编译安装多，那些模块要熟悉一下它的作用，特别是PHP的那些模块。 前面1和2两点只是基础，也是必要的条件，不能说是工具，以下才是真正要掌握的工具。 3. Shell脚本和另一个脚本语言Shell是运维人员必须具备的，不懂这个连入职都不行，至少也要写出一些系统管理脚本，最简单也得写个监控CPU、内存比率的脚本吧，这是最最最基本的了，别以为会写哪些猜数字和计算什么数的吗，这些没什么用，只作学习意义，写系统脚本才是最有意义。 而另一个脚本语言是可选的，一般是3P：Python、Perl和PHP。PHP就不需要考虑了，除非你要做开发，我个人建议学Python会比较好，难实现自动化运维，Perl是文本处理很强大，反正这两个学一个就好了。 4. grep、sed 和 awk工具必须要掌握。这三个工具称为“正则三剑客”！在掌握这些工具的同时，还要掌握正则表达式，这个就痛苦了，正则是最难学的表达式，但结合到这三个工具中会很强大，在处理文本内容和过滤Web内容时十分有用，不过在学Shell的同时，一般会经常结合用到的，所以学第3点就会顺便学第4点。 5. 文本处理命令sort、tr、cat、paste、uniq、tee等，必学内容，也是结合第3点时一并学习的。 6. 数据库首选MySQL，别问我为什么不学SQLServer和Oracle，因为Linux用的最多的绝对是MySQL，增删该查必须学，特别要学熟练，其它方面可能不太需要，因为运维人员使用最多的还是查，那些优化和开发语句不会让你弄的。 7. 防火墙不学不行，防火墙也算是个难点，说难不难，说易不易，最重要的是要弄懂规则，如果学过CCNA的朋友可能会比较好学，因为iptables也有NAT表，原理是一样的，而FILTER表用的最多，反正不学就肯定不合格。 8. 监控工具十分十分重要，我个人建议，最好学习这3个：cacti、nagios和zibbix，企业用得最多的应该是nagios和zibbix，反正都学吧 ，但nagios会有点难，因为会设计到用脚本写自动监控，那个地方很难。 9. 集群和热备这个很重要，肯定要懂的，但到了公司就不会让你去弄，因为新手基本不让你碰，集群工具有很多，最好学LVS，这是必学，最好也学学nginx集群、反向代理，还有热备，这个就有更多工具能实现了。MySQL热备也要学，就是主从复制，这个别告诉我容易，其实是不容易的，要学懂整个流程一点也不容易，只照着做根本没有意思。 10. 数据备份不学不行，工具有很多，但至少要把RAID的原理弄懂，特别是企业最常用的1+0或0+1，自己做实验也要弄出来。备份工具有很多，如tar、dump、rsync等，最好多了解一下。 11. 结束语说到这10点已经够你受的了，应该可以入门了，因为有些技术会比较难学，例如apache和Nginx中还有些很重要的技术，如系统调优和服务优化，还有程序优化，这些在没接触工作之前很难学习到的，所以先把这10点学了吧，估计要学习3个月不止。 就脚本那部分已经让你很吃力了，我建议先学熟Shell，等工作后再学另一门脚本语言，这样会比较好。 以上就是踏入Linux运维工程师需要掌握的工具，其实还有很多工具要掌握的，但你在学习环境中是很难学到的。最好，我灾提醒一下，这里所指的工具相当于技能，而不是像Windows和Ubuntu那些图形化工具，那些工具没用的，还有，学Linux就别用图形界面，这样虚拟机就不用吃太多内存。 OK]]></content>
      <categories>
        <category>转载</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C和C++高手修炼之路]]></title>
    <url>%2F2017%2F12%2F25%2F%E8%BD%AC%E8%BD%BD%2F002.%20C%E5%92%8CC%2B%2B%E9%AB%98%E6%89%8B%E4%BF%AE%E7%82%BC%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[GO 一、C/C++语言买两本基础书，把例子都敲一遍，把基础的知识该掌握的都掌握好。 二、带界面的应用程序 微软路线：MFC 开源路线：界面库多的是 通用的并且简单的就是 wxWidget，官网：www.wxwidgets.org。 三、网络应用程序《Unix网络编程》，学号这本书，自己动手写一个服务器，再写一个客户端。请务必学会select这个简单的多路复用模型，这样才能慢慢的深入里面的poll、epoll、IOCP之类的模型。 四、文件操作fopen、fclose、fread、fwrite、fseek、ftell。 五、深刻理解内存与指针的关系内存的分配释放。可以看《高质量C/C++编程》中的例子。 六、apache源代码，仔细研究它apache的源代码是高手中的高手写的。尤其要学习其中的很多编程思想。 七、修炼C++泛型编程思想。 八、深研设计模式设计模式是程序设计的灵魂，是通用方法，当你面对一个大型项目的时候，如歌设计一个有弹性的系统，是所有系统分析员应该掌握的技能。在设计模式的研究上，要结合实际的项目进行。 OK]]></content>
      <categories>
        <category>转载</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim初学笔记]]></title>
    <url>%2F2017%2F12%2F25%2FTool%2F003.%20Vim%E5%88%9D%E5%AD%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[GO 0. Vim初相识0.1 Vim简介Vim是从Vi发展出来，第一个版本由布拉姆米勒在1991年发布，它基于VIM许可证，兼容GPL。官网www.vim.org 0.2 Vim的安装和使用 安装：yum install -y vim-enhanced 使用：vim filename 1. Vim的模式（这节内容摘抄自Vim-维基百科） Vim有6种基本模式和5种派生模式： 1.1 基本模式 普通模式 在普通模式中，用的编辑器命令，比如移动光标，删除文本等等。这也是Vim启动后的默认模式。 在普通模式中，有很多方法可以进入插入模式。比较普通的方式是按”a”（append／追加）键或者”i”（insert／插入）键。 插入模式 在这个模式中，大多数按键都会向文本缓冲中插入文本。大多数新用户希望文本编辑器编辑过程中一直保持这个模式。 在插入模式中，可以按ESC键回到普通模式。 可视模式 这个模式与普通模式比较相似。但是移动命令会扩大高亮的文本区域。高亮区域可以是字符、行或者是一块文本。当执行一个非移动命令时，命令会被执行到这块高亮的区域上。Vim的”文本对象”也能和移动命令一样用在这个模式中。 选择模式 这个模式和无模式编辑器的行为比较相似（Windows标准文本控件的方式）。这个模式中，可以用鼠标或者光标键高亮选择文本，不过输入任何字符的话，Vim会用这个字符替换选择的高亮文本块，并且自动进入插入模式。 命令行模式 在命令行模式中可以输入会被解释成并执行的文本。例如执行命令（”:”键），搜索（”/“和”?”键）或者过滤命令（”!”键）。在命令执行之后，Vim返回到命令行模式之前的模式，通常是普通模式。 Ex模式 这和命令行模式比较相似，在使用”:visual”命令离开Ex模式前，可以一次执行多条命令。 1.2 派生模式 操作符等待模式 这个派生模式指普通模式中，执行一个操作命令后Vim等待一个”动作”来完成这个命令。Vim也支持在操作符等待模式中使用”文本对象”作为动作，包括”aw”一个单词（a word）、”as”一个句子（a sentence）、”ap”一个段落（a paragraph）等等。 比如，在普通模式下”d2as”删除当前和下一个句子。在可视模式下”apU”把当前段落所有字母大写。 插入普通模式 这个模式是在插入模式下按下ctrl-o键的时候进入。这个时候暂时进入普通模式，执行完一个命令之后，Vim返回插入模式 插入可视模式 这个模式是在插入模式下按下ctrl-o键并且开始一个可视选择的时候开始。在可视区域选择取消的时候，Vim返回插入模式。 插入选择模式 通常这个模式由插入模式下鼠标拖拽或者shift方向键来进入。当选择区域取消的时候，Vim返回插入模式。 替换模式 这是一个特殊的插入模式，在这个模式中可以做和插入模式一样的操作，但是每个输入的字符都会覆盖文本缓冲中已经存在的字符。在普通模式下按”R”键进入。 1.3 其它 Evim（Easy Vim） Evim（Easy Vim）是一个特殊的GUI模式用来尽量的表现的和”无模式”编辑器一样。编辑器自动进入并且停留在插入模式，用户只能通过菜单、鼠标和键盘控制键来对文本进行操作。可以在命令行下输入”evim”或者”vim -y”进入。在Windows下，通常也可以点击桌面上Evim（Easy Vim）的图标。 1.4 说明一般情况下，我们通常只使用三种模式（其它的模式可能会在我们使用过程中不经意就会用上，所以初学时不要在模式上花费太大的精力，只需要搞懂这常用的三种就足够了）： 普通模式 插入模式 命令行模式 以下的内容也是针对这三种常用模式的学习。 2. Vim的使用2.1 进入Vim vim 进入Vim软件环境 vim filename 用Vim打开或新建一个文件 2.2 三种常用模式之间的切换2.2.1 进入普通模式 一般用Vim打开文件时的默认模式就是普通模式。 如果是在别的模式下，按Esc键 就会切换到普通模式。 同上，按 Ctrl+C 或者 Ctrl+[ 效果也同 按Esc键。 2.2.2 进入插入模式一般是从默认的普通模式进入到插入模式，常用的方式如下表所示： 按键 说明 i 在当前光标的前面插入 I 在当前光标所在行的行首插入 a 在当前光标的后面插入 A 在当前光标所在行的行尾插入 o 在当前光标所在行的下面新插入一行 O 在当前光标所在行的上面新插入一行 cw 替换从光标所在位置后到一个单词结尾的字符 2.2.3 进入命令行模式一般是从默认的普通模式进入到命令行模式，方式如下表所示： 按键 说明 ： 冒号后面加一些命令 / 进行查找替换时前面要用它 ？ 进行查找时前面要用它 2.2.4 关于模式之间相互切换的说明 普通模式和插入模之间可以相互切换。 普通模式和命令行模式之间可以相互切换。 插入模式和命令行模式之间不可以直接切换，只能先从一种模式中切换到普通模式，才能再切换到另一个模式。 2.3 光标移动光标移动 按键 说明 h/左箭头 左 l/右箭头 右（小写L） j/下箭头 下 k/上箭头 上 行间跳转 命令 说明 nG（n Shift+g） 光标移动到第n行 gg 光标移动到第一行 G（Shift+g） 到最后一行 小技巧：你在完成依次跳转后，可以使用Ctrl+o快速回到上一次(跳转前)光标所在位置,这个技巧很实用，比如当你在写代码时，忽然想起有个bug，需要修改，这时候你跳过去改好了，只需要按下Ctrl+o就可以回到你之前的位置。 行内跳转 命令 说明 w 到下一个单词的开头 e 到下一个单词的结尾 b 到前一个单词的开头 ge 到前一个单词的结尾 0或^ 到行头 $ 到行尾 f&lt;字母&gt; 向后搜索&lt;字母&gt;并跳转到第一个匹配的位置（非常实用） F&lt;字母&gt; 向前搜索&lt;字母&gt;并跳转到第一个匹配的位置 t&lt;字母&gt; 向后搜索&lt;字母&gt;并跳转到第一个匹配位置之前的一个字母（不常用） T&lt;字母&gt; 向前搜索&lt;字母&gt;并跳转到第一个匹配位置之后的一个字母（不常用） 2.4 操作文本2.4.1 删除文本普通模式下删除Vim文本信息 操作 说明 x（小写） 删除光标所在的字符 X（大写） 删除光标所在前一个字符 Delete 同x dd 删除（实际上是剪切，可用p来粘贴）光标所在行 dw 删除一个单词（不适合中文） d$或D 删除至行尾 d^ 删除至行首 dG 删除至文档结尾处 d1G 删除至文档首部 除此之外，还可以在命令之前加上数字，表示多次删除1行，即一次删除多行。 2.4.2 复制粘贴和剪切在普通模式下进行复制粘贴和剪切的操作 操作 说明 yy 复制光标所在行的整行 3yy 复制3行 y^ 复制至行首的第一个字符，不包含光标所在处字符 y0 同上 yw 复制一个单词 y2w 复制两个单词 yG 复制至文本末 y1G 复制至文本开头 p（小写） 粘贴至光标后（下） P（大写） 粘贴至光标前（上） dd 剪切光标所在行的整行 ddp 快速交换光标所在行与它下面的行 剪切的操作 同复制的操作一致，以此类推 2.4.3 替换和撤销（Undo）在普通模式下进行 操作 说明 r+&lt;待替换字母&gt; 将光标所在字母替换为指定字母 R 连续替换，直到按下Esc cc 替换整行，即删除光标所在行，并进入插入模式 cw 替换一个单词，即删除一个单词，并进入插入模式 C（大写） 替换光标以后至行末 ~ 反转光标所在字母大小写 u{n} 撤销一次或n次操作 U（大写） 撤销当前行的所有修改 Ctrl+r redo，即撤销undo的操作 2.4.4 查找在普通模式下进行 操作 说明 /&lt;字符串&gt; 向下进行查找 ?&lt;字符串&gt; 向上进行查找 n（小写） 继续相同侧的查找 N（大写） 继续相反侧的查找 \* 向下查找光标所在处的单词 \# 向上查找光标所在处的单词 g\* 同\*，但部分符合该单词即可 g\# 同\#，但部分符合该单词即可 补充说明：1234加入old中包含“/”这个字符就需要反斜杠|转换或将/换成#或@1. :%s/\/etc\/old/new/g2. :%s#/etc/old#new#g3. :%s@/etc/old@new@g 2.4.5 快速缩进使用快速缩进，用于格式化代码超爽，在普通模式下进行 操作 说明 &gt;&gt; 将整行向右缩进 &lt;&lt; 将整行向左回退 :set shiftwidth=n 设置缩进和回退的字符数（可以简写成sw) :ce 使本行内容居中 :ri 使本行内容靠右 :le 使本行内容靠左 2.5 Vim重复命令和设置2.5.1 Vim重复命令 重复执行上次命令：在普通模式下，.（小数点）表示重复上一次的命令操作。 执行指定次数相同的命令：在普通模式输入数字N，N表示重复后面操作的次数。几个例子如下: 输入 10x ,删除10个连续字符 输入 3dd ,将会删除3行文本 在普通模式下，还可以使用dw或者daw（delete a word）删除一个单词，所以可以联想到dnw（n替换为相应数字）表示删除n个单词。 2.5.2 Vim常用设置 :set nu 显示行号 :set shiftwidth=n 设置缩进和回退的字符数（可以简写成sw–&gt; :set sw=n ） :set nohl 取消查找关键字后的高亮 2.6 退出Vim命令行模式下退出Vim 命令 说明 :q! 强制退出，不保存 :q 退出 :wq! 强制保存并退出 :w &lt;文件路径&gt; 另存为 :saveas &lt;文件路径&gt; 另存为 :x 保存并退出 :wq 保存并退出 普通模式下输入 ZZ（Shift+zz） 即可退出（若文件改动，则保存，否则不保存） 3. Vim初学的补充3.1. 正常模式下的命令格式在正常模式下一个命令的格式是∶ [number] command object 或者 command [number] object 其意是∶ number - 代表的是命令执行的次数 command - 代表要做的事情，比如 d 代表删除 object - 代表要操作的对象，比如 w 代表单字/单词，$ 代表到行末等等。 $ (to the end of line), etc. 3.2. 括号匹配如果光标当前位置是括号(、)、[、]、{、}，按 % 可以将光标移动到配对的括号上。 3.3. 字符替换 在一行内替换头一个字符串 old 为新的字符串 new，请输入 :s/old/new 在一行内替换所有的字符串 old 为新的字符串 new，请输入 :s/old/new/g 在两行内替换所有的字符串 old 为新的字符串 new，请输入 :#,#s/old/new/g 在文件内替换所有的字符串 old 为新的字符串 new，请输入 :%s/old/new/g 进行全文替换时询问用户确认每个替换需添加 c 选项，请输入 :%s/old/new/gc 3.4. Vim的在线帮助命令 Vim 拥有一个细致全面的在线帮助系统。要启动该帮助系统，请选择如下三种方法之一∶ 按下 &lt;HELP&gt; 键 (如果键盘上有的话) 按下 &lt;F1&gt; 键 (如果键盘上有的话) 输入 :help &lt;回车&gt; 输入 :q &lt;回车&gt; 可以关闭帮助窗口。 提供一个正确的参数给”:help”命令，您可以找到关于该主题的帮助。请试验以下参数(可别忘了按回车键哦)∶ :help w &lt;回车&gt; :help insert-index &lt;回车&gt; :help user-manual &lt;回车&gt; vim手册，使用的命令是∶ :help user-manual 4. Vim高级功能4.1. 多文件编辑4.1.1 使用Vim编辑多个文件编辑多个文件有两种形式，一种是在进入Vim前使用的参数就是多个文件，另一种就是进入Vim后再编辑其他的文件。 同时创建两个新文件并编辑： vim 1.txt 2.txt 默认进入1.txt文件的编辑界面 命令行模式下输入:n 编辑2.txt文件，可以加!即:n!强制切换，之前一个文件的输入内容没有保存，仅仅切换到另一个文件 命令行模式下输入:N 编辑1.txt文件，可以加!即:N!强制切换，之前文件内的输入没有保存，仅仅是切换到另一个文件。 4.1.2 进入Vim后打开新文件命令行模式下的操作： 操作 说明 :e 3.txt 打开新文件3.txt :e# 回到前一个文件 :ls 可以列出以前编辑过的文档 :b 2.txt（或者编号） 可以直接进入文件2.txt编辑 :bd 2.txt（或者编号） 可以删除以前编辑过的列表中的文件项目 :e! 4.txt 新打开文件4.txt，放弃正在编辑的文件 :f 显示正在编辑的文件名 :f new.txt 改变正在编辑的文件名字为new.txt 4.1.3 恢复文件如果因为断电等原因造成文档没有保存，可以采用恢复方式： vim -r 进入文档后，输入:ewcover 1.txt来恢复。 4.2. 可视模式 在普通模式下输入v（小写），进入字符选择模式，就可以移动光标，光标走过的地方就会选取。再次按下v会后就会取消选取。 在普通模式下输入Shift+v（小写），进入行选择模式，按下V之后就会把整行选取，您可以上下移动光标选更多的行，同样，再按一次Shift+v就可以取消选取。 在普通模式下输入Ctrl+v（小写），这是区域选择模式，可以进行矩形区域选择，再按一次Ctrl+v取消选取。 在普通模式下输入d删除选取区域内容 在普通模式下输入y复制选取区域内容 4.3. 视窗操作vim可以在一个界面里打开多个窗口进行编辑，这些编辑窗口称为vim的视窗。打开方法有很多种，例如可以使用在命令行模式下输入:new 打开一个新的vim视窗，并进入视窗编辑一个新文件（普通模式下输入Ctrl+w也可以,但是Ctrl+w在chrome下会与chrome关闭标签页的快捷键冲突，所以使用该快捷键你可以在IE或其它浏览器进行练习），除了:new命令，下述列举的多种方法也可以在命令模式或普通模式下打开新的视窗： 命令行模式下输入:sp 1.txt 打开新的横向视窗来编辑1.txt 命令行模式下输入:vsp 2.txt 打开新的纵向视窗来编辑1.txt 普通模式下Ctrl-w s 将当前窗口分割成两个水平的窗口 普通模式下Ctrl-w v 将当前窗口分割成两个垂直的窗口 普通模式下Ctrl-w q 即 :q 结束分割出来的视窗。如果在新视窗中有输入需要使用强制符！即:q! 普通模式下Ctrl-w o 打开一个视窗并且隐藏之前的所有视窗 普通模式下Ctrl-w j 移至下面视窗 普通模式下Ctrl-w k 移至上面视窗 普通模式下Ctrl-w h 移至左边视窗 普通模式下Ctrl-w l 移至右边视窗 普通模式下Ctrl-w J 将当前视窗移至下面 普通模式下Ctrl-w K 将当前视窗移至上面 普通模式下Ctrl-w H 将当前视窗移至左边 普通模式下Ctrl-w L 将当前视窗移至右边 普通模式下Ctrl-w - 减小视窗的高度 普通模式下Ctrl-w + 增加视窗的高度 4.4. 文档加密vim -x file1 输入您的密码确认密码这样在下一次打开时，vim就会要求你输入密码 4.5. 在Vim执行外部命令在命令行模式中输入!可以执行外部的shell命令: :!ls 用于显示当前目录的内容 :!rm FILENAME 用于删除名为 FILENAME 的文件 :w FILENAME 可将当前 VIM 中正在编辑的文件另存为 FILENAME 文件 4.6. Vim的帮助系统 普通模式下按&lt;F1&gt;打开vim自己预设的帮助文档 命令行模式下输入:h shiftwidth 打开名为shiftwidth的帮助文件 命令行模式下输入:ver 显示版本及参数 4.7. 功能设定4.7.1 Vim的功能设定可以在编辑文件的时候进行功能设定，如命令行模式下输入:set nu（显示行数），设定值退出vim后不会保存。要永久保存配置需要修改vim配置文件。vim的配置文件~/.vimrc，可以打开文件进行修改，不过务必小心不要影响vim正常使用 4.7.2 获取目前的设定 命令行模式下输入:set或者:se显示所有修改过的配置 命令行模式下输入:set all 显示所有的设定值 命令行模式下输入:set option? 显示option的设定值-命令行模式下输入:set nooption 取消当期设定值 4.7.3 set功能的说明 命令行模式下输入:set autoindent(ai) 设置自动缩进 命令行模式下输入:set autowrite(aw) 设置自动存档，默认未打开 命令行模式下输入:set background=dark或light，设置背景风格 命令行模式下输入:set backup(bk) 设置自动备份，默认未打开 命令行模式下输入:set cindent(cin) 设置C语言风格缩进 5. Vim使用技巧总结5.1. Vim一些常用使用技巧总结 操作 说明 Ctrl-C 回到普通模式 u / Ctrl+r 撤销/反撤销 9G / :9 定位到第9行 :9y 拷贝第9行 Ctrl-o 回到此前光标位置 ZZ / ZQ 保存并退出/无条件退出 = 格式化选定文本 ggvG 全选文件内容 gg=G 格式化文件 Shift-v 选取行 vip 选取光标所在段落 yit / dit / cit 对标签内的文本进行操作 mx 添加书签 `X 跳转到书签X :marks 查看所有书签X delm X 删除书签X :ls 查看缓冲区 :bN 打开缓冲区N :bn / bp / 缓冲区切换 :shell / :sh /!cmd 执行shell命令 Ctrl-z / fg 利用了Linux的作业机制，将Vim进程放到后台/前台执行，便于使用shell环境 vim -o *.py 打开当前目录下全部.py文件 :qa 退出全部窗口 vnew 垂直分屏 Ctrl-w r 切换缓冲区 :r filename 将文件读入到当前光标位置 Windo diffthis/diffof 对比当前打开的两个缓冲区 :e! 重新打开缓冲区 :s/foo/bar/gc 查找foo并将其替换成bar :1?xxx / G?xxx 从文件末尾开始查找 Shift-k 查找光标所在命令或函数的man帮助 J 合并行 gi / gk 对于换行的段落的行移动 Ctrl-g 用于显示当前光标所在位置和文件状态信息。 :!command 用于执行一个外部命令 command。 :w FILENAME 可将当前 VIM 中正在编辑的文件保存到名为 FILENAME 的文件中。 :#,#w FILENAME 可将当前编辑文件第 # 行至第 # 行的内容保存到文件FILENAME 中。 :r FILENAME 可提取磁盘文件 FILENAME 并将其插入到当前文件的光标位置后面。 5.2. Vim键盘图图一 图二 图三 OK]]></content>
      <categories>
        <category>Tool</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用便携软件]]></title>
    <url>%2F2017%2F12%2F19%2FTool%2F002.%20%E5%B8%B8%E7%94%A8%E4%BE%BF%E6%90%BA%E8%BD%AF%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[GO 便携软件平台 PortableApps.com PortableAppC Sourceforge 便携软件平台软件 PortableApps.com_Platform 常用便携软件清单 PDF阅读 | Sumatro PDF 拼音输入 | Sogou Pinyin 办公套件 | LibreOffice 编辑神器 | Gvim 截屏工具 | PicPick 截屏神器 | Ashampoo Snap 魔影工厂 | Modiac Factory 视频播放 | PotPlayer 视频播放 | SMPlayer 音乐播放 | AirPlay 快速搜索 | Everything 垃圾清理 | Wise Disk Cleaner 密码管理 | KeePass Classic 软件卸载 | GeekUninstaller 数据恢复 | Wise Disk Recovery 文件比较 | Checksum Control 系统安装 | UNetbootin 压缩解压 | 7-Zip 占用解锁 | Obit Unlocker 资源管理 | FreeCommander XE 资源平衡 | Process lasso 网页浏览 | Google Chrome 网页浏览 | Mozilla FireFox 迅雷迷你 | ThunderMini 迅雷下载 | Thunder 远程文件 | WinSCP 远程终端 | KiTTY 远程终端 | PuTTY OK]]></content>
      <categories>
        <category>Tool</category>
      </categories>
      <tags>
        <tag>软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FTP服务配置（Aming）]]></title>
    <url>%2F2017%2F09%2F21%2F%E6%8A%80%E6%9C%AF%2F002.%20FTP%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE%EF%BC%88Aming%EF%BC%89%2F</url>
    <content type="text"><![CDATA[GO FTP介绍FTP是File Transfer Protocol（文件传输协议，简称”文传协议”）的英文简写形式，用于在互联网上控制文件的双向传输。它同时也是一个应用程序，用户可以通过它把自己的PC机与世界各地所有运行FTP协议的服务器相连，以访问服务器上的大量程序和信息。FTP的主要作用就是让用户连接一个远程计算机（这些计算机上运行着FTP服务器程序），并查看远程计算机中的文件，然后把文件从远程计算机复制到本地计算机，或把本地计算机的文件传送到远程计算机。FTP方便传输数据，所以个人用户很多，但在企业里用得越来越少，因为FTP是有一定安全隐患的。在本章会介绍两种FTP软件。 使用vsftpd搭建FTP服务CentOS或RHEL上有自带的FTP软件vsftpd，默认并没有安装，需要用yum安装，安装后不用配置，启动后便可以使用。但本节介绍的是它的高级用法。 1. 安装 vsftpdyum install -y vsftpd db4-utils 这里安装了两个软件包，同时也会把依赖的包安装上。其中db4-utils包用来生成密码库文件。 2. 建立账号vsftpd默认可以支持使用系统账号体系登陆，但是那样不太安全，所以建议使用虚拟账号体系登陆。 首先建立与虚拟账号相关联的系统账号：useradd virftp -s /sbin/nologin 接着建立与虚拟账户相关的文件：vim /etc/vsftpd/vsftpd_login，其内容如下： 1234test1123456test2abcdfe 需要说明的是，该文件的奇数行为用户名，偶数行为上一行的用户密码。 更改文件的权限，提升安全级别：chmod 600 /etc/vsftpd/vsftpd_login vsftpd使用的密码不是明文的，需要生成对应的库文件：db_load -T -t hash -f /etc/vsftpd/vsftpd_login /etc/vsftpd/vsftpd_login.db 最后建立与虚拟账号相关的目录以及配置文件： mkdir /etc/vsftpd/vsftpd_user_conf cd /etc/vsftpd/vsftpd_user_conf 3. 创建和用户对应的配置文件用户的配置文件是单独存在的，每一个用户都有一个自己的配置文件，文件名和用户名一致。如下所示：123456789101112# vim test1 //内容如下local_root=/home/virftp/test1anonymous_enable=NOwrite_enable=YESlocal_umask=022anon_upload_enable=NOanon_mkdir_write_enable=NOidle_session_timeout=600data_connection_timeout=120max_clients=10max_per_ip=5local_max_rate=50000 说明： local_root为test1账号的家目录 anonymous_enable用来限制是否允许匿名账号登陆（若为NO，表示不允许匿名账号登陆） write_enable=YES表示可写 local_umask指定umask值 anon_upload_enable表示是否允许匿名账号上传文件 anon_mkdir_write_enable表示是否允许匿名账号可写 以上为关键配置参数，其他参数暂时不用关心 创建test2账号的步骤和test1一样，如下所示：123456# mkdir /home/virftp/test1# touch /home/virftp/test1/aminglinux.txt# chown -R virftp:virftp /home/virftp# vim /etc/pam.d/vsftpd //在最开头添加两行auth sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/vsftpd_loginaccount sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/vsftpd_login 说明： CentOS7为64位系统，所以库文件路径为/lib64/security/pam_userdb.so（32位系统的库文件路径为/lib/security/pam_userdb.so） 4. 修改全局配置文件/etc/vsftpd/vsftpd.conf修改用户的配置文件后还不可用，还需要修改vsftpd的一些全局配置文件。 首先编辑vsftpd.conf文件，如下所示：12345678910111213# vim /etc/vsftpd/vsftpd.conf //修改如下内容- 将anonymous_enable=YES 改为 anonymous_enable=NO- 将#anon_upload_enable=YES 改为 anon_upload_enable=NO- 将#anon_mkdir_write_enable=YES 改为 anon_mkdir_write_enable=NO// 再增加如下内容chroot_local_user=YESguest_enable=YESguest_username=virftpvirtual_use_local_privs=YESuser_config_dir=/etc/vsftpd/vsftpd_user_confallow_writeable_chroot=YES 然后启动vsftpd服务，执行如下命令：systemctl start vsftpd 测试安装是否成功以上所示的整个配置过程有点繁琐，但是并不复杂。接下来我们做一下测试： ps aux | grep vsftp 查看进程是否存在 yum install -y lftp 安装lftp客户端软件 lftp test1@127.0.0.1 输入口令后即可登陆到vsftpd，然后利用ls命令查看test1家目录下面的aminglinux.txt。文件的所属主和所属组以virftp用户的UID和GID的方式显示。 如果在这一步遇到问题，请检查/var/log/secure日志，通常会记录一些错误信息。 使用pure-ftpd搭建FTP服务pure-ftpd为另一款比较小巧实用的FTP软件，平时用的比较多。 1. 安装 pure-ftpd默认的CentOS的yum源并不包含pure-ftpd，需要安装epel扩展源，具体过程如下：12# yum install -y epel-release# yum install -y pure-ftpd 2. 配置 pure-ftpd在启动pure-ftpd之前，需要先修改配置文件/etc/pure-ftpd/pure-ftpd.conf。该配置文件里面的内容很多，其中需要修改的是：把PureDB /etc/pure-ftpd/pureftpd.pdb前面的#删除，然后启动pure-ftpd，启动之前需要关闭vsftpd，因为有端口冲突，过程如下所示：123# systemctl stop vsftpd# systemctl start pure-ftpd# ps aux | grep pure-ftp 启动成功的话，ps aux可以看到相关的进程。如果乜有正常启动，需要通过/var/log/messages日志查看原因。 3. 建立账号为了安全，pure-ftp使用的账号并非Linux的系统账号，而是虚拟账号。 首先，创建一个虚拟账号，如下所示：123456# mkdir /data/ftp/# useradd -u 1010 pure-ftp# chown -R pure-ftp:pure-ftp /data/ftp/# pure-pw useradd ftp_user1 -u pure-ftp -d /data/ftp/Password:Enter it again: 说明： -u选项将虚拟用户ftp_user1与系统用户pure-ftp关联再一起，也就是说，使用ftp-user1账号登陆FTP后，会以pure-ftp的身份来读取和下载文件 -d选项后面的目录为ftp_user1账户的家目录，这样可以使ftp_user1只能访问其家目录/data/ftp/ 然后创建用户信息数据库文件，这一步很关键。执行如下命令：pure-pw mkdb 其中，pure-pw还可以列出当前FTP账号以及删除某个账号。例如，我们再创建一个账号，如下所示：12# pure-pw useradd ftp_user2 -u pure-ftp -d /tmp# pure-pw mkdb 列出当前账号，执行如下命令：123# pure-pw listftp_user1 /data/ftp/./ftp_user2 /tmp/./ 如果想删除账号，执行如下命令：1pure-pw userdel ftp_user2 4. 测试pure-ftpd测试过程如下：12345# lftp ftp_user1@172.0.0.1口令：# ls# put /etc/fatab# ls 说明： 登陆后，使用ls可以查看当前目录都有什么文件 使用put命令可以把系统的文件上传到FTP服务器上 你还可以再Windows机器里安装一个FTP客户端软件（推荐开源的FileZilla），然后远程链接测试。 OK]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell脚本常用基础语法]]></title>
    <url>%2F2017%2F09%2F21%2FShell%2F002.%20Shell%E8%84%9A%E6%9C%AC%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[GO 什么是shell脚本shell脚本在Linux系统管理员的运维工作中非常重要。shell脚本并不能称之为正式的编程语言，因为它是在Linux的shell中运行的，而且它是有一些逻辑语法组合起来的命令的集合，所以称之为shell脚本很贴切。 在运维工作中，自定义的shell脚本建议都放到/usr/local/bin目录下，这样做的好处是，一来可以很方便的管理文档，二来在以后运维工作中，接管你的管理员就会知道自定义脚本都放在了哪里，方便维护。 shell脚本的创建和运行创建一个shell脚本vim hello.sh用编辑器vim即可创建一个空的shell脚本。在其中添加脚本内容：123456#!/bin/bash# HelloWorld!# 创建时间：2017-09-21dateecho "HelloWorld!" 说明： shell脚本通常都是以.sh为后缀名。 shell脚本第一行要以#!/bin/bash或#!/bin/sh开头，它俩是相同的，是链接文件。这行内容表示的是该文件使用的是bash语法。 #为注释符，一般在后面填写这样的注释内容：本脚本的功能，创建时间和更新时间，以及作者等相关信息。 运行一个shell脚本运行一个脚本有两种方式： 以bash来执行这个脚本 # sh hello.sh # bash hello.sh # sh -x hello.sh 用-x选项用来查看shell脚本的执行过程，方便debug。 以可执行文件的方式来执行这个脚本 # chmod +x hello.sh 使用这种执行方式要使该脚本文件具有可执行的权限。 ./hello.sh或该文件的绝对路径名称。 date命令date命令常用语shell脚本中。 该命令常用的几个选项如下： date +%Y：表示以四位数字格式打印年份 date +%y：表示以两位数字格式打印年份 date +%m：表示月份 date +%d：表示日期 date +%H：表示小时 date +%M：表示分钟 date +%S：表示秒 date +%w：表示星期几。结果显示0则表示周日 date +%W：表示目前所在星期是一年中的第多少个星期 该命令在shell中最常用的几个选项如下： date +%Y-%m-%d：输出四位的年月日，格式 2017-09-21 date +%y-%m-%d：输出两位的年月日，格式 17-09-21 date +%F：相当于date +%Y-%m-%d date +%H:%M:%S：输出时间，格式 16:22:30 date +%T：等同于上面 date +%s：时间戳 date -d @时间戳：根据时间戳反推出时间 date -d &quot;+1 day&quot; +%d：一天后 date -d &quot;-1 day&quot; +%d：一天前 date -d &quot;-1 hour&quot; +%H：一个小时前 date -d &quot;-1 month&quot; +%m：一个月前 date -d &quot;-1 min&quot; +%M：一分钟前 shell脚本中的变量自定义变量变量的定义和使用定义变量的格式为：变量名=变量的值使用变量时需要在变量前面加上这个符号$ 变量的常用用法反引号的使用使用反引号，可以将一条命令的执行结果赋值给一个变量，如：12d1=`date +F%T`echo "$d1" 数学运算shell脚本中变量的数学运算有两种方式，如下： c=$[$a+$b] c=$(($a+$b)) 但是，shell脚本默认是不支持小数的，如果我们需要用到小数，比如保留两位小数点时，我们可以这样来实现：# echo &quot;scale=2;10/3&quot; | bc 和用户交互read命令用于和用户交互，它把用户输入的字符串作为变量值。常用格式为:read &quot;提示的内容：&quot; 变量名 示例脚本如下：123456789#!/bin/bash## Using 'read' in shell script.## Theshu 2017-09-21read -p "Please input a number: " xread -p "Please input another number: " ysum=$[$x+$y]echo "The sum of two numbers is: $sum" 预设变量在shell脚本执行时，后面可以跟一个或多个参数。在shell中有一些预设的变量可以表示这些参数（这些预设的变量从理论上看是没有限制的）。 常用的几个预设变量如下： $#：表示总共有几个参数 $0：表示命令或脚本名本身 $1：表示后面跟的第一个参数 $2：表示后面跟的第二个参数 $n：表示后面跟的第n个参数 示例脚本如下：123456#!/bin/bash# use $1 and $2 # Theshu 2017-09-21sum=$[$1+$2]echo "sum=$sum" shell脚本中的逻辑判断if 语句if语句常用于判断某些条件满足时执行哪些语句，不满足时又执行哪些语句。其格式有以下三种。 不带else的if语句格式如下：1234if 判断语句then commandfi 带有else的if语句格式如下：123456if 判断语句then command1else command2fi 带有elif的if语句格式如下：123456789101112if 判断语句1then command1elif 判断语句2then command2......elif 判断语句nthen command(n)else command(n+1) case 语句当有多个判断条件时，除了用带有elif的if语句外，还可以用case语句来实现。 格式如下：123456789101112131415case 变量 in value1) command1 ;; value2) command2 ;; ...... valuen) command(n) ;; *) command(n+1) ;;esac 条件表达式（即判断语句）一个特殊的条件表达式： :表示条件为真 以((条件表达式))来表示判断语句这种格式在判断数值大小时最为方便，比如：(($a &gt; 60)) 在这种格式下，可以用&lt;、&lt;=、&gt;、&gt;=、==、!=这些数学符号。 以[[ 条件表达式 ]]条件表达式来表示判断语句这种格式在判断小数值的大小时最为方便，比如：[[ $a &gt; 1.5 ]] 以[ 条件表达式 ]来表示判断语句这种格式最为常用，但是这种格式下，不能用那些数学符号来表示数值关系了（除==外）。 在这种格式下，常用的判断符号有： 判断数值大小 -lt：小于 -gt：大于 -le：小于等于 -ge：大于等于 -eq：等于（也可以使用==） -ne：不等于 判断属性的符号 -e：判断文件或目录是否存在 -d：判断是不是目录以及是否存在 -f：判断是不是普通文件以及是否存在 -r：判断是否有读权限 -w：判断是否有写权限 -x：判断是否有执行权限 -z：判断某个变量是否为空 使用if判断时具体的格式如下（例子）： 1234if [ -e filename ]then commandfi 说明： shell脚本中的语句可以以分号结尾，也可以不用分号，不用分号时以换行符结尾 [ 条件表达式 ]这种格式中，中括号和条件表达式之间有空格 条件表达式中，变量名用双引号括起来更加准确，变量名和判断符号之前也要有空格 逻辑运算符逻辑运算符用于判断条件与条件之间的关系。有下面三个： &amp;&amp;：表示并且的意思 ||：表示或者的意思 !：表示非的意思 常用格式：12345[ 条件表达式1 ] &amp;&amp; [ 条件表达式2 ][ 条件表达式1 ] || [ 条件表达式2 ]((条件表达式1)) &amp;&amp; ((条件表达式2))((条件表达式1)) || ((条件表达式2))[ ! 条件表达式 ] 表示不满足该条件时 shell脚本中的循环for循环for循环结构是在日常工作中使用最频繁的循环结构。其格式为：1234for 变量名 in 循环的条件do commanddone 说明： 循环的条件，可以是一组字符或者数字（用一个或多个空格隔开），也可以是一条命令的执行结果（用反引号把命令括起来，如`seq 1 5`表示从1到5的一个序列）。 示例脚本如下（打印出1到5的数字）：1234567#!/bin/bash## use forfor i in `seq 1 5`do echo $idone while循环while循环常用于编写死循环的脚本，用于监控某项服务。其格式为：1234while 条件do commanddone 示例脚本如下：12345678#!/bin/basha=5while [ $a -ge 1 ]do echo $a a=$[$a-1]done 另外可以用一个冒号代替循环条件，表示真，这样可以做到死循环。示例脚本如下：123456#!/bin/bashwhile : do sleep 3done select循环select也是循环的一种，它比较适合在用户选择的情况下。接下来我们用一个例子来说明它的用法。 一个例子比如，我们有这样一个需求，运行脚本后，让用户去选择数字，选择1运行w命令，选择2运行top命令，选择3运行free命令，选择4退出。脚本这样实现： 123456789101112131415161718192021222324#!/bin/bashecho "Please chose a number, 1:run w, 2:run top, 3:run free, 4:quit"echo select command in w top free quitdo case $command in w) w ;; top) top ;; free) free ;; quit) exit ;; *) echo "Please input a number:(1-4)." ;;esacdone 运行结果如下：1234567891011121314151617# sh select.shPlease chose a number, 1:run w, 2:run top, 3:run free, 4:quit1) w2) top3) free4) quit#? 1 19:41:01 up 13 min, 1 user, load average: 0.00, 0.01, 0.04USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 192.168.0.100 19:30 5.00s 0.04s 0.00s w#? 3 total used free shared buff/cache availableMem: 2032156 109500 1791200 8748 131456 1765448Swap: 4194300 0 4194300#? 4# 说明： select默认会把序列号对应的命令列出来，每次输入一个数字，则会执行相应的命令，命令执行完后并不会退出脚本。它会继续让我们再次输入序号。 序号前面的提示符，我们是可以修改的，利用变量PS3即可。 例子改版1利用PS3变量定义序号前的提示符，修改脚本如下：123456789101112131415161718192021222324252627#!/bin/bashPS3="Please select a number:"echo "Please chose a number, 1:run w, 2:run top, 3:run free, 4:quit"echo select command in w top free quitdo case $command in w) w ;; top) top ;; free) free ;; quit) exit ;; *) echo "Please input a number:(1-4)." ;;esacdone 执行结果如下：1234567891011121314151617# sh select2.shPlease chose a number, 1:run w, 2:run top, 3:run free, 4:quit1) w2) top3) free4) quitPlease select a number:1 19:52:07 up 24 min, 1 user, load average: 0.00, 0.01, 0.04USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 192.168.0.100 19:30 7.00s 0.07s 0.00s wPlease select a number:3 total used free shared buff/cache availableMem: 2032156 109496 1791192 8748 131468 1765444Swap: 4194300 0 4194300Please select a number:4# 例子改版2如果想要脚本每次输入一个序号后就自动退出，则需要再次更改脚本如下：123456789101112131415161718192021222324252627#!/bin/bashPS3="Please select a number:"echo "Please chose a number, 1:run w, 2:run top, 3:run free, 4:quit"echo select command in w top free quitdo case $command in w) w;exit ;; top) top;exit ;; free) free;exit ;; quit) exit ;; *) echo "Please input a number:(1-4).";exit ;;esacdone 执行结果如下：123456789101112# sh select3.shPlease chose a number, 1:run w, 2:run top, 3:run free, 4:quit1) w2) top3) free4) quitPlease select a number:1 19:55:14 up 27 min, 1 user, load average: 0.08, 0.03, 0.04USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 192.168.0.100 19:30 2.00s 0.08s 0.00s w# shell脚本中的函数在shell脚本中也可以使用函数，包括自定义的函数。其格式如下12345function 函数名()&#123; command1 command2&#125; 示例脚本如下：123456789#!/bin/bashfunction sum()&#123; sum=$[$1+$2] echo $sum&#125;sum $1 $2 说明： 函数必须定义在前，使用在后 shell脚本中的控制语句 break语句：break用于结束本层循环 continue语句：continue忽略continue之下的代码，直接进行下一次循环 exit语句：exit 数值用于结束脚本的执行，并向系统返回后面的数值 shell脚本中的数组关于shell脚本中的数组了解即可，因为它不常用。在平时的运维工作中，几乎用不到。但是这个概念还是需要了解一下。 数组定义一对圆括号表示是数组，数组元素用”空格”符号分隔开。123# a=(1 2 3 4 5)# echo $a1 说明； 数组名代表的是数组的首个元素 数组读取 获取数组元素的个数： 1echo $&#123;#a[@]&#125; 读取数组中的某一个元素，数标从0开始，a[0]是第一个元素： 1echo $&#123;a[2]&#125; 打印整个数组的元素： 123echo $&#123;a[*]&#125;或者echo $&#123;a[@]&#125; 数组赋值123456# a[1]=100# echo $&#123;a[*]&#125;1 100 3 4 5# a[5]=100# echo $&#123;a[*]&#125;1 100 3 4 5 100 说明： 直接通过数组名[下标]就可以对其进行赋值 如果下标不存在，自动添加一个新的数组元素 数组的删除123456789# a=(1 2 3 4 5)# unset a# echo $&#123;a[*]&#125;# a=(1 2 3 4 5)# unset a[1]# echo $&#123;a[*]&#125;1 3 4 5# echo $&#123;#a[*]&#125;4 数组分片12345# a=(`seq 1 5`)# echo $&#123;a[@]:0:3&#125; //表示从a[0]开始，依次向后输出3个元素1 2 3# echo $&#123;a[@]:1:4&#125; //表示从a[1]开始，依次向后输出4个元素2 3 4 5 数组替换可用echo替换（并非真正的改变值）：12345# a=(1 2 3 4 5)# echo $&#123;a[@]/3/100&#125;1 2 100 4 5# echo $&#123;a[@]&#125;1 2 3 4 5 可用赋值的方式来替换123# a=($&#123;a[@]/3/100&#125;)# echo $&#123;a[@]&#125;1 2 100 4 5 Shell脚本技巧使用 exec 重定向输出使用exec可以把脚本中exec下面所用到的全部的命令重定向到某一个指定的文件。使用示例如下：1234567#!/bin/bashd=`date +%F`exec &gt; /tmp/$d.log 2&gt;&amp;1echo "Begin at `date`"ls /tmp/jlkfsksdcd /sdfsdfas/echo "End at `date`" 这样的话在运行脚本的时候，屏幕上没有任何的信息输出，但是其全部信息都重定向到了指定的文件中了，可在相关文件中查阅。 case 结构中的条件12345678910case n in 1|2) command1 ;; 3|4) command2 ;; *) command3 ;; 如上，在右半括号之前可以写多个条件，用或字符分割，这样可以达到满足多个条件时执行相同的下一步。 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS服务简单配置（Aming）]]></title>
    <url>%2F2017%2F09%2F20%2F%E6%8A%80%E6%9C%AF%2F001.%20NFS%E6%9C%8D%E5%8A%A1%E7%AE%80%E5%8D%95%E9%85%8D%E7%BD%AE%EF%BC%88Aming%EF%BC%89%2F</url>
    <content type="text"><![CDATA[GO NFS用于在网络上共享存储。 服务端配置NFS安装在CentOS上使用NFS服务需要安装两个包：nfs-utils和rpcbind。在使用yum工具安装nfs-utils时会一并安装rpcbind。如下所示：yum install -y nfs-utils 说明： 以往的CentOS版本是需要安装protmap包的，从CentOS6开始，就改为安装rpcbind包了。 配置配置NFS比较简单，只需要编辑配置文件/etc/exports。如下所示，是一个非常简单的例子，用来创建一个简单的NFS服务器。 首先，修改配置文件（默认该文件为空），如下所示：123# vim /etc/exports //写入如下内容/home/nfstestdir 192.168.188.0/24(rw,sync,all_squash,anonuid=1000,anongid=1000) 说明： 这个配置文件就一行，共分为三个部分 第一个部分是本地要共享出去的目录 第二个部分是允许访问的主机（可以是一个IP，也可以是一个IP段） 第三个部分是小括号里面的一些权限选项 如上例子所示的这条配置的意义是，要共享的目录为/home/nfstestdir，信任的主机为192.168.188.0/24这个网段，权限为读写，同步模式，下限定所有使用者，并且限定的UID和GID都为1000 关于第三部分的权限选项的说明 rw：表示读/写 ro：表示只读 sync：同步模式，表示内存中的数据实时写入磁盘 async：非同步模式，表示把内存中的数据定期写入磁盘 no_root_squash：加上这个选项后，root用户就会对共享目录拥有至高的权限控制，就像是对本机的目录操作一样，但这样安全性降低 root_squash：与no_root_squash选项相对应，表示root拥护对共享目录的权限不高，只有普通用户的权限，即限制了root all_squash：表示不管使用NFS的用户是谁，其身份都会被限定为一个指定的普通用户身份 anonuid/anongid：要和root_squash以及all_squash选项一同使用，用于指定使用NFS的用户被限定后的UID和GID，但前提是本机的/etc/passwd中存在相应的UID和GID 其次，编辑好配置文件后，创建相关目录并启动NFS服务，如下所示：12345# mkdir /home/nfstestdir# systemctl start rpcbind# systemctl start nfs# systemctl enable rpcbind# systemctl enable nfs 说明： 在启动NFS服务之前，需要先启动rpcbind服务（CentOS的老版本中为portmap]） 客户端挂载NFS假设两台机器的IP分别为192.168.188.128和192.168.188.129。其中提供NFS服务的是192.168.188.128，客户端是192.168.188.129。 在客户端挂载NFS之前，需要查看服务端共享了哪些目录。在客户端（188.129）安装nfs-utils包后，可以使用showmount命令查看（这个命令就是前面的包所带的），如下所示：123# showmount -e 192.168.188.128Export list for 192.168.188.128:/home/nfstestdir 192.168.188.0/24 说明： 使用命令showmount -e IP就可以查看NFS的共享情况，这个IP为NFS服务端IP 从上例中可以看到192.168.188.128的共享目录为/home/nfstestdir，信任主机为192.168.188.0/24这个网段。 .然后在客户端上（188.129）挂载NFS，如下所示：123# mount -t nfs -o nfsvers=3 192.168.188.128:/home/nfstestdir /mnt# df -h....... 说明： 使用命令df -h可以看到增加了一个/mnt分区，它就是NFS的共享目录了。 -o后面跟挂载选项，如果不加-o nfsvers=3则在挂载目录下的文件属主和属组都是nobody，如果指定 nfsvers=3 则显示UID和GID，所以尽量加上这个选项，避免权限混乱 假如在该NFS的共享目录里面创建文件的权限不够，则需要在客户端中给共享目录相应的权限（如：chmod 777 /home/nfstestdir） 在权限配置正确后，客户端在NFS共享目录里面创建文件即可成功。（在上例配置的情况下，客户端在NFS共享目录里面创建的文件所有者和所属组的UID和GID都为1000） 命令 exportfs这个命令用于这种情况，当改变NFS的配置文件/etc/exports后，使用该命令挂载而不需要重启NFS服务。 exportfs命令的常用选项为-a、-r、-u和-v，各个选项的含义如下： 常用选项 含义 -a 表示全部挂载或者卸载 -r 表示重新挂载 -u 表示卸载某一个目录 -v 表示显示共享的目录 一个测试实验下面是关于以上知识的一个实验（从上面的例子中继续试验）： 首先修改服务端（188.128）的配置文件，如下所示：123# vi /etc/exports //增加一行：/tmp/ 192.168.188.0/24(rw.sync,no_root_squash) 然后在服务端（188.128）上执行如下命令：123# exportfs -arvexporting 192.168.188.0/24:/tmpexporting 192.168.188.0/24:/home/nfstestdir 在上一节用到了mount命令。用mount命令来挂载NFS服务是有讲究的，它要用-t nfs来指定挂载的类型为nfs。另外在挂载NFS服务时，常用-o nolock选项（即不加锁）。例如在客户端（188.129）上执行如下命令：12# mkdir /aminglinux# mount -t nfs -o nolock 192.168.188.128:/tmp /aminglinux/ 开机自动挂载NFS（基于上面的实验）还可以把要挂载的NFS目录写入到客户端上的/etc/fstab文件中，挂载时只需要执行mount -a命令。例如在/etc/fstab文件中增加一行，如下所示：1192.168.188.128:/tmp/ /aminglinux nfs defualt,nolock 0 0 由于刚刚已挂载了NFS，需要先卸载，执行如下命令：1# umount /aminglinux 然后重新挂载，执行如下命令：1mount -a 说明： 这样操作的好处是以后开机会自动挂载NFS。 刚刚挂载的/aminglinux/目录在服务端设置为了no_root_squash，它并不会限制root用户，也就是说使用root用户创建文件时，跟在客户端本机上创建的一样。 OK]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>NFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell基础知识]]></title>
    <url>%2F2017%2F09%2F03%2FShell%2F001.%20Shell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[GO 这些内容是在学习Shell脚本之前必须要掌握的Shell基础知识。 Shell 初相识什么是ShellShell 是系统跟计算机硬件交互时使用的中间介质，它只是系统的一个工具。在Shell和计算机硬件中间还有一层东西，那就是系统内核。用户在使用计算机的时候，直接面对的并不是计算机硬件，而是Shell，用户把指令告诉Shell，然后Shell再传输给系统内核，接着内核再去支配计算机硬件去执行各种操作。 Shell的版本有很多，但是初学时所接触的Linux发布版本（RedHat或CentOS系列）默认安装的Shell版本是bash（即Bourne Again Shell），它是sh（Bourne Shell）的增强版本。Bourne Shell是最早流行起来的一个Shell版本。其创始人是Steven Bourne，为了纪念他而将其命名为Bourne Shell，简称sh。 Shell的特性命令记录历史historyhistory：用来查看命令历史列表。 我们执行过的命令bash都会记录，预设可以记录1000条历史命令，这些命令保存在用户的家目录下的 .bash_history 文件中。 需要注意的是，只有当用户正常退出当前Shell时，在当前Shell中运行过的命令才会保存至该文件里。 我们可以自定义命令历史的大小，可以更改在配置文件/etc/profile 中的 HISTSIZE 环境变量。比如我们可以将其更改为2000。 我们也可以设置一下命令历史的记录格式，比如在每条命令前加上其被执行的时间，这时我们应该设置 HISTTIMEFORMAT 环境变量，也是在配置文件 /etc/profile 中进行设置，为了方便查看，可以在 HISTSIZE 下面增加一条：HISTTIMEFORMAT=&quot;%Y/%m/%d %H:%M:%S&quot; 。 我们可以把记录命令历史的文件设置成永久保存的权限，即不允许删除其内容，只能追加：chattr +a ~/.bash_history 。 Ctrl+r：可以搜索命令历史来执行 关于!的几个用法!是与命令历史有关的一个特殊字符，该字符常用的应用有一下几个： !!：连续两个!表示执行上一条命令。 !n：这里的n是数字，表示执行命令历史中的第n条命令。可用命令history查看历史命令列表。 !字符串（字符串大于等于1）：执行最近一次以该字符串开头的命令 !$：使用上一次命令的最后一个参数 命令和文件名补全Tab按键可以补全命令、补全路径或者一个文件名。连续按两次该键会把所有命令或文件名都显示出来。 命令补全 目录补全和文件名补全 命令参数补全 （默认不支持，需要安装一个包：yum install -y bash-comletion，安装后重启系统即可生效） 别名alias 设置别名格式 alias 别名字符串=&#39;所要替代的指令和该指令的参数&#39; 直接执行 alias 会把目前系统预设的别名全部列出来。 别名的配置文件有：~/.bashrc 、 /etc/profile.d/下的脚本里 每个用户可以在自己的配置文件 ~/.bashrc 中加入自定义的别名。 unalias 取消别名格式 unalias 别名字符串 通配符在bash下、可以使用*来匹配零个或多个字符，用?匹配一个字符，[]匹配里面的任一个字符（如 [0-9]），{}表示任取一组。 输入/输出重定向 符号 意义 &gt; 输出重定向 &gt;&gt; 输出追加重定向 &lt; 输入重定向（例子：mail -s &quot;zhuti&quot; somebody@host.com &lt; 邮件内容文件.txt） 2&gt; 错误输出重定向 2&gt;&gt; 错误输出追加重定向 2&gt;&amp;1 相当于 &gt; 1.txt 2&gt; 1.txt 2&gt;&gt;&amp;1 相当于 &gt;&gt; 1.txt 2&gt;&gt; 1.txt &amp;&gt; 把错误和正确的信息重定向到一个文件 &amp;&gt;&gt; 把错误和正确的信息追加重定向到一个文件 管道符管道符|，它用于将前一个指令的标准输出作为后一个指令的参数。 作业控制当运行程序时，可以使它暂停（按Ctrl+Z组合键），然后使用fg（foreground的简写）命令恢复它，或是用bg（background的简写）命令使它到后台运行（或是在运行命令的时候在命令后面加一个&amp;符号）。此外，还可以使它终止运行（按Ctrl+C组合键）。 多个被暂停的任务会有编号，使用jobs命令可以查看到放在后台的任务列表以及它们的编号，ID号后面有+ 或 - ，表示优先级。+比-优先级高。在这时使用bg或者fg命令时，则需要在后面加上编号。若不加编号，默认恢复优先级高的。 如何关掉在后台运行的任务呢？这分两种情况： 如果你没有退出Shell，则应先使用 fg 编号 把任务调到前台，然后按Ctrl+C组合键结束任务。 关闭了当前Shell，再次打开另一个Shell时，使用jobs命令并不会显示在后台运行或者被暂停的任务。要想关闭这些任务，则需要先知道它们的PID。用这个命令 ps aux | grep 关键字 找到这个进程。若是想结束这个进程，需要使用到kill命令。 kill命令很简单，直接在后面加PID即可 kill PID。如果遇到结束不了的进程时，可以在Kill后面加一个选项，即 kill -9 PID。 总结： 命令 意义 Ctrl+Z 暂停任务 fg [编号] 继续任务，把任务调到前台 bg [编号] 把命令调到后台并运行 命令 &amp; 把命令直接丢到后台并运行 jobs 查看进程列表和编号 Ctrl+C 结束当前任务 ps aux 查看相关进程的PID kill [-9] PID 结束进程 变量在Linux系统中预设了很多变量，可以供我们使用。我们也可以自定义一些变量，包括局部变量和全局变量。 echo $变量名 echo $变量名 用于查看一个变量的值。 env env 用于查看系统的全部环境变量。 登陆不同的用户，这些环境变量的值也不同。常见的环境变量如下： 变量名 值的意义 HOSTNAME 主机名 SHELL 当前用户的Shell类型 HISTSIZE 命令历史记录数 MAIL 当前用户的邮件存放目录 PATH 该变量决定了Shell将到哪些目录中寻找命令或程序 PWD 当前目录 LANG 这是与语言相关的环境变量，多语言环境可以修改此环境变量 HOME 当前用户的家目录 LOGNAME 当前用户的登陆名 注意：env命令显示的变量只是环境变量，系统预设的变量其实还有很多，这就需要用到下面的set命令了。 还有两个变需要了解一下： PS1：shell中的提示符 PS2：当在shell中执行换行后再继续操作时的提示符 set 和 unset set 用于查看系统里的全部变量，包括环境变量和用户自定义变量。unset 变量名 可取消或删除一个变量 export 变量名 export 变量名 声明一个变量为全局变量。 自定义变量定义变量的方式 变量=值 只能在当前Shell中使用，不能在子Shell中使用。 export 变量=值 设置了一个全局变量，可以在当前Shell和子Shell中使用。 自定义变量的规则 设定变量的格式为a=b，其中a为变量名，b为变量的值，等号两边不能有空格。 变量名只能由字母、数字以及下划线组成，且不能以数字开头。 当变量内容带有特殊字符时，需要进行特殊处理，如下： 当变量内容带有空格时，需要给该变量加上单引号。如 myname=’Aming Linux’ 当变量内容带有单引号，需要给该变量加上双引号。如 myname=”I’m a cocker” 若变量内容中需要用到其它命令，只使用该命令的运行结果作为变量的值，则该命令需要加上反引号。如 myname=`pwd` 变量内容可以累加其它变量的内容，但需要加双引号。如 myname=”$LOGNAME”Aming b=$a”123” 或 b=$a’123’ c=$a$b a=$a”增加值” 注意单引号、双引号和反引号的使用区别： 单引号：里面的内容全部是普通字符 双引号：里面的内容带有本身的意义，比如某个变量 反引号：里面的内容为一个命名，所代表的是该命令执行之后的结果 让自定义变量一直生效如果想要使自定义的变量一直生效，该如何办到呢？分以下两种情况： 允许系统内所有用户登陆后都可以使用该变量。 在/etc/profile文件的最后一行加入export 变量=值 运行source /etc/profile或. /etc/profile让此配置文件生效 目的达到 仅允许当前用户使用该变量。 在用户家目录下的.bashrc文件的最后一行加入export 变量=值 运行source .bashrc或. .bashrc让配置文件生效 目的达到 变量的配置文件这些配置文件总结如下表： 配置文件名 文件的作用 /etc/profile 到交互登陆时才执行。这个文件预设了几个重要的变量，例如PATH、USER、LOGNAME、MAIL、INPUTRC、HOSTNAME、HISTSIZE、umask等 /etc/bashrc 用户不用登陆，执行shell就生效。这个文件主要预设umask以及PS1 .bash_profile 该文件定义了用户的个人化路径与环境变量的文件名称。每个用户都可以使用该文件输入专属于自己的shell信息，当用户登陆时，该文件仅仅执行一次 .bashrc 该文件包含专属于自己的shell的bash信息，当登陆或每次打开新的shell时，该文件会被读取。例如，用户可以将自己定义的别名或者自定义变量写到这个文件中 .bash_history 该文件用于记录命令历史 .bash_logout 当退出shell时，会执行该文件。可以将一些清理的工作放到这个文件中 PS1变量的说明这个PS1就是我们在输入命令时前面的那串字符。如 [root@AmingLinux-105 ~]#，我们来查看一下PS1的值：12[root@AmingLinux-105 ~]# echo $PS1[\u@\h \W]\$ 其中，\u是用户名，\h是主机名，\W当前目录名，（\w表示的是工作目录的完整绝对路径），\$代表用户身份字符（root为#，普通用户为$） Shell 中的特殊符号特殊符号 特殊符号 意义 * 代表零个或多个任意字符 ? 只代表一个任意字符 # 注释符，这个符号在Linux中表示注释说明，在后面的内容都会被忽略 \ 脱义字符，将后面的特殊字符还原为普通字符 管道符 将前面命令的输出作为后面命令的输入。支持它的工具有cat、less、head、tail、grep、cut、sort、wc、uniq、tee、tr、split、sed、awk等 $变量名 它可以作为变量前面的标识符 $? 表示上一条的命令执行的返回值，若为0则正确执行，若非零则错误执行 !$ 表示上条命令中的最后一个变量 ; 如果在多条命令中间使用这个符号连接，则表示按顺序依次执行 ~ 代表用户的家目录，用于cd ~ &amp; 表示把命令放到后台执行，用于命令 &amp;；&amp;&amp;代表逻辑与；&amp;1代表参数1 重定向 &gt;、&gt;&gt;、2&gt;、2&gt;&gt;、&lt; 中括号[] 中括号内为字符组合中的任意一个，可以是一个范围（[1-3a-z]） 还有两个符号&amp;&amp;和||，将与;放在一起进行总结： command1 ; command2 不管command1是否执行成功，都会执行command2 command1 &amp;&amp; command2 只有command1执行成功后，才会执行command2 command1 || command2 只有command1执行失败了，才会执行command2 几个常用的管道命令cut cut 用来截取某一个字段。 格式 cut -d &#39;分隔字符&#39; [-cf] n，这里n是数字。其选项说明如下： 选项 说明 -d 后面跟分隔字符，分隔字符要用单引号括起来 -c 后面接的是第几个字符 -f 后面接的是第几个区块 cut命令的用法说明： -d选项后面加冒号作为分隔字符，-f 1 表示截取第一段，-f和1之间的空格可有可无。示例如下： cut -d ‘分隔符’ -f 1 filename cut -d ‘分隔符’ -f 1,2 filename cut -d ‘分隔符’ -f 1-4 filename123456[root@AmingLinux-105 ~]# cat /etc/passwd | cut -d ':' -f 1 | head -5rootbindaemonadmlp -c选项后面可以一个数字n，也可以是一个区间n1-n2，还可以是多个数字n1,n2,n3。示例如下： 123456789101112[root@AmingLinux-105 ~]# head -n2 /etc/passwd | cut -c2oi[root@AmingLinux-105 ~]# head -n2 /etc/passwd | cut -c1rb[root@AmingLinux-105 ~]# head -n2 /etc/passwd | cut -c1-10root:x:0:0bin:x:1:1:[root@AmingLinux-105 ~]# head -n2 /etc/passwd | cut -c1,3,10ro0bn: sort sort 用作排序 格式 sort [-t 分隔符] [-kn1,n2] [-nru]，这里的n1和n2指的是数字，其它选项的含义如下 选项 含义 -t 后面跟分隔字符，作用跟cut的-d选项一样 -n 表示使用纯数字排序 -r 表示反向排序 -u 表示去重复 -kn1,n2 表示由n1区间排序到n2区间，可以只写-kn1，表示只对n1字段排序 sort 命令的用法示例： sort 如果不加任何选项，则从首字符向后依次按ASCII码值进行比较，最后将它们按升序输出。 123456[root@AmingLinux-105 ~]# head -n5 /etc/passwd | sortadm:x:3:4:adm:/var/adm:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinroot:x:0:0:root:/root:/bin/bash -t 选项后面跟分隔符，-k 选项后面跟单个数字表示对第几个区域的字符串排序，-n选项则表示用纯数字排序。 123456[root@AmingLinux-105 ~]# head -n5 /etc/passwd | sort -t: -k3 -nroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin -k 选项后面跟数字n1和n2表示对第n1和n2区域内的字符串排序，-r选项则表示反向排序。 1234567[root@AmingLinux-105 ~]# head -n5 /etc/passwd | sort -t: -k3,5 -rlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologinroot:x:0:0:root:/root:/bin/bash//这里的-k3,5表示对第3区域至第5区域间的字符串排序。 wc wc 用于统计文档的行数、字符数或词数。 常用选项 含义 不加选项 依次输出文档的行数、词数和字符数 -l 统计行数 -m 统计字符数 -w 统计词数 示例命令如下：12345678910[root@AmingLinux-105 ~]# wc /etc/passwd 27 47 1269 /etc/passwd[root@AmingLinux-105 ~]# wc -l /etc/passwd27 /etc/passwd[root@AmingLinux-105 ~]# wc -m /etc/passwd1269 /etc/passwd[root@AmingLinux-105 ~]# wc -w /etc/passwd47 /etc/passwd一个例子（判断文件有几行，如果行数少于3显示no）:line=`wc -l 4.txt|cut -d ' ' -f1` ; if [ $line -lt "3" ]; then echo "no"; fi uniq uniq 用来删除重复的行 该命令只有-c选项最常用，它表示统计重复的行数，并把行数写在最前面。使用uniq前，必须先给文件排序，否则不管用。示例如下：123456789101112131415161718[root@AmingLinux-105 test]# uniq test.txt11111111111222222222223333333333355555555555[root@AmingLinux-105 test]# sort test.txt | uniq11111111111222222222223333333333355555555555[root@AmingLinux-105 test]# sort test.txt | uniq -c 1 1 11111111111 4 22222222222 2 33333333333 1 55555555555 tee tee 命令类似于重定向&gt;，它的作用是既输出到文件，又输出到屏幕，可以叫它为”双向重定向”。 tee 命令后面跟文件名，且它常用与管道符后面。示例如下：1234[root@AmingLinux-105 test]# echo "aaaaaaaaaaaaaaaaaaa" | tee test.txtaaaaaaaaaaaaaaaaaaa[root@AmingLinux-105 test]# cat test.txtaaaaaaaaaaaaaaaaaaa tr tr 用于替换字符，常用来处理文档中出现的特殊符号，如DOS文档中出现的^M。这个工具是针对一个字符来讲的，有一定的局限性。 常用选项 含义 -d 表示删除某个字符，后面跟要删除的字符 -s 表示删除重复的字符 示例如下： tr 常用于把小写字母变成大写字母，如tr &#39;[a-z]&#39; &#39;[A-Z]&#39;。 123[root@AmingLinux-105 test]# head -n2 /etc/passwd | tr '[a-z]' '[A-Z]'ROOT:X:0:0:ROOT:/ROOT:/BIN/BASHBIN:X:1:1:BIN:/BIN:/SBIN/NOLOGIN tr 还可以替换一个字符。 123[root@AmingLinux-105 test]# grep 'root' /etc/passwd | tr 'r' 'R'Root:x:0:0:Root:/Root:/bin/bashopeRatoR:x:11:0:opeRatoR:/Root:/sbin/nologin split split 用于切割文档，常用选项为-b和-l 常用选项 含义 -b 依据大小来分割文档，单位为byte -l 依据行数来分割文档 示例如下：1234[root@AmingLinux-105 test]# cp /etc/passwd .[root@AmingLinux-105 test]# split -b 500 passwd[root@AmingLinux-105 test]# ls1 2 3 4 passwd test.txt test.txt.zip xaa xab xac 如果split不指定目标文件名，则会以xaa、xab、xac….这样的文件名来存储切割后的文件。当然，也可以指定目标文件名。示例如下：12345[root@AmingLinux-105 test]# rm -f xa*[root@AmingLinux-105 test]# split -b 500 passwd new[root@AmingLinux-105 test]# ls1 2 3 4 newaa newab newac passwd test.txt test.txt.zip[root@AmingLinux-105 test]# split -b 1M passwd new 使用-l选项的示例：1234567891011121314151617[root@AmingLinux-105 test]# rm -f new*[root@AmingLinux-105 test]# split -l 10 passwd[root@AmingLinux-105 test]# ls1 2 3 4 passwd test.txt test.txt.zip xaa xab xac[root@AmingLinux-105 test]# wc -l * 0 1 0 2 0 3wc: 4: 是一个目录 0 4 27 passwd 1 test.txt 0 test.txt.zip 10 xaa 10 xab 7 xac 55 总用量 OK]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux软件管理技术]]></title>
    <url>%2F2017%2F08%2F31%2FLinux%2F010.%20Linux%E8%BD%AF%E4%BB%B6%E7%AE%A1%E7%90%86%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[GO 0. RPM和DPKG两大阵营在 GNU/Linux( 以下简称 Linux) 操作系统中，RPM 和 DPKG 为最常见的两类软件包管理工具，他们分别应用于基于 RPM 软件包的 Linux 发行版本和 DEB 软件包的 Linux 发行版本。软件包管理工具的作用是提供在操作系统中安装，升级，卸载需要的软件的方法，并提供对系统中所有软件状态信息的查询。 RPM 全称为 Redhat Package Manager，最早由 Red Hat 公司制定实施，随后被 GNU 开源操作系统接受并成为很多 Linux 系统 (RHEL) 的既定软件标准。与 RPM 进行竞争的是基于 Debian 操作系统 (UBUNTU) 的 DEB 软件包管理工具－ DPKG，全称为 Debian Package，功能方面与 RPM 相似。 1. CentOS软件管理学习CentOS的软件管理方式，包括RPM包的安装更新查询卸载等，还有源码包的安装方式。 1.1. RPM一个 RPM 包包含了已压缩的软件文件集以及该软件的内容信息（在头文件中保存），通常表现为以 .rpm 扩展名结尾的文件，例如 package.rpm 。对其操作，需要使用 rpm 命令。下面介绍 rpm 工具的参数和使用方法。 1.1.1. RPM 介绍RPM是Red Hat Package Manager的缩写，由RedHat公司开发。它是以一种数据库记录的方式将我们所需要的套件安装到Linux主机的一套管理程序。也就是说，在Linux系统中存在着一个关于RPM的数据库，它记录了安装的包以及包与包之间的依赖关系。RPM包是预先在Linux机器上编译并打包的文件，安装非常快捷。但是它也有一些缺点，比如安装环境必须与编译时一致或相当，包与包之间存在着相互依赖的情况，卸载包时需要先把依赖的包卸载。如果依赖的包是系统所必须的，就不能卸载这个包，否则系统会崩溃。 RPM包的文件名都由-和.分成了若干部分，一般都像这样 abattis-cantarell-fonts-0.0.16-3.el7.noarch.rpm 、abrt-2.1.11-45.el7.centos.x86_64.rpm。abrt为包名，2.11为版本信息，45.el7.centos为发布版本号，x86_64为运行平台。常见的运行平台有i386、i486、i586、i686（这三个为32位的CPU）和x86_64（64位的CPU）。另外，有些RPM包并没有写具体的平台而是noarch，这是该包没有平台限制的意思。 1.1.2. rpm 命令 常用选项 意义 -i 表示安装 -v 表示可视化 -h 表示显示安装进度 -U 表示升级 -e 表示卸载 -q 表示查询 -p 表示对RPM包进行查询，通常和其它参数同时使用 –force 表示强制安装，即使覆盖属于其他包的文件也要安装 –nodeps 表示当要安装（或卸载）的RPM包依赖于其它包时，即使其它包没有安装（或卸载），也要安装（或卸载）这个包 命令 功能 rpm -ivh package.rpm 安装RPM包 rpm -Uvh package.rpm 升级RPM包 rpm -ev package 卸载RPM包（这里的filename是通过RPM的查询功能所查询到的） rpm -q package 查询一个RPM包 rpm -qa (package) 查询当前系统所有已安装的RPM包 rpm -qi package 得到一个已安装的RPM包的相关信息 rpm -ql package 列出一个RPM包的安装文件 rpm -qf 文件的绝对路径 列出某个文件属于哪个RPM包 rpm -qRp package.rpm 查询RPM包的依赖关系 1.1.3. RPM 包管理示例以下步骤描述了一个普通用户安装 IBM Lotus Notes V85 ( 以下简称 Notes) 的典型操作过程。 Notes 的 RPM 包名为 ibm_lotus_notes-8.5.i586.rpm 。 首先查询是否该软件是否已经在系统中存在 : rpm -qa | grep ibm_lotus_notes。如果返回信息为空那么说明该软件还未被安装。 查询 Notes 软件包内容： 12345678910111213# rpm -qip ibm_lotus_notes-8.5.i586.rpm Name : ibm_lotus_notes Relocations: /opt/ibm/lotus/notes Version : 8.5 Vendor: IBM Release : 20081211.1925 Build Date: Sat 13 Dec 2008 09:38:55 AM CST Install Date: (not installed) Build Host: dithers.notesdev.ibm.com Group : Applications/Office Source RPM: ibm_lotus_notes-8.5-20081211.1925.src.rpm Size : 603779427 License: Commercial Signature : DSA/SHA1, Sat 13 Dec 2008 09:43:02 AM CST, Key ID 314c8c6534f9ae75 Summary : IBM Lotus Notes Description : IBM Lotus Notes software provides a robust ... 安装 Notes：rpm -ivh ibm_lotus_notes-8.5.i586.rpm。返回信息如下： 12Preparing... ########################################### [100%] 1:ibm_lotus_notes ########################################### [100%] 升级 Notes：若今后需要基于该版本升级至更高版本的 Notes( 缝 .0 - ibm_lotus_notes-9.0.i586.rpm)，则使用 -U 参数：# rpm -Uvh ibm_lotus_notes-8.5.i586.rpm 卸载 Notes：注意卸载软件使用软件名称，而不是包文件名：# rpm -ev ibm_lotus_notes 1.2. YUM 工具1.2.1. YUM 介绍YUM工具是用来集中管理RPM包的，使用它会更加方便的进行安装卸载升级RPM包。YUM工具最大的优势在于可以联网去下载所需要的RPM包，然后自动安装，若是所安装的RPM包有依赖关系，它会依次安装所依赖的包。 YUM 基于 RPM 包管理工具，能够从指定的源空间（服务器，本地目录等）自动下载目标 RPM 包并且安装，可以自动处理依赖性关系并进行下载、安装，无须繁琐地手动下载、安装每一个需要的依赖包。此外，YUM 的另一个功能是进行系统中所有软件的升级。如上所述，YUM 的 RPM 包来源于源空间，在 RHEL 中由 /etc/yum.repos.d/ 目录中的 .repo 文件配置指定，如 rhel-debuginfo.repo 的内容： rhel-debuginfo.repo123456[rhel-debuginfo] name=Red Hat Enterprise Linux 5Client - i386 - Debug baseurl=ftp://ftp.redhat.com/pub/redhat/linux/enterprise/5Client/en/os/i386/Debuginfo/ enabled=0 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release YUM 的系统配置文件位于 /etc/yum.conf，内容如下：12345678910111213[main] cachedir=/var/cache/yum keepcache=1 debuglevel=2 pkgpolicy=newest logfile=/var/log/yum.log distroverpkg=redhat-release tolerant=1 exactarch=1 obsoletes=1 gpgcheck=1 plugins=1 exclude= firefox gftp 配置文件用来定义用户期望的 yum 行为，比如，gpgcheck 表明安装时不进行 gpg 验证，exclued=firefox gftp 表明进行系统全软件升级时不升级 firefox 和 gftp 。 1.2.2. YUM 命令 命令 功能 yum repolist all 列出所有仓库 yum list all 列出仓库中所有软件包 yum list 列出所有可用的RPM包资源。（已安装可未安装的都显示出来，yum list会先列出已经安装的包(Installed Packages) 然后再列出可以安装的包(Available Packages)） yum clean all 清除所有仓库缓存 yum info 软件包名称 查看软件包信息 yum search [关键字] 搜索RPM包（还可以利用 grep 来过滤） yum install [-y] RPM包名 安装RPM包。加上-y选项，表示自动安装，跳过交互的程序 yum reinstall 软件包名称 重新安装软件包 yum remove [-y] RPM包名 卸载RPM包（注意，卸载时最好不要加-y选项，以免重要的RPM包被卸载掉） yum check-update 列出系统中可升级的所有软件 yum update [-y] RPM包名 升级RPM包 yum -y update 升级所有包，改变软件设置和系统设置,系统版本内核都升级 yum -y upgrade 升级所有包，不改变软件设置和系统设置，系统版本升级，内核不改变 yum provides 命令名 查询该命令是由那个包安装的 yum grouplist 列出所有安装过和未安装过的套件 yum groupinfo 软件包组 查询指定的软件包组信息 yum groupinstall 套件名 安装该组件套件 yum groupremove 套件名 卸载该组件套件 1.2.3. 安装YUM扩展源 我们使用 yum 安装 rpm 包时，经常遇到一些包没有，这时候你可以尝试安装 epel 的扩展源，这里有很多系统不自带的 rpm 包。 yum install -y epel-release yum list 你会发现最右侧出现很多 epel 的 rpm 包。 下载一个扩展源的rpm包，用yum安装。然后用 yum clean all 或 yum makecache 清除缓存，用 yum list 检查是否成功。 1.2.4. 使用本地光盘制作YUN源有时候，Linux系统不能联网，此时当然就不能很便捷地使用联网的yum源了，这时就需要我们自己在Linux系统下使用光盘制作yum源。具体操作步骤如下： 挂载光盘mount /dev/cdrom /mnt 删除/etc/yum.repos.d目录下所有的repo文件（删除之前，最好先做一下备份）。cp -r /etc/yum.repos.d /etc/yum.repos.d_bakrm -rf /etc/yum.repos.d/* 创建新文件dvd.repo，并添加如下内容： 123456# vim /etc/yum.repos.d/dvd.repo[dvd]name=install dvdbaseurl=file:///mntenabled=1gpgcheck=0 刷新repos生成缓存，如下所示：yum makecache 然后就可以用yum了。若需要恢复之前的yum源，则进行如下操作：123# rm -rf /etc/yum.repos.d# mv /etc/yum.repos.d_bak /etc/yum.repos.d# yum list //这一步是必须要执行的，这样就可以生成缓存，方便下次使用 1.2.5. 利用YUM工具下载RPM包有时我们需要下载RPM包但不安装，而仅仅是复制给其它机器使用。我们可以用YUM工具来完成这个任务，做到只下载而不安装。命令如下： 安装 yum-downloadonly（首先需要安装一个插件来支持只下载不安装）yum install -y yum-plugin-downloadonly.noarch（如果你的 CentOS 是 5.x 版本，则需要安装 yum-downloadonly.noarch 这个包。） 只下载而不安装RPM包 yum install 包名 -y --downloadonly （这样虽然下载了，但是并没有保存到我们想要的目录下，它默认保存到了/var/cache/yum/后面还有好几层子目录，根据你系统的版本决定。） 把RPM包下载到指定目录 yum install 包名 -y --downloadonly --downloaddir=绝对路径 下载一个已安装过的RPM包 yum reinstall 包名 -y --downloaonly [--downloddir=绝对路径] 2. Ubuntu软件管理2.1. DEB2.1.1. DEB 介绍一个 DEB 包包含了已压缩的软件文件集以及该软件的内容信息（在头文件中保存），通常表现为以 .deb 扩展名结尾的文件，例如 package.deb 。对其操作，需要使用 dpkg 命令。下面介绍 dpkg 工具的参数和使用方法。 2.1.2. dpkg 命令DPKG 的常规使用方法为 dpkg -? Package(.rpm), 其中 -? 为安装参数 ( 更多信息，请查阅帮助 $man rpm)。 参数 意义 -l 在系统中查询软件内容信息 –info 在系统中查询软件或查询指定rpm包的内容信息 -i 在系统中安装/升级软件 -r 在系统中卸载软件，不删除配置文件 -P(大) 在系统中卸载软件以及其配置文件 depk命令参数使用方法 命令 意义 dpkg -i package.deb 安装或升级DEB包命令 dpkg -r package.deb 卸载DEB包，但是不删除其配置文件 dpkg -P package.deb 卸载DEB包，并且删除其配置文件 dpkg-deb -c package.deb 查询DEB包中包含的文件列表命令 dpkg –info package.deb 查询DEB包中包含的内容信息命令 dpkg -l package 查询系统中所有已安装DEB 2.1.3. DEB 包管理示例以下步骤描述了一个普通用户安装 IBM Lotus Notes V85 ( 以下简称 Notes) 的典型操作过程。 Notes 的 DEB 包名为 ibm_lotus_notes-8.5.i586.deb。 首先查询是否该软件是否已经在系统中存在：dpkg -l ibm-lotus-* 如果系统中从未安装过 Lotus 产品，那么返回信息为 : No pakcages found matching ibm-lotus-* 如果系统安装过 Lotus 产品，但已被删除，那么返回信息为 : pn ibm-lotus-notes none (no description available) 查询 Notes 软件包内容：dpkg --info ibm_lotus_notes-8.5-i586.deb。返回信息如下： 123456789101112new debian package, version 2.0. size 335012296 bytes: control archive= 231821 bytes. ... Package: ibm-lotus-notes Version: 8.5-20081211.1925 Section: IBM Priority: extra Architecture: i386 Installed-Size: 619444 Maintainer: IBM Lotus Product Description: IBM Lotus Notes IBM Lotus Notes software provides a robust ... ... 安装 Notes : dpkg -i ibm_lotus_notes-8.5.i586.deb。返回信息如下： 12345(Reading database ... 151150 files and directories currently installed.) Preparing to replace ibm-lotus-notes 8.5-20081211.1925 (using ibm-lotus-notes-higher-version.i586.deb) ... Unpacking replacement ibm-lotus-notes ... Setting up ibm-lotus-notes (higher-version) ... 升级 Notes：dpkg -i ibm_lotus_notes-8.5.i586.deb。返回信息如下： 12345(Reading database ... 151150 files and directories currently installed.) Preparing to replace ibm-lotus-notes 8.5-20081211.1925 (using ibm-lotus-notes-higher-version.i586.deb) ... Unpacking replacement ibm-lotus-notes ... Setting up ibm-lotus-notes (higher-version) ... 卸载 Notes : 注意卸载软件使用软件名称，而不是包文件名：dpkg -P ibm-lotus-notes 2.2. APT工具2.2.1. APT 介绍APT 的全称为 Advanced Packaging Tools 。与 YUM 对应，它最早被设计成 DPKG 的前端软件，现在通过 apt-rpm 也支持 rpm 管理。而本节本节将介绍 APT 作为 DPKG 前端的使用。 APT 的主要包管理工具为 APT-GET，通过此工具可满足和上述 YUM 相似的功能要求。 APT 的软件源定义来自 /etc/apt/sources.list 文件：1234# See http://help.ubuntu.com/community/UpgradeNotes for how to upgrade to # newer versions of the distribution. deb http://cn.archive.ubuntu.com/ubuntu/ hardy main restricted deb-src http://cn.archive.ubuntu.com/ubuntu/ hardy main restricted 注意每次手动修改上述文件后，需要使用 sudo apt-get update 来更新系统的源使新的源数据被当前系统识别。 Ubuntu 中 APT 的配置文件位于 /etc/apt/apt.conf.d，其中的多个配置文件依功能分类。 2.2.2. APT 命令 命令 意义 apt-get update 更新源索引 apt-get install package-name 安装指定软件 apt-get source package-name 下载指定软件的源文件 apt-get upgrade 将系统中所有软件升级到最新版本 apt-get dist-upgrade 将操作系统连同所有软件升级到最新版本 apt-get remove package-name 卸载指定软件 3. RPM与DEB的一些常见问题3.1. 查询软件包依赖关系查询 RPM 包的依赖关系，使用 rpm -qRp：1234567# rpm -qRp package_a.rpm package_b = version_info 或 package_b &gt;= version_info 或 package_b &lt;= version_info 表明 package_a.rpm 依赖于 version_info 版的 package_b，或者任何高于并包括 version_info 版的 package_b，亦或低于或包括 version_info 版的 package_b 。所以 package_b.rpm 必须在 package_a 之前安装于系统中。 查询 DEB 包的依赖关系，可解读 dpkg –info 结果中的 Pre-Depends 字段：12345678910$ dpkg --info package_a.deb Pre-depends: package_b (= version_info) Depends: package_b (= version_info) 或 Pre-depends: package_b (&gt;= version_info) Depends: package_b (&gt;= version_info) 或 Pre-depends: package_b (&lt;= version_info) Depends: package_b (&lt;= version_info) 表明 package_a.deb 依赖于 version_info 版的 package_b 或者任何高于并包括 version_info 版的 package_b 亦或低于或包括 version_info 版的 package_b. 所以 package_b.deb 必须在 package_a 之前安装于系统中。 所以正确的安装方法如下所示： 对于 package_a，正确的安装方法应该是：1234567##RPM # rpm -ivh package_b.rpm # rpm -ivh package_a.rpm ##DEB $ sudo dpkg -i package_b.deb $ sudo dpkg -i package_a.deb 如上示例为最理想的依赖关系，实际应用中往往最令用户头疼的是 package_a 依赖于 package_b/c/d/e/f 等多个包 , 而 package_b/c/d/e/f 等包又依赖于 package_b1,b2,b3/c1,c2/d1,d2/e1,e2/f1,f2 等等 … … 为保证软件的正常使用，必须找到所有依赖包以及子依赖包并且安装。过多的依赖关系大大降低了 Linux 软件安装的用户友好性。所以针对此类问题，使用了更高级的包管理策略去解决 - yum/apt 。 3.2. RPM 与 DEB 的兼容 - AlienAlien 工具可以将 RPM 软件包转换成 DEB 软件包，或把 DEB 软件包转换成 RPM 软件包，以此适应兼容性的需要。注意首先请在系统中安装 alien 。 在 UBUNTU 中使用 alien 将 rpm 转换为 deb 并安装 :12$ sudo alien -d package.rpm $ sudo dpkg -i package.deb 在 RHEL 中使用 alien 将 deb 转换为 rpm 并安装 :12# alien -r package.deb # rpm -ivh package.rpm 3.3. 常见的一些问题3.3.1. 可以手动强制不进行 RPM/DEB 的依赖性关系检查吗？ RPM：可以。使用 –nodeps 辅助参数，则安装过程将不理会依赖性关系限制，强制安装目标包，如：rpm -i --nodeps package_a.rpm DEB：可以。使用— force-depends 辅助参数，如：dpkg -i --force-depends package_a.deb 3.3.2. RPM 中的 –force 是干什么用的？RPM 中的默认安装规则是不允许同一个包多次安装的，也不允许降级安装。使用 –force 辅助参数将不考虑以上因素，强制安装 RPM 包。但是，–force 无法强制安装一个不满足系统依赖性关系的包 ( 此时需要用到 –nodeps 参数 ) 。使用方法如：rpm -i --force package_a.rpm 3.3.3. RPM/DPKG 支持远程安装吗？ RPM：是。 RPM 支持 HTTP 和 FTP 协议，如：rpm -Uvh ftp://user:pass@ftpserver/package.rpm DEB：最新的基于 DEB 包的系统中，远程安装通常被更先进的 APT 代替。 3.3.4. 可以从 RPM/DPKG 中抽取个别文件吗？ RPM：是。可以使用 rpm2cpio 工具来提取文件 DEB：是。可以使用 dpkg-deb 工具来提取文件：dpkg-deb --extract ibm_lotus_notes-8.5.i586.deb $dir( 目标目录 ) 3.3.5. RPM/DPKG 提供包安装成功的验证机制吗？ RPM：是。可以使用 -V 参数进行验证。 DEB：Debian 系统通常使用 debsums 工具参数进行验证。 3.3.6. RPM/DPKG 提供包安全签名吗？ RPM：是。可以使用 –import 导入与软件同时发布的 GPG KEY, 接着使用 -K 命令来验证包的安全性，如： 1234# rpm --import pub_ibm_lotus_notes.gpg # rpm -K ibm_lotus_notes-8.5.i586.rpm 返回信息 : ibm_lotus_notes-8.5.i586.rpm: (sha1) dsa sha1 md5 gpg OK DEB：DPKG 不提供原生的 Key 验证机制。可以使用 debsigs 和 debsigs-verify 3.3.7. 如果 RPM 的底层数据库损坏，RPM 还能使用吗？ RPM：如果底层数据库损坏，RPM 将无法正常使用。此时最常用的解决方法是重构数据库：rm -f /var/lib/rpm/__* ; rpm -vv --rebuilddb DEB：DPKG 本身不提供底层数据库恢复机制。它的数据库以文件形式保存在 /var/lib/dpkg 目录中。及时地备份这个目录是最好的预防数据库损坏措施。 3.3.8. 可以查询系统中已经安装的某个文件属于哪个 RPM 包吗？ RPM：可以。使用 -qf 参数 , 如在安装了 Notes8.5 的系统中：rpm -qf /opt/ibm/lotus/notes/notes；返回信息 : Ibm_lotus_notes-8.5-20081211.1920 DEB：可以。使用— search 参数 , 如在安装了 Notes8.5 的系统中：dpkg --search /opt/ibm/lotus/notes/notes；返回信息 : ibm-lotus-notes: /opt/ibm/lotus/notes/notes 3.3.9. 可以查询 RPM 包的安装时间吗？ RPM：可以。可使用 –last 查询。如：rpm -qa --last；返回信息 : 系统中所有软件的安装时间。 DEB：DPKG 不提供直接的查询参数，但是可以用过查询 dpkg 的日志文件实现这个功能。如：cat /var/log/dpkg.log | grep &quot;\ install\ &quot; 4. 源码包安装在Linux下安装源码包是最常用的。安装源码包，需要我们把源代码编译成可执行的二进制文件。如果你能读懂这些源代码，就可以修改这些源代码的自定义功能，然后按你的需求编译。使用源码包除了可以自定义修改源代码外，还可以定制相关的功能，因为源码包在编译时可以附加额外的选项。 源码包的编译用到了Linux系统里的编译器。常见的源码包一般都是用C语言开发的，因为C语言是Linux上最标准的程序语言。Linux上的C语言编译器称为gcc。利用它可以把C语言编译成可执行的二进制文件。所有，如果Linux上没有安装gcc，就无法编译源码。可以使用命令yum install -y gcc来完成安装。 4.1. 源码包安装的一般步骤安装源码包通常需要以下三个步骤： ./configure。这一步可以定制功能，加上相应的选项即可，具体有什么选项可以通过命令./configure --help来查看。（一般常用的有–prefix=PREFIX这个选项的意思是定义软件包安装到哪里）这一步会自动检测你的Linux系统与相关的套件是否有编译该源代码包时所需要的库，因为一旦缺少某个库，就不能完成编译，所以若是遇到这种情况，要先安装这些库。只有检测通过后，才会生成Makefile文件。 make。使用这个命令，会根据Makefile文件中预设的参数进行编译，这一步其实就是gcc在工作了。 make install。这一步是安装步骤，用于创建相关软件的存放目录和配置文件。 注意，对于以上这3个步骤，并不是所有的源代码包软件都一样，也就是说，源码包的安装并没有标准的安装步骤。这就需要你在拿到源码包解压后，进入目录，找到相关的帮助文档（通常，会以INSTALL或README为文件名）。 通常，源码包都会放置在/usr/local/src目录下，方便对源码包的统一管理。 4.2. 一个源码包安装的实例（安装Apache） 下载源码包 cd /usr/local/src/ #约定目录 wget http://mirrors.cnnic.cn/apache/httpd/httpd-2.2.27.tar.bz2 解压 tar jxvf httpd-2.2.27.tar.bz2 //查看README或者INSTALL说明文件 指定编译参数 ./configure --help ./configure --prefix 安装路径 …… echo $? 验证是否成功 make echo $? 验证是否成功 make install OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux压缩打包技术]]></title>
    <url>%2F2017%2F08%2F31%2FLinux%2F009.%20Linux%E5%8E%8B%E7%BC%A9%E6%89%93%E5%8C%85%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[GO 1. 常见压缩包后缀名及对应工具 后缀名 所使用的压缩工具 .gz gzip .bz2 bzip2 .zip zip .rar rar .tar tar打包程序打包的文件 .tar.gz 先由tar打包，再由gzip压缩 .tar.bz2 先由tar打包，再由bzip2压缩 .tar.xz 先由tar打包，再由xz压缩 2. 常用压缩工具2.1. gzip格式 gzip [-d#] filename（其中#为1~9的数字） 选项 说明 -d 解压 -# 设定压缩等级1为最差，9为最好，6为默认 说明： gzip后面直接跟文件名，表示在当前目录下压缩该文件，而源文件也会消失。 gzip -d \*.gz 命令gzip -d后面跟压缩文件表示解压缩该压缩文件。解压后源文件会消失。 gunzip filename.gz 解压文件为源文件，不保留压缩文件 gzip 不支持压缩目录，压缩目录时会报错。 关于-#选项，平时很少用到，使用默认压缩级别就够了。 2.2. bzip2格式 bzip2 [-dz] filename 选项 说明 -z 压缩不加该选项也是表示压缩文件 -d 解压缩 说明： 该命令只有-z和-d两个常用选项。 压缩或解压后源文件会消失。 它的压缩级别有1~9，默认级别是9。 bzip2 不可以压缩目录，压缩目录会报错。 2.3. xz格式 xz [-dz] filename 选项 说明 -z 压缩不加该选项也是表示压缩文件 -d 解压缩 说明： 该命令常用的只有-z和-d两个常用选项。 压缩或解压后源文件会消失。 xz 不可以压缩目录，压缩目录会报错。 2.4. zip 和 unzipzip 压缩包非常常见，在Linux里，zip可以压缩目录和文件。压缩目录时，需要指定目录下的文件。 格式： zip filename.zip filename 把文件filename压缩为filename.zip，且保存源文件filename zip -r dir.zip dir 把目录dir压缩为dir.zip，原目录保存（注意，若是目录中有软连接会把链接的原文件也压缩） 示例如下：12345678# zip test.txt.zip test.txt adding: test.txt (deflated 63%) zip test.zip test/* adding: test/1 (stored 0%) adding: test/2 (stored 0%) adding: test/3 (stored 0%) adding: test/test.txt (deflated 63%) adding: test/test.txt.zip (stored 0%) 说明： zip后面先跟目标文件名，即压缩后的自定义压缩包名，然后跟要压缩的文件或目录。 若CentOS没有这个命令，要安装一下：yum install -y zip unzip 当目录下还有二级目录甚至更多级目录是，zip命令仅仅是把二级目录本身压缩而已。如果想要一并压缩二级下的目录，必须加上-r选项，这样就不用加/*了。如下所示：1234567891011# zip -r tests.zip test/ adding: test/ (stored 0%) adding: test/test.txt (deflated 63%) adding: test/test.txt.zip (stored 0%) adding: test/1 (stored 0%) adding: test/2 (stored 0%) adding: test/3 (stored 0%) adding: test/4/ (stored 0%) adding: test/4/5 (stored 0%) adding: test/4/6 (stored 0%) adding: test/4/7 (stored 0%) unzip 是用于解压缩.zip格式文件的，unzip 1.txt.zip解压file.zip文件到当前目录下，且原压缩文件file.zip不会消失。 选项 说明 -l 可查看文件的清单 -d dir 解压到指定目录下 2.5. 查看压缩文件的命令 命令 作用 zcat 查看gzip压缩的文件的内容 bzcat 查看bzip2压缩的文件内容 2.6. tar tar 是一个打包工具，可以把目录打包成一个文件，它把所有文件整合成一个大文件，方便复制或者移动。 格式 tar [-zjxcvfpP] filename.tar 要打包的文件1 要打包的文件2 …… 常用选项 选项说明 -z 同时用gzip压缩 -j 同时用bzip2压缩 -J 同时用xz压缩 -x 解包或解压缩 -t 查看tar包里的文件 -c 建立一个tar包或者压缩文件包 -v 可视化 -f filename 表示压缩后的文件名为filename，或者解压文件filename需要注意的是，如果是多个参数组合的情况，要把-f选项写到最后面） -C dir 在解压解包时使用，解压到指定目录下 -u newfile 在之前的包的基础上更新新的文件到包里 -p小写 使用源文件的属性，压缩前什么属性压缩后还是什么属性（不常用） -P大写 可以使用绝对路径（不常用） –exclude filename 在打包或压缩时，不要将filename文件包括在内。支持通配符。 如：--exclude &quot;*.sh&quot; 将*.sh文件过滤掉不打包（不常用）（不常用） 一些常用的例子： 打包 ： tar -cvf test.tar test1 test2 解包 ： tar -xvf test.tar 打包时排除 ： tar -cvf test.tar --exclude 1.txt test3 查看包或压缩包的文件列表 ： tar -tf test.tar或test.tar.gz等 打包的同时使用gzip压缩 打包压缩： tar -zcvf test.tar.gz test 解包解压缩： tar -zxvf test.tar.gz 打包的同时使用bzip2压缩 打包压缩： tar -jcvf test.tar.bz2 test 解包解压缩： tar -jxvf test.tar.bz2 打包的同时使用xz压缩 打包压缩： tar -Jcvf test.tar.xz test 解包解压缩： tar -Jxvf test.tar.xz OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux磁盘管理技术]]></title>
    <url>%2F2017%2F08%2F31%2FLinux%2F008.%20Linux%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[GO 这一章学习：如何分区、如何格式化、如何挂载、如何卸载。 0. MBR和GPT0.1. MBRMBR全称Master Boot Record，中文叫做“主引导记录”，又叫做“主引导扇区”，是计算机开机后访问硬盘时所必须要读取的首个扇区，它在硬盘上的地址为0柱面0磁道1扇区。MBR 的主要作用是检查分区状态，寻找活动分区，并将控制权交给活动分区引导记录DBR，再由分区引导程序加载操作系统。标准MBR的结构如下： 主引导记录最开头是第一阶段引导代码。其中的硬盘引导程序的主要作用是检查分区表是否正确并且在系统硬件完成自检以后将控制权交给硬盘上的引导程序（如GNU GRUB）。MBR是由分区程序所产生的，它不依赖任何操作系统，而且硬盘引导程序也是可以改变的，从而能够实现多系统引导。 硬盘分区表占据主引导扇区的64个字节(偏移0x01BE至偏移0x01FD)，可以对四个分区的信息进行描述，其中每个分区的信息占据16个字节。具体每个字节的定义可以参见硬盘分区结构信息： 结束标志字0x55和0xAA是主引导扇区的最后两个字节，是检验主引导记录是否有效的标志。 0.2. GPT0.2.1. GPT概述全局唯一标识分区表（GUID Partition Table，缩写：GPT）是一个实体硬盘的分区结构。它是可扩展固件接口标准的一部分，用来替代BIOS中的主引导记录分区表。 传统的主启动记录 (MBR) 磁盘分区支持最大卷为 2.2 TB (terabytes) ，每个磁盘最多有 4 个主分区（或 3 个主分区，1 个扩展分区和无限制的逻辑驱动器）。 与MBR 分区方法相比，GPT 具有更多的优点，因为它允许每个磁盘有多达 128 个分区，支持高达 18 千兆兆字节 (exabytes，1EB=10^6TB) 的卷大小，允许将主磁盘分区表和备份磁盘分区表用于冗余，还支持唯一的磁盘和分区 ID (GUID)。 与 MBR 分区的磁盘不同，GPT的分区信息是在分区中，而不象MBR一样在主引导扇区。为保护GPT不受MBR类磁盘管理软件的危害，GPT在主引导扇区建立了一 个保护分区 (Protective MBR)的MBR分区表，这种分区的类型标识为0xEE，这个保护分区的大小在Windows下为128MB，Mac OS X下为200MB，在Window磁盘管理器里名为GPT保护分区，可让MBR类磁盘管理软件把GPT看成一个未知格式的分区，而不是错误地当成一个未分 区的磁盘。另外，GPT 分区磁盘有多余的主要及备份分区表来提高分区数据结构的完整性。 在MBR硬盘中，分区信息直接存储于主引导记录(MBR)中（主引导记录中还存储着系统的引导程序）。但在GPT硬盘中，分区表的位置信息储存在GPT头中。但出于兼容性考虑，硬盘的第一个扇区仍然用作MBR，之后才是GPT头。跟现代的MBR一样，GPT也使用逻辑区块地址（LBA）取代了早期的CHS寻址方式。传统MBR信息存储于LBA 0，GPT头存储于LBA 1，接下来才是分区表本身。64位Windows操作系统使用16,384字节（或32扇区）作为GPT分区表，接下来的LBA 34是硬盘上第一个分区的开始。为了减少分区表损坏的风险，GPT在硬盘最后保存了一份分区表的副本。与主启动记录 (MBR) 分区方法相比，GPT 具有更多的优点，因为它允许每个磁盘有多达 128 个分区，支持高达18 千兆兆字节的卷大小，允许将主磁盘分区表和备份磁盘分区表用于冗余，还支持唯一的磁盘和分区ID(GUID)。 0.2.2. GPT结构 0.2.3. 传统MBR（LBA 0）在GPT分区表的最开头，处于兼容性考虑仍然存储了一份传统的MBR，用来防止不支持GPT的硬盘管理工具错误识别并破坏硬盘中的数据，这个MBR也叫做保护MBR。在支持从GPT启动的操作系统中，这里也用于存储第一阶段的启动代码。在这个MBR中，只有一个标识为0xEE的分区，以此来表示这块硬盘使用GPT分区表。不能识别GPT硬盘的操作系统通常会识别出一个未知类型的分区，并且拒绝对硬盘进行操作，除非用户特别要求删除这个分区。这就避免了意外删除分区的危险。另外，能够识别GPT分区表的操作系统会检查保护MBR中的分区表，如果分区类型不是0xEE或者MBR分区表中有多个项，也会拒绝对硬盘进行操作。 在使用MBR/GPT混合分区表的硬盘中，这部分存储了GPT分区表的一部分分区（通常是前四个分区），可以使不支持从GPT启动的操作系统从这个MBR启动，启动后只能操作MBR分区表中的分区。如Boot Camp就是使用这种方式启动Windows。 0.2.4. 分区表头（LBA 1）分区表头定义了硬盘的可用空间以及组成分区表的项的大小和数量。在使用64位Windows Server 2003的机器上，最多可以创建128个分区，即分区表中保留了128个项，其中每个都是128字节。（EFI标准要求分区表最小要有16,384字节，即128个分区项的大小） 分区表头还记录了这块硬盘的GUID，记录了分区表头本身的位置和大小（位置总是在LBA 1）以及备份分区表头和分区表的位置和大小（在硬盘的最后）。它还储存着它本身和分区表的CRC32校验。固件、引导程序和操作系统在启动时可以根据这个校验值来判断分区表是否出错，如果出错了，可以使用软件从硬盘最后的备份GPT中恢复整个分区表，如果备份GPT也校验错误，硬盘将不可使用。所以GPT硬盘的分区表不可以直接使用16进制编辑器修改。 分区表头的格式如下： 起始字节 所占长度 内容 0 8字节 签名（”EFI PART”, 45 46 49 20 50 41 52 54） 8 4字节 修订（在1.0版中，值是 00 00 01 00） 12 4字节 分区表头的大小（单位是字节，通常是92字节，即 5C 00 00 00） 16 4字节 分区表头（第0－91字节）的CRC32 校验，在计算时，把这个字段作为0处理，需要计算出分区串行的CRC32校验后再计算本字段 20 4字节 保留，必须是0 24 8字节 当前LBA（这个分区表头的位置） 32 8字节 备份LBA（另一个分区表头的位置） 40 8字节 第一个可用于分区的LBA（主分区表的最后一个LBA+1） 48 8字节 最后一个可用于分区的LBA（备份分区表的第一个LBA-1） 56 16字节 硬盘GUID（在类UNIX 系统中也叫UUID） 72 8字节 分区表项的起始LBA（在主分区表中是2） 80 4字节 分区表项的数量 84 4字节 一个分区表项的大小（通常是128） 88 4字节 分区串行的CRC32校验 92 * 保留，剩余的字节必须是0（对于512字节LBA的硬盘即是420字节） 主分区表和备份分区表的头分别位于硬盘的第二个扇区（LBA 1）以及硬盘的最后一个扇区。备份分区表头中的信息是关于备份分区表的。 0.2.5. 分区表项（LBA 2-33）GPT分区表使用简单而直接的方式表示分区。一个分区表项的前16字节是分区类型GUID。例如，EFI系统分区的GUID类型是{C12A7328-F81F-11D2-BA4B-00A0C93EC93B}。接下来的16字节是该分区唯一的GUID（这个GUID指的是该分区本身，而之前的GUID指的是该分区的类型）。再接下来是分区起始和末尾的64位LBA编号，以及分区的名字和属性。 GPT分区表项的格式如下： 起始字节 所占长度 内容 0 16字节 分区类型GUID 16 16字节 分区GUID 32 8字节 其实LBA（小端序） 40 8字节 末尾LBA 48 8字节 属性标签（如：60表示“只读”） 56 72字节 分区名（可以包括36个UTF-16（小端序）字符） 1. 查看磁盘或目录的容量监控磁盘的使用率在日常的监控工作中是必须要做的。 1.1. df df （disk filesystem）用于查看已挂载磁盘的总容量、使用容量、剩余容量等。 常用选项 选项说明 不加选项 默认以KB为单位显示 -i 查看inodes的使用状况，如已使用100%，即使磁盘空间有富余，也会提示磁盘空间已满 -h 以合适的单位显示 -k 以KB为单位显示（默认） -m 以MB为单位显示 -T 查看每个分区的文件系统类型 示例：1234567891011121314151617181920# df文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda3 16561152 3760600 12800552 23% /devtmpfs 1006276 0 1006276 0% /devtmpfs 1016076 0 1016076 0% /dev/shmtmpfs 1016076 8796 1007280 1% /runtmpfs 1016076 0 1016076 0% /sys/fs/cgroup/dev/sdb5 991512 2516 921412 1% /newdir/dev/sda1 201380 95320 106060 48% /boottmpfs 203216 0 203216 0% /run/user/0df -h文件系统 容量 已用 可用 已用% 挂载点/dev/sda3 16G 3.6G 13G 23% /devtmpfs 983M 0 983M 0% /devtmpfs 993M 0 993M 0% /dev/shmtmpfs 993M 8.6M 984M 1% /runtmpfs 993M 0 993M 0% /sys/fs/cgroup/dev/sdb5 969M 2.5M 900M 1% /newdir/dev/sda1 197M 94M 104M 48% /boottmpfs 199M 0 199M 0% /run/user/0 该命令所显示的内容中，每列所代表的意义如下： 列数 意义 第一列 分区的名字 第二列 该分区的总容量 第三列 已使用容量 第四列 可用的剩余容量 第五列 使用容量的百分比（若该数值达到90%以上，就需要进行管理了） 第六列 分区的挂载点 该命令所显示的内容中，挂载点的说明： /dev和//dev/shm 为内存分区，默认大小为内存的1/2，如果我们把文件存在这个分区下，相当于存在了内存中，好处是读写速度非常快，坏处是系统重启时文件会丢失。 /run、/sys/fs/cgroup等分区都是tmpfs，跟/dev/shm类似，为临时文件系统，最好不要碰它们 1.2. du du （disk useage）用来查看某个目录或文件所占空间的大小。 格式 du [-abckmsh] [文件或目录名] 常用选项 选项说明 不加参数 只会列出目录（包含子目录）的大小。默认单位为KB -a 表示全部文件和目录的大小都列出来 -b 以B为单位输出 -k 以KB为单位输出 -m 以MB为单位输出 -h 自动以合适的单位输出 -c 表示最后加总（不常用） -s 只列出总和（用的最多） 说明：这个命令用的最多的情况是这种形式： du -sh filename 2. 磁盘的分区2.1. fdiskfdisk 是Linux下硬盘的分区工具，是一个非常实用的命令，但是fdisk只能划分小于2TB的分区。大于2T的用parted命令。注意，分区是非常危险的操作，操作失误很可能会把数据弄丢，所以一定要高度警惕！ 格式 fdisk [-l] 设备名称 说明： fdisk 的选项只有-l这一个。 选项-l的后面不加设备名称，会直接列出系统中所有的磁盘设备以及分区表。 选项-l的后面加上设备名称，则会列出该设备的分区表。 fdisk -l 显示系统能够识别到的硬盘有哪些，每个硬盘的分区有哪些（类似 /dev/sda，/dev/sdb 等，和/dev/sda1，/dev/sda2等，大于2T用GPT分区表）。示例如下： 1234567891011121314151617181920212223242526272829303132fdisk -l磁盘 /dev/sdb：5368 MB, 5368709120 字节，10485760 个扇区Units = 扇区 of 1 * 512 = 512 bytes扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x8de7a46e 设备 Boot Start End Blocks Id System/dev/sdb1 2048 10485759 5241856 5 Extended/dev/sdb5 4096 2052095 1024000 83 Linux/dev/sdb6 2054144 4102143 1024000 83 Linux磁盘 /dev/sda：21.5 GB, 21474836480 字节，41943040 个扇区Units = 扇区 of 1 * 512 = 512 bytes扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x000f3f8d 设备 Boot Start End Blocks Id System/dev/sda1 * 2048 411647 204800 83 Linux/dev/sda2 411648 8800255 4194304 82 Linux swap / Solaris/dev/sda3 8800256 41943039 16571392 83 Linux# fdisk -l /dev/sda1磁盘 /dev/sda1：209 MB, 209715200 字节，409600 个扇区Units = 扇区 of 1 * 512 = 512 bytes扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节 fdisk 如果不加-l选项，则会进入另一个模式，在该模式下，可以对磁盘进行分区操作。示例如下： 123456789101112131415161718192021222324252627fdisk /dev/sdb欢迎使用 fdisk (util-linux 2.23.2)。更改将停留在内存中，直到您决定将更改写入磁盘。使用写入命令前请三思。命令(输入 m 获取帮助)：m命令操作 a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition g create a new empty GPT partition table G create an IRIX (SGI) partition table l list known partition types m print this menu n add a new partition o create a new empty DOS partition table p print the partition table q quit without saving changes s create a new empty Sun disklabel t change a partition's system id u change display/entry units v verify the partition table w write table to disk and exit x extra functionality (experts only)命令(输入 m 获取帮助)： 进入分区模式后，可以输入m获取命令列表的说明和帮助。其常用的操作命令如下： 命令 功能 m 获取命令列表和帮助 p 打印当前磁盘的分区情况 n 新建一个新的分区 w 保存分区 q 表示退出，若未进行保存，则会未保存退出，在此之前的一切分区工作都失效 d 删除一个分区 l 已知的分区类型列表 在工作中，常使用的就是给一个盘分一个主分区。 2.2. parted2.2.1. 使用方法parted命令是由GNU组织开发的一款功能强大的磁盘分区和分区大小调整工具，与fidisk不通，它支持调整分区的大小。作为一种设计用于Linux的工具，它没有构建成处理与fdisk关联的多种分区类型，但是，它可以处理最常见的分区格式，包括：ext2、ext3、XFS、fat16、fat32、NTFS、ReiserFS、JFS、UFS、HFS以及Linux交换分区。 语法：parted [选项] [参数] 常用选项如下： 选项 意义 -h –help，显示帮助信息 -l –list，列出所有设备的分区信息 -i –interactive，交互式模式 -s –script，脚本模式，不提示用户 -v –version，显示版本号 参数说明如下： 磁盘设备 ：指定要分区的硬盘所对应的设备文件 操作命令 ：要执行的parted命令 操作命令如下： 操作命令 意义 cp [FROM-DEVICE] FROM-MINOR TO-MINOR 将文件系统复制到另一个分区 help [COMMAND] 打印通用求助信息，或关于COMMAND的信息 mklabel 标签类型 创建新的磁盘标签（分区表） mkfs MINOR 文件系统类型 在 MINOR 创建类型为“文件系统类型”的文件系统 mkpart 分区类型 [文件系统类型] 起始点 终止点 创建一个分区 mkpartfs 分区类型 文件系统类型 起始点 终止点 创建一个带有文件系统的分区 move MINOR 起始点 终止点 移动编号为 MINOR 的分区 name MINOR 名称 将编号为 MINOR 的分区命名为“名称” print [free或MINOR或all] 打印分区表，或者分区 quit 退出程序 rescue 起始点 终止点 挽救临近“起始点”、“终止点”的遗失的分区 resize MINOR 起始点 终止点 改变位于编号为 MINOR 的分区中文件系统的大小 rm MINOR 删除编号为 MINOR 的分区 select 设备 选择要编辑的设备 set MINOR 标志 状态 改变编号为 MINOR 的分区的标志（对于PC常用的msdoc分区表来说，分区标记FLAG可有如下值：boot(引导)、hidden(隐藏)、raid(软RAID磁盘阵)、lvm(逻辑卷)、lba(LBA,Logic Block Addressing模式)）。状态的取值是: on或off 2.2.2. 操作实例1、选择分区硬盘 首先类似fdisk一样，先选择要分区的硬盘，此处为/dev/hdd。（(parted)表示在parted中输入的命令，其它为自动打印的信息）：1234[root@10.10.90.97 ~]# parted /dev/hddGNU Parted 1.8.1Using /dev/hddWelcome to GNU Parted! Type 'help' to view a list of commands. 2、创建分区 选择了/dev/hdd作为我们操作的磁盘，接下来需要创建一个分区表（在parted中可以使用help命令打印帮助信息）：12(parted) mklabelNew disk label type? gpt (我们要正确分区大于2TB的磁盘，应该使用gpt方式的分区表，输入gpt后回车) 3、完成分区操作 创建好分区表以后，接下来就可以进行分区操作了，执行mkpart命令，分别输入分区名称、文件系统和分区的起止位置：12345(parted) mkpartPartition name? []? dp1File system type? [ext2]? ext3Start? 0 （可以用百分比表示，比如Start? 0% , End? 50%）End? 500GB 4、验证分区信息 分好区后可以使用print命令打印分区信息，下面是一个print的样例：1234567(parted) printModel: VBOX HARDDISK (ide)Disk /dev/hdd: 2199GBSector size (logical/physical): 512B/512BPartition Table: gptNumber Start End Size File system Name Flags1 17.4kB 500GB 500GB dp1 5、删除分区示例 如果分区错了，可以使用rm命令删除分区，比如我们要删除上面的分区，然后打印删除后的结果：1234567(parted)rm 1 #rm后面使用分区的号码，就是用print打印出来的Number(parted) printModel: VBOX HARDDISK (ide)Disk /dev/hdd: 2199GBSector size (logical/physical): 512B/512BPartition Table: gptNumber Start End Size File system Name Flags 6、完整示例 按照上面的方法把整个硬盘都分好区，下面是一个分完后的样例：123456789101112131415161718(parted) mkpartPartition name? []? dp1File system type? [ext2]? ext3Start? 0End? 500GB(parted) mkpartPartition name? []? dp2File system type? [ext2]? ext3Start? 500GBEnd? 2199GB(parted) printModel: VBOX HARDDISK (ide)Disk /dev/hdd: 2199GBSector size (logical/physical): 512B/512BPartition Table: gptNumber Start End Size File system Name Flags1 17.4kB 500GB 500GB dp12 500GB 2199GB 1699GB dp2 7、格式化和挂载操作 完成以后我们可以使用quit命令退出parted并使用系统的mkfs命令对分区进行格式化了。123456789101112[root@10.10.90.97 ~]# fdisk -lWARNING: GPT (GUID Partition Table) detected on '/dev/hdd'! The util fdisk doesn't support GPT. Use GNU Parted.Disk /dev/hdd: 2199.0 GB, 2199022206976 bytes255 heads, 63 sectors/track, 267349 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesDevice Boot Start End Blocks Id System/dev/hdd1 1 267350 2147482623+ ee EFI GPT[root@10.10.90.97 ~]# mkfs.ext3 /dev/hdd1[root@10.10.90.97 ~]# mkfs.ext3 /dev/hdd2[root@10.10.90.97 ~]# mkdir /dp1 /dp2[root@10.10.90.97 ~]# mount /dev/hdd1 /dp1[root@10.10.90.97 ~]# mount /dev/hdd2 /dp2 3. 格式化磁盘分区磁盘分区后，还需要对其进行格式化操作才能使用。格式化就是为分区配置相应的文件系统。Win系统用Fat32和NTFS文件系统，而Linux用ext3、ext4或xfs文件系统在 CentOS 7 系统中，是以XFS作为默认的文件系统的，但是我们依旧可以给它指定ext3和ext4格式。 cat /etc/filesystems 查看系统支持哪些文件系统 3.1. mke2fs mke2fs 用于给磁盘进行格式化。它和这几个工具具有相同的功能： mkfs.ext2 mkfs.ext3 mkfs.ext4但需要注意的是，mke2fs并不支持把分区格式化为XFS系统，而只能使用mkfs.xfs。 mke2fs 的常用选项如下： 常用选项 选项说明 -b 分区时设定每个数据区块占用的空间大小。目前，每个数据块支持1024B、2048B和4096B。（设定为别的值可能会不能用） -I 设定inode的大小 -i 设定块和inode数量的比例，比如块大小为4096，则后面加上8192，格式化后inode的数量是块数量的两倍 -N 设定inode的数量。有时默认的inode数不够用，所以要自定义inode的数量 -c 在格式化前先检测一下磁盘是否有问题，加上这个选项后，运行速度会非常慢 -L 预设该分区的标签（Label） -j 建立ext3格式的分区。如果使用mkfs.ext3命令，就不用加这个选项了 -t 指定文件系统的类型，可以是ext2、ext3和ext4 -m 1 （表示百分之一对super user的保留，最小也支持0.1）格式化时，指定预留给管理员的磁盘比例，是一个百分比，只针对 mke2fs 命令 示例如下：123456789101112131415161718192021# mke2fs -t ext4 /dev/sdb5mke2fs 1.42.9 (28-Dec-2013)文件系统标签=OS type: Linux块大小=4096 (log=2)分块大小=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks64000 inodes, 256000 blocks12800 blocks (5.00%) reserved for the super user第一个数据块=0Maximum filesystem blocks=2621440008 block groups32768 blocks per group, 32768 fragments per group8000 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376Allocating group tables: 完成正在写入inode表: 完成Creating journal (4096 blocks): 完成Writing superblocks and filesystem accounting information: 完成 使用mkfs.xfs把分区格式化为XFS类型，示例如下：12345678910# mkfs.xfs /dev/sdb7meta-data=/dev/sdb7 isize=512 agcount=4, agsize=64000 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0data = bsize=4096 blocks=256000, imaxpct=25 = sunit=0 swidth=0 blksnaming =version 2 bsize=4096 ascii-ci=0 ftype=1log =internal log bsize=4096 blocks=855, version=2 = sectsz=512 sunit=0 blks, lazy-count=1realtime =none extsz=4096 blocks=0, rtextents=0 可以使用-L选项来指定标签。标签会在挂载磁盘的时候使用，也可以写入配置文件，这样会很可靠。示例如下：123456789101112131415161718192021# mke2fs -L TEST -t ext4 /dev/sdb5mke2fs 1.42.9 (28-Dec-2013)文件系统标签=TESTOS type: Linux块大小=4096 (log=2)分块大小=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks64000 inodes, 256000 blocks12800 blocks (5.00%) reserved for the super user第一个数据块=0Maximum filesystem blocks=2621440008 block groups32768 blocks per group, 32768 fragments per group8000 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376Allocating group tables: 完成正在写入inode表: 完成Creating journal (4096 blocks): 完成Writing superblocks and filesystem accounting information: 完成 3.2. e2label e2label 用于查看或修改分区的标签，它只支持ext格式的文件系统，而不支持XFS文件系统。 示例如下：12345# e2label /dev/sdb5TEST# e2label /dev/sdb5 TEST1# e2label /dev/sdb5TEST1 4. 挂载和卸载磁盘分区格式化完成后，如果想要使用这些分区，就需要对它们进行挂载操作。格式化后的磁盘其实是一个块文件，类型为b。 在挂载某个分区之前，需要先建立一个挂载点，这个挂载点是以目录的形式出现的。一旦把某个分区挂载到这个挂载点（目录）下，要再往这个目录写数据时，就都会写到该分区。所以，在挂载该分区前，挂载点（目录）最好是个空目录。其实目录不为空并不影响所挂载分区的使用，但一旦挂载上了，该目录下以前的东西就看不到了（数据并没有丢失），除非卸载该分区。 4.1. /etc/fstab 配置文件这个文件的内容就是系统启动时需要挂载的各个分区。我们可以在该文件里增加系统启动时需自动挂载的分区。文件内容如下所示：12345678910111213# cat /etc/fstab## /etc/fstab# Created by anaconda on Tue Aug 15 00:19:30 2017## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=1d54c61a-2320-4f2d-92d3-0bfbcebbf797 / xfs defaults 0 0UUID=9f03989b-dc6d-4d48-99e1-a85984422d6c /boot xfs defaults 0 0UUID=4ad00c9e-66f1-42c4-99b3-d9cd326b586a swap swap defaults 0 0LABEL=TEST123 /newdir ext4 defaul 配置文件中各列的意义如下： 列数 意义 1 分区的标识，可以是分区的Label，分区的UUID，以及分区名（如/dev/sda1） 2 挂载点 3 分区的文件系统类型 4 mount的一些挂载参数。一般情况下，直接写defaults即可 5 是否被dump备份。1表示备份，0表示不备份 6 开机时是否自检磁盘。1和2都表示检测，0表示不检测。自检是，1比2优先级高，所以先检测1，再检测2。如果有多个分区需要开机检测，就都设置成2，1检测玩后会同时检测2.在CentOS7里，所有分区的该值都设置为0 下面是配置文件中第4列的常用选项： 选项 意义 default 表示按照大多数永久文件系统的默认值设置挂载定义，它包含了：rw、suid、dev、exec、auto、nouser和async async和sync async表示磁盘和内存不同步。系统每隔一段时间就会把内存数据写入磁盘中，而sync则会时时同步内存和磁盘中的数据 auto和noauto 表示开机自动挂载或是不自动挂载 ro 按只读权限挂载 rw 按可读可写权限挂载 exec和noexec 表示允许或不允许可执行文件执行，但千万不要把根分区挂载为noexec，否则将无法只用系统，甚至连mount命令都无法使用 user和nouser 表示允许或不允许root外的其他用户挂载分区。为了安全，请用nouser suid和nosuid 表示允许或不允许分区有suid属性，一般设置为nosuid usrquota 表示启动用户的磁盘配额模式。磁盘配额会针对用户限定他们使用的磁盘额度 grquota 表示启动群组的磁盘配额模式 4.2. mount mount 用于挂载分区。 直接运行 mount，会显示一大推信息，可在其中查看当前系统已挂载的所有分区、分区文件系统的类型、挂载点及一些选项等信息。如果想知道某个已挂载分区的文件系统类型，直接用mount命令查看即可。（查看未挂载的分区，可以使用后面所讲的blkid命令） 挂载操作，可以用分区名（如/dev/sdb5）、也可以用分区的Label和UUID的方式进行（更可靠）。示例如下所示：123# mount /dev/sdb5 /newdir或# mount LABEL=TEST /newdir mount的常用选项如下： 常用选项 选项说明 -a 会把 /etc/fstab 配置文件中出现的所有磁盘分区挂载上 -t 用来指定挂载的分区类型，默认不指定，会自动识别 -o 用来指定挂载的分区有哪些特性，即上面/etc/fstab配置文件中第4列的哪些（该选项常用）。例如mount -oremount,ro /dev/sdb5 /db5 重新挂载该分区为只读。mount -o loop \*.iso 挂载点 挂载一个镜像文件 –bind 源目录 目标目录 挂载一个目录到另一个目录 建议：在进行分区的挂载操作时，最好用分区的LABEL或UUID挂载。 4.3. blkid blkid 用来获取全部磁盘分区的UUID。如果分区在格式化时指定了Label，该命令也会显示LABEL值、文件系统的类型。 示例如下：12345678# blkid/dev/sdb5: LABEL="TEST1" UUID="d2c3e579-dc31-4121-95b8-789e41fbdd96" TYPE="ext4"/dev/sdb6: UUID="e9d355cd-d339-4bfe-ab4e-b6ed0a766964" TYPE="xfs"/dev/sdb7: UUID="ea87ed23-218c-4fed-a600-823c24ac35b2" TYPE="xfs"/dev/sda1: UUID="9f03989b-dc6d-4d48-99e1-a85984422d6c" TYPE="xfs"/dev/sda2: UUID="4ad00c9e-66f1-42c4-99b3-d9cd326b586a" TYPE="swap"/dev/sda3: UUID="1d54c61a-2320-4f2d-92d3-0bfbcebbf797" TYPE="xfs"/dev/sr0: UUID="2016-12-05-13-52-39-00" LABEL="CentOS 7 x86_64" TYPE="iso9660" PTTYPE="dos" 这个命令后面也可以指定查询哪个分区：12# blkid /dev/sdb5/dev/sdb5: LABEL="TEST1" UUID="d2c3e579-dc31-4121-95b8-789e41fbdd96" TYPE="ext4" 查询到某个分区的UUID后，如何使用？用法如下：mount UUID=&quot;d2c3e579-dc31-4121-95b8-789e41fbdd96&quot; /newdir 4.4. umount umount 用于卸载分区。 格式 umount 挂载点/分区名 。注意，卸载时不能跟LABEL和UUID。 有时，umount的-l选项很有用。当当前目录在即将要卸载的分区内时，会遇到不能卸载的情况。解决这个问题的方法有两个，一个是从该分区切换到别的分区，另一个就是加上-l这个选项。 4.5. 让某个分区在开机后自动挂载有两个方法： 在/etc/fstab文件中配置 在/etc/rc.d/rc.local文件中，添加一行挂载该分区的命令（注意，命令用绝对路径的写法，且把该文件的权限设置一下： chmod a+x /etc/rc.d/rc.local。因为CentOS7中该文件默认没有执行权限） 一个小建议，那就是挂载磁盘分区的时候，尽量使用 UUID 或者 LABEL 这两种方法。 5. 建立一个Swap文件增加虚拟内存首先介绍一下dd命令。 5.1. dd dd命令用于创建指定大小的文件。 格式 dd if=指定源 of=指定目标文件 bs=指定块大小 count=指定块数量 说明： 用if指定源（一般是用/dev/zero，它是Unix系统特有的一个文件，它可以源源不断地提供”0”） 用of指定目标文件，这里写上新建文件的名字 bs乘以count的得数就是即将创建的文件的大小 5.2. 增加虚拟内存的实现方法增加虚拟磁盘的思路是：建立swapfile–&gt;格式化为swap格式–&gt;启用该虚拟磁盘。 具体操作如下： 建立swapfile ： dd if=/dev/zero of=/tmp/newdisk bs=1M count=1024 将其格式化为swap格式： mkswap -f /tmp/newdisk 挂载使用： swapon /tmp/newdisk 关闭临时swap： swapoff /tmp/newdisk 6. 补充的内容6.2. LVM 好处是扩展性好 坏处是数据损坏时可恢复性很小，因此LVM在企业中用的很少，初学时可以不学了 6.3. fsck fsck 用于修复磁盘，但有时会把磁盘中的数据弄丢，因此不常用。 格式 fsck -y 分区名 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux用户与用户组管理技术]]></title>
    <url>%2F2017%2F08%2F31%2FLinux%2F007.%20Linux%E7%94%A8%E6%88%B7%E4%B8%8E%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[GO 这部分知识在日常工作中用的并不多，但是这些都是属于基础知识，也必须要掌握。 1. 认识 /etc/passwd 和 /etc/shadow这两个文件是Linux系统中最重要的文件之一。注意，Linux系统关于像这两个与用户和组有关的文件，都会在相应的目录下面自动备份成相应的名字后面加-，如：passwd- - /etc/passwd 解说每个用户都有自己的一行配置。查看该文件的内容：1234567891011# cat /etc/passwd | headroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologin 由内容可知，/etc/passwd 由”:”分割成7个字段，每个字段的具体含义如下： 字段 含义 1 用户名 2 账号的口令标识 3 用户标识号，UID（0-4294967294=2^32-2） 4 组标识号，GID 5 注释说明 6 家目录 7 可用shell 说明： 用户名可以是大小写字母、数字、减号（不能出现在首位）、点或下划线，其它字符不合法。虽然用户名中可以出现点，但不建议使用，尤其是首位。另外，减号也不建议使用，容易造成混淆。 口令标识在该文件里是一个x。早期的Unix系统口令确实存放在这里，但基于安全因素，后来就将其存放在 /etc/shadow 中了，这里只用了一个x代替。 系统是通过UID来识别用户身份的。root的UID为0，如果我们创建一个用户user，并把其UID设置为0，则user和root会被系统视为同一个用户。UID的取值范围是0~65535（但实际上已经可以支持到4294967294）。CentOS 7 的普通用户标识号从1000开始。 组标识号的这个字段对应着 /etc/group 中的一条记录，其是 /etc/group 和 /etc/passwd 基本类似。 注释说明没有实际意义，只是用来备注一些关于该用户的信息，例如电话、地址等。 家目录的字段，就是说当用户登陆系统后所处的就是他自己的家目录。可以修改该字段，来自定义家目录。 允许用户登陆的shell就是在此字段来设置的。例如，/sbin/nologin 表示不允许用户登陆。这个字段的默认值是 /bin/bash - /etc/shadow 解说查看该文件的内容：1234567891011# cat /etc/shadow | headroot:$6$SlsvE2F09ZCOaE2x$I71HiFKIJ1V349nJus7X8qYfryfXz9hWPcnkEHK1g88X9aXANQV2WjPXatvPcXWH4qTmcfh19.YrSEUJjWhw8/::0:99999:7:::bin:*:17110:0:99999:7:::daemon:*:17110:0:99999:7:::adm:*:17110:0:99999:7:::lp:*:17110:0:99999:7:::sync:*:17110:0:99999:7:::shutdown:*:17110:0:99999:7:::halt:*:17110:0:99999:7:::mail:*:17110:0:99999:7:::operator:*:17110:0:99999:7::: 由内容可知，/etc/shadow 由”:”分割成9个字段，每个字段的具体含义如下： 字段 含义 1 用户名，与/etc/passwd对应 2 用户的真正的密码。这个密码已经加密。 3 上次更改密码的时间戳。这个数字以1970.1.1和上次更改密码的日期为基准计算而来。 4 表示要过多少天才可以更改密码，默认0，表示不受限制 5 表示密码多少天后到期，即在多少天内必须更改密码。例如，这里设置成30，则30天内必须要更改一次密码；否则，将不能登陆系统。默认99999，可以理解为永远不需要改 6 表示密码到期前的警告期限。若这个值设置为7，则表示当7天后密码过期时，系统就发出警告，提醒用户他的密码将在7天后过期 7 表示账号的失效期限。如果这个值设置为3，则表示密码已经到期，然而用户并没有在密码到期前修改密码，那么再过3天，这个账号便失效，即锁定 8 表示该账号的生命周期。和第3个字段一样，这个周期是按距离1970.1.1多少天换算的。它的含义是，账号在这个日期前可以使用，到期后账号将作废。 9 作为保留用的，没有什么意义 说明： 密码，默认用SHA-512加密过的，且不可逆解密 $1 : MD5加密 $5 : SHA-256加密 $6 : SHA-512加密 !! : 表示用户未设置密码 : 表示用户被锁定 2. 用户和用户组管理下面的命令是用来创建、删除用户和组的，以及更改其属性的。 - groupadd groupadd 用来创建用户组 格式 groupadd [-g GID] groupname 相关的配置文件为 /etc/group 和 /etc/gshadow 示例如下：123# groupadd greptest1# tail -1 /etc/groupgreptest1:x:1008: 如果不加-g选项，则按照系统默认的GID创建组。跟UID一样，GID也是从1000开始的。我们也可以按如下操作自定义GID：1234# groupadd -g 1010 grouptest2# tail -2 /etc/groupgreptest1:x:1008:grouptest2:x:1010: - groupdel groupdel 用来删除用户组 格式 groupdel groupname 示例如下：1234# groupdel grouptest2# tail -2 /etc/groupmysql:x:1007:greptest1:x:1008: 命令groupdel没有特殊选项，但有一种情况不能删除组，如下所示：12# groupdel user1groupdel：不能移除用户“user1”的主组 上例中，user1组中包含user1用户，只有在该组中移除了user1用户后才可以删除该组。 - useradd useradd 用来添加用户。 格式 useradd [-u UID] [-g GID] [-d HOME] [-M] [-s] username 相关的配置文件为 /etc/passwd 和 /etc/shadow 选项 意义 -u 自定义UID -g 使新用户属于已经存在的某个组，后面可以跟GID，也可以跟组名 -G 该选项可跟多个组名，为用户指定多个扩展组 -d 自定义用户的家目录 -M 表示不建立家目录 -s 自定义Shell 说明： 如果useradd不加任何选项，直接跟用户名，则会创建一个跟用户名相同的组。 如果 -g 选项后面跟一个不存在的GID，则会报错，提示该组不存在。 加上 -M 选项后，则不建立用户家目录，但在/etc/passwd文件中仍然有这个字段，所以它的作用只是不创建那个目录。但是我们可以在之后为其创建家目录，并将其属主和属组的属性改为该用户：chmod -R user:user /home/user/；创建家目录后，还需要把相关的默认配置文件拷贝过去： cp -v /etc/skel/.b* /home/username 即可） - userdel userdel 用于删除用户。 格式 userdel [-r] username 说明： 选项-r的作用是，当删除用户时，一并删除该用户的家目录和邮件目录。 - usermod usermod 用于修改用户的属性 格式 usermod 选项 用户名 常用选项 含义 -s Shell类型 修改用户的Shell类型 -d 家目录绝对路径 修改用户家目录（只修改配置文件，并没有为其创建新的家目录） -u UID 修改用户的UID -g GID 为用户修改主组 -G 附加组名 为用户添加附加组 -L 锁定用户的账号 -U 解锁用户 - id id 用户名 用来查看用户的UID和GID - chfn chfn 用于修改用户的finger，即/etc/passwd文件中第五个字段所显示的信息。这个命令在工作中几乎用不到。 格式 chfn username 3. 用户密码管理密码对于一个用户来说是非常的关键，而密码管理也是系统管理员的一项非常重要的任务。 - 密码设置的规则创建用户后，默认是没有设置密码的，只有设置好密码后，才可以登陆系统。为了安全，在为用户创建密码时，应该遵循一些密码设置的规则，这些规则是为了密码的安全性而考虑的。 长度大于10个字符 密码中包含大小写字母、数字以及特殊字符等 不规则性（即不要出现常用的单词、类似于123456这样的密码等） 密码中不要带有名字、电话、生日等信息 - passwd passwd 用于设置密码。 格式 passwd [username] 说明： passwd后面不加用户名，则为自己设置密码 passwd后面加上用户名，则为该用户设置密码（以root身份） 注意：只有root才可以修改其他用户的密码，普通用户只能修改自己的密码 passwd --stdin username 即可实现只输入一次密码就更改成功的效果（这在脚本中经常使用） echo &quot;密码字符串&quot; | passwd --stdin username 即可实现将用户的密码直接设置为密码字符串 echo -e &quot;密码字符串第一遍\n密码字符串第二遍\n&quot; | passwd username 也可实现上面的功能 - mkpasswd mkpasswd 用于生成密码。 若是Linux没有这个命令，则需要安装一下expect： yum install -y expect。 常用选项 选项说明 -l 数字 指定生成密码的长度 -s 数字 指定特殊字符的个数 -d 数字 指定数字的个数 4. 用户身份切换- 查看当前用户 who am i 用于查看当前登陆的用户身份、登陆终端、登陆时间和来源IP whoami 用于查看当前登陆的用户的名字 w 用于查看当前登陆系统的用户的详细信息 - su su 用于切换用户身份。 格式 su [-] [username] 说明： su 的后面可以跟-，也可以不跟。加上-，即表示完整切换用户身份，即环境变量也切换过来 普通用户的su命令不加username，表示切换到root身份，需要输入root的密码才能成功切换 root用此命令切换身份时，不需要输入该用户的密码 su -c &quot;命令&quot; 用户名 用该用户的身份执行命令（这在以后写脚本的时候会用到） - sudo sudo 用于使用root身份执行一条命令。 用su可以切换用户身份，而且每个普通用户都能切换到root身份。如果某个用户不小心泄露了root的密码，那岂不是系统非常不安全？为了改进这个问题，Linux系统工程师设计了sudo这个命令。 使用sudo命令执行一个只有root才能执行的命令是可以办到的，但是需要输入密码。这个密码并不是root的密码，而是用户自己的密码。默认情况下，只有root用户能使用sudo命令，普通用户想要使用sudo，是需要root预先设定的。 可以使用visudo命令编辑相关的配置文件/etc/sudoers。如果没有visudo这个命令，则需安装yum install -y sudo 默认root支持sudo，是因为在配置文件/etc/sudoers中有一行 root ALL=(ALL) ALL。在改行下面添加一行 test ALL=(ALL) ALL，就可以让test用户拥有使用sudo的特权。这行配置的含义如下： 段数 含义 第一段 用户名，指定让哪个用户有sudo特权 第二段 ALL=（ALL），左边的ALL指的是所有的主机，右边的ALL指的是获取哪个用户的身份。第二段几乎都不用配置 第三段 设定可以使用sudo执行的命令有哪些 一个例子：1aming ALL=(root) NOPASSWD: /bin/ls, /bin/su 上面例子的意思是：不允许aming用户修改root的密码，且切换root用户时不需要输入root密码） 如果每增加一个用户就设置一行，这样太麻烦了，所以可以这样设置：把#wheel ALL=(ALL) ALL前面的#去掉，让这一行生效。它的意思是，wheel这个组的所有用户都拥有了使用sudo的权利。接下来，只要把需要设置sudo权限的用户加入到wheel这个组中即可。 - 关于sudo命令的一个很实用的案例需求：只允许使用普通账户登陆，并且普通用户登陆后，可以不用输入密码就能用sudo切换到root身份。 实现方法：1234567# visudo然后在文件的最后加入如下三行：User_Alias USER_SU = test,test1,amingCmnd_Alias SU = /usr/bin/suUSER_SU ALL=(ALL) NOPASSWD:SU 说明： 第一行设置了一个user的别名，USER_SU相当于test、test1和aming三个用户。可以写多个用户 第二行设定了一个命令别名，SU相当于/usr/bin/su，可以写多个命令 第三行就是类似于 root ALL=(ALL) ALL 这条配置语句。其中NOPASSWD的意思是：普通用户使用sudo时，不需要输入自己的密码 注意：这种配置方法有一个问题，就是普通用户可以使用su -命令切换到root账户，然后他可以再修改root的密码就能直接登陆root了。还有一个更好的办法，那就是下面的”不允许root远程登陆Linux” - 不允许root远程登陆Linux/etc/ssh/sshd_config 为sshd服务的配置文件，默认允许root用户通过ssh远程登陆Linux。要想不允许root用户远程登陆Linux，具体的操作方法为： 修改配置文件/etc/ssh/sshd_config 在配置文件中查找 #PermitRootLogin yes 并把它修改为 PermitRootLogin no 保存配置文件后，需要重启sshd服务：systemctl restart sshd.service 注意：这个方法只适用于通过ssh远程登陆Linux的情况。 补充一个小知识：/etc/ssh/sshd_config（ 为 sshd 服务的配置文件）中，将#UseDNS yes 改成 UseDNS no ，即可实现在远程登陆时的等待问题。 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件与目录管理技术]]></title>
    <url>%2F2017%2F08%2F26%2FLinux%2F006.%20Linux%E6%96%87%E4%BB%B6%E4%B8%8E%E7%9B%AE%E5%BD%95%E7%AE%A1%E7%90%86%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[GO 0. 几个基本概念- 绝对路径和相对路径 绝对路径：由根目录写起的路径。如：/usr/local/mysql。 相对路径：不是由根目录。写起的路径。如：../ 表示上一层路径，./ 表示本层路径。 1. 文件管理命令- ls ls （list）用于查看某个目录下有何文件。 常用选项 选项说明 无参数 列出目录下的文件和目录，不包含隐藏文件 -a 列出所有文件，包括隐藏文件，./ 和 ../ -l 列出详细信息（文件类型+文件所有者权限+属组权限+其它权限+inode数量+属主+属组+文件大小+mtime+文件名） -d 针对目录的，只列出目录本身；如果不加-d，那么会列出目录下面的文件来 -h 自动以合适的方式显示文件的大小 -t 按时间的顺序排列文件（新的在上面） -i 可查看文件的inode -F 在文件末尾显示文件类型 - tree tree 目录名：查看目录的树形显示 -C选项 ：用来以不通颜色区别文件类型 -L 数字选项 ：用来定义显示几级 - pwd pwd （print working directory）用于查看当前所在路径。 常用选项 选项说明 -L（不加也可） 显示逻辑上的路径（默认） -P 在查看链接文件时显示真正的路径，即不是链接文件的地址 - cd cd （change directory，是shell的内置命令）用于更改文件路径。 常用参数 参数说明 无参数 直接到当前用户的家目录下 ~username 进入username用户的家目录下 - 切换到上一次所在的目录 绝对或相对路径 到指定的目录下 注意：cd 后面只能跟目录，如何跟文件会报错。 - mkdir mkdir （make directory）用于创建目录。 格式为 mkdir [-mp] [目录名称] 常用选项 选项说明 -m 指定要创建目录的权限（不常用） -p 可一次性创建多层的空的目录，否则一次只能创建一层目录。后面跟一个已存在的目录名时，它不会做任何事情，只是不报错而已 -v 可视化创建过程 说明： 若是所创建的目录和已存在的文件名字一样的话，会创建失败 可同时创建多个目录，只需在后面用空格隔开目录名即可 - rmdir rmdir （remove directory）用于删除空的目录，后面可以是一个目录，也可以是多个目录（用空格隔开）。 常用选项 选项说明 -p 连续删除一连串空的目录 -v 可视化删除过程 注意：只能用来删除空的目录，否则会报错，即不能用来删除非空目录和删除文件。 - rm rm （remove）用于删除文件或目录。 常用选项 选项说明 -r 删除目录时要加的选项 -i 交互式的进行删除工作，即问你是不是确定要删除（默认带着呢） -f 强制安静删除，不用输入y或n来确认，且不再屏幕上显示任何信息，不论什么情况（比如目标文件不存在） 在写脚本时，我们会用绝对路径的形式/bin/rm，这是个危险的命令，需要谨慎操作！ - cp cp （copy）用于复制文件或目录。 格式为 cp [选项] [来源文件] [目的文件] 常用选项 选项说明 -r 复制目录时要加的选项 -i 安全选项，交互式进行工作，若是遇到一个已存在的文件，会询问是否覆盖（默认带着呢） -p 可把文件的权限页复制过去 - mv mv （move）用于移动或重命名文件或目录。 格式为 mv [选项] [源文件或目录] [目标文件或目录] 情况 结果 目标文件是目录，但该目录不存在 重命名该目录 目标文件是目录，且该目录存在 移动该目录 目标文件是文件，但该文件不存在 重命名该文件 目标文件是文件，且该文件存在 会询问是否覆盖 常用选项 选项说明 -i 交互式的进行工作，即问你是不是确定要删除（默认带着呢） -v 可视化过程 - touch格式 touch filename 若文件存在，更改文件的三个time属性 若文件不存在，则会新建这个文件 - file格式 file filename 用来查看文件的类型。 2. 文件内容查看命令- cat cat 用于查看一个文件的内容并将其显示在屏幕上。 常用选项 选项说明 -n 显示出行号 -A 显示所有的内容，包含特殊字符 示例：123456789101112131415161718# cat test.txt11111111111222222222223333333333355555555555# cat -n test.txt1 111111111112 222222222223 3333333333345 55555555555# cat -A test.txt11111111111$22222222222$33333333333$$55555555555$ - tac tac 是 cat 倒着写的，因此功能是把文件内容倒叙的方式显示在屏幕上。选项与cat相同。 - more more 用于查看一个文件的内容。当文件内容太多而一屏不能全部显示时，会分页显示，由按键操作： 按键 说明 空格 向下一页（看完所有内容后会退出） Ctrl+F 同空格 Ctrl+D 向上翻页 q 提前退出阅读 - less less 作用与more相同，只是功能要多一些，是增强版的more。 按键 说明 空格 一屏一屏向下翻页 j 向下移动一行 k 向上移动一行 g 到第一行行首去 G 到最后一行行首去 Ctrl+B 向上翻 Ctrl+F 向下翻 PGUP 向上翻页 PGDN 向下翻页 q 退出 less和more都支持用 / （向下查找）或 ? （向上查找）来进行字符串的查找，并且按 n 查找下一个，按 N 反向查找下一个。 - head head 用于显示文件的前几行。（默认不加选项，会显示最先十行） 常用选项 选项说明 -n 数字 显示指定的前几行 -n数字 同上 -数字 同上 - tail tail 和head类似，用于显示文件的最后几行内容。（默认不加选项，会显示最后十行） 常用选项 选项说明 -n 数字 显示指定的最后几行 -n数字 同上 -数字 同上 -f 如果文件内容不断地在增加，那么加上该选项就可以动态、实时地查看文件的内容。例如用的最多的：查看日志tail -f /var/log/messages 3. Linux文件属性- 文件属性的意义用命令 ls -l 查看当前目录下的文件时，共显示了9列内容（用空格分列），它们都代表着什么意思呢？如下表所示：12# ls -l test.txt-rw-r--r-- 1 root root 49 8月 27 17:45 test.txt 列数 意义 1 包含该文件的类型、所有者所属组以及其他用户对该文件的权限 2 表示该文件所占用的节点（inode），如果是目录，则该数值与该目录下的子目录数量有关 3 该文件的所有者 4 该文件的所属主 5 该文件的大小 678 表示该文件最后一次被修改的时间（mtime），一次为月份、日期、时间 9 文件名 - Linux下文件的类型在文件属性的第一列的第一个字符上我们可以看出该文件属于什么类型，主要有以下几种 字符 所代表的文件类型 - 普通文件 d 目录文件 l 链接文件 b 块设备文件，比如/dev/sda就是这样的文件 c 串行端口设备文件（又称字符设备文件），比如键盘、鼠标、打印机、tty终端等都是这样的文件 s 套接字文件（socket），用于进程间的通信 p 管道文件（与管道命令相关） - Linux文件的权限文件类型后面的9位为权限，每三个为一组，分别是文件的所有者（user）、所属组（group）和其他人（others）对该文件的权限。r 为可读权限，w 为可写权限，x 为可执行权限，- 为没有权限。另外，有的文件在最后还会有一个符号，一个点”.”或者是一个加号”+”。在CentOS 5的老版本中是没有这个的，这是因为新版本中的ls添加了SELinux或者ACL属性。如果文件或目录使用了SELinux context属性，这里会是一个点”.”；如果设置了ACL属性，这里会是一个加号”+”。（这个概念先了解即可） - 文件的三种权限对文件的作用对于文件来说，它的意义如下： 权限 意义 r Read 可读取此文件的实际内容，如读取文本文件的文字内容等 w Write 可以编辑、新增或者是修改该文件的内容（但不含删除该文件） x eXecute 该文件具有可以被系统执行的权限 - 文件的三种权限对目录的作用对于目录来说，它的意义如下： 权限 意义 r read contents in directory 具有读取目录结构列表的权限 w modify contents of directory 具有更改目录结构列表的权限，如新建文件与目录，删除已存在的文件或目录（不论它们是什么权限），将已存在的文件或目录重命名，转移该目录内的文件和目录 x access directory 决定用户能否进入该目录成为工作目录 - 文件的三种时间属性 时间属性 意义 atime access time 是在读取文件或执行文件时更改的 mtime modified time 是在写入文件时随文件内容的更改而更改的 ctime change time 是在写入文件、更改所有者、权限或链接设置时随inode内容的更改而更改的 - stat stat 用于查看文件的三个时间属性。 格式 stat filename - touch格式 touch 已存在的文件名 用于更改文件的三个时间属性为当前时间 - inode中包含的元信息具体说来有一下内容： 文件的字节数 文件拥有者的User ID 文件的Group ID 文件的读、写、执行权限 文件的时间戳，共有三个： ctime mtime atime 链接数：即有多少文件名指向这个inode 文件数据block的位置 4. 更改文件的权限- chgrp chgrp 用于更改文件的所属组。（chown可以代替它） 格式为 chgrp [组名] [文件名] 常用选项 选项说明 -R 作用于目录，连同目录下的所有文件和子目录全部都更改 - chown chown 用于更改文件的所有者，也可以更改所属组。 格式为 chown [-R] 账户名 文件名 或 chown [-R] 账户名:组名 文件名 常用选项 选项说明 -R 作用于目录，递归（继承）更改，即连同目录下的所有文件和子目录全部都更改 - chmod chmod 用于更改文件的权限。 格式为 chmod [-R] xyz 文件名 （其中xyz代表的数字） Linux中也可用数字代表rwx的权限，具体规则为：r为4，w为2，x为1，-为0。u为所有者，g为所属组，o为其他人，a为全部人。+为增加权限，-为去除权限，=为设置权限。权限的设置就是上面各个符号的组合。 常用选项 选项说明 -R 作用于目录，递归更改权限，即连同目录下的所有文件和子目录全部都更改 -v 可视化工作过程 几个例子如下：1234567chmod u=rwx,go=rw test.txtchmod ugo=rw test.txtchmod a=rw test.txtchmod a+x test.txtchmod a-x test.txtchmod 700 test.txtchmod 655 test.txt - umask默认情况下，新建一个目录的权限值为755，新建一个普通文件的权限值为644，那么这个值是由谁来控制的呢？那就是 umask 了。 umask 用于改变文件的默认权限 格式为 umask xxx （xxx在这里代表权限的三个数字） 几个例子如下：12umask # 查看umask的预设值umask 0022 # 设置umask的值 - umask的作用原理先了解以下两条规则： 若用户建立普通文件，则预设没有可执行权限，只有r、w两个权限，最大值为666（-rw-rw-rw-） 若用户建立目录，则预设所有权限均开放，即777（drwxrwxrwx） umask值的作用原理便是在这两条规则上，设置上需要减去的规则数字。 需要注意的是，root的umask值通常为022，而一般用户通常为002。umask的值可以在/etc/bashrc里面更改。 - chattr chattr 用于修改文件的特殊权限 格式为 chattr [+-=] [Asaci] [文件或者目录名]（其中+、-、=分别表示增加、减少和设定）。各个选项的意义如下： 常用选项 选项说明 A 文件或目录的atime将不可修改 s 会将数据同步写入磁盘中 a 只能追加不能删除，非root用户不能设定该属性 c 自动压缩该文件，读取时自动解压 i 锁定文件，不能删除、重命名、设定链接文件、写入以及新增数据 上表中最最常用的两个选项就是 a 和 i。 - lsattr lsattr 用于读取文件或目录的特殊权限 格式为 lsattr [-adR] 文件或目录名 常用选项 选项说明 -a 类似于ls的-a选项，即连同隐藏文件一同列出 -d 查看目录本身的特殊权限，而不是目录下文件的特殊权限 -R 连同子目录的数据一同列出 - Set UID、Set GID和Sticky Bit前面介绍权限的时候其实一共是4位，我们一直都是用3位数，其实最前面还有一位，那就是代表SUID、SGID和SBIT这三个属性的。它们的意义如下： SUID：该权限针对二进制可执行文件，使文件在执行阶段具有文件所有者的权限。比如，passwd这个命令就具有该权限。当普通用户执行passwd命令时，可以临时获得root权限，从而可以更改密码。 SGID：该权限可以作用在文件上（二进制可执行文件），也可以作用在目录上。当作用在文件上时，其功能和 Set UID 类似，它会使文件在执行阶段具有文件所属组的权限。目录被设置这个权限后，任何用户在此目录下创建的文件都具有和该目录所属的组相同的组。 SBIT：该权限只能作用于目录上。可以理解为防删除位。文件是否可以被某用户删除，主要取决于该文件所在的目录是否对该用户具有写权限。如果没有写权限，则这个目录下的所有问价都不能删除，同时也不能添加新的文件。如果希望用户能够添加文件但不能删除该目录下其他用户的文件，则可以对父目录增加该权限。设置该权限后，就算用户对该目录具有写权限，也不能删除其他用户的文件。例如，/tmp 目录就是设置了这个权限。 设置方法如下： SUID : chmod u[+-]s filename 或 chmod [40]*** filename SGID : chmod g[+-]s filename 或 chmod [20]*** filename SBIT : chmod o[+-]t filename 或 chmod [10]*** filename 说明： 设置了以上的各个权限后，文件的相应权限位上的情况分别是： SUID：所有者的可执行权限x变为了s； SGID：所属组的可执行权限x变为了s； SBIT：其他人的可执行权限变为了t。 有时候可能会发现某个文件的相关属性位上的字母为S（大写）和T（大写），这是因为文件本身就不具备该身份的可执行权限，所以即使设置了这三个属性中的其中一种，也不会生效。 5. 文件搜索命令- which which 只能用来查找PATH环境变量中出现的路径下可执行文件。 格式：which command 说明： 在PATH变量指定的路径中，搜索某个系统命令的位置，并返回第一个搜索结果。也就是说，使用which命令就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令 cd用which是查不到的，因为cd 是bash的内置命令 - whereis whereis 命令通过欲生成的一个文件列表库查找与给出的文件名相关的文件。类似于模糊查找，只要文件名中包含给定的字符串，就会列出来。这个命令很少用到 格式 whereis [-bms] [关键字] 常用选项 选项说明 -b 只查找二进制文件 -m 只查找帮助文件（在man目录下的文件） -s 只查找源代码文件 -u 没有说明文档的文件 说明： 也是局限在某些目录下，只在以下几个目录中搜索：/bin 、/sbin、/sur/bin 、/usr/sbin、/usr/share/man/man1/ 等等。 只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s），如果省略参数，则返回所有信息。 - locate locate 命令类似于whereis，也是通过查找预先生成的文件列表库来告诉用户要查找的文件在哪里，后面直接跟文件名。 如果Linux中没有这个命令，请安装mlocate软件包。yum install -y mlocate 安装好mlocate后，要更新相关的库：updatedb （注意：这个操作会占用大量的服务器资源） 可以在文件 /etc/updated.conf 中配置这个数据库额生成（或更新）规则。 locate 所搜索到的文件列表，不管是目录名还是文件名，只要包含该关键字，都会列出来，所以它不适合精确搜索，因此并不会被常用。 - find find 用于精确查找某些符合给定条件的文件，功能非常强大。 格式 find 指定目录 指定条件 指定动作 指定目录：所要搜索的目录及其所有子目录。默认为当前目录。 指定条件：所有搜索的文件的特征。 指定动作：对搜索结果进行特定的处理。 常用参数 参数说明 -atime +n/-n 表示访问或执行时间大于或小于n天的文件 -ctime +n/-n 表示写入、更改inode属性（如更改所有者、权限或者链接）的时间大于或小于n天的文件 -mtime +n/-n/n 表示更改内容的时间大于、小于或等于n天的文件（该参数用的最多） -mmin -n 表示在十分之之内更改内容的文件 -name filename 表示直接查找该文件名的文件（常用） -type 类型符 表示通过文件类型查找文件。filestype包含了f、b、c、d、l、s等类型 在条件前加! 表示对条件进行取反 条件1 -o 条件2 在两个条件之间，-o表示或者，不加任何东西就是并且 注意：find命令可结合管道命令和通配符来配合使用 |xargs 命令 -exec 命令 {} \; 不交互直接进行处理 -ok 命令 {} \; 交互式地进行处理 6. 链接文件- 硬链接硬链接是再建立一个inode链接到文件放置的区块域，即进行硬链接时该文件内容没有任何变化，只是增加了一个指向这个文件的inode，并不会额外占用磁盘空间。 硬链接有两个限制： 不能跨文件系统，因为不同的文件系统有不同的inode table 不能链接目录 - 软链接软链接相当于快捷方式。它与硬链接不同的是，软链接是建立一个独立的文件，当读取到这个链接文件时，它会把读取的行为转发到文件所链接的文件上。 - ln ln 用于创建链接文件，即硬链接和软链接 格式 ln [-s] [来源文件] [目的文件] 说明： ln的常用选项就是-s 加上-s就是创建软链接 不加-s就是创建硬链接 示例：12ln test test-hard //创建test的硬链接文件test-hardln -s test test-soft //创建test的软链接文件test-soft OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统目录结构]]></title>
    <url>%2F2017%2F08%2F26%2FLinux%2F005.%20Linux%E7%B3%BB%E7%BB%9F%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[GO 1. FHS标准 根据FHS（Filesystem Hierarchy Standard ）官方文件说明，其主要目的是希望让用户可以了解到已安装软件通常放在哪个目录下，所以其希望独立的开发商、操作系统制作者以及想要维护系统的用户，都能够遵循FHS标准。 FHS将目录定义为四种交互作用的形态： 可分享的：可以分享给其它系统挂载使用的目录，所以包括可执行文件与用户的邮件等数据。 不可分享的：自己机器上米娜运行的设备文件或者是与程序有关的socket文件等，由于仅与自身机器有关，所以就不适合分享给其它主机了。 不可变动的：有些数据是不会经常变动的，跟随着distribution而不变动。例如函数、说明文件、系统管理员所管理的主机服务配置文件等。 可变动的：经常改变的数据，例如登陆文件、新闻组等。 事实上，FHS针对目录树架构仅定义出三层目录下面应该放置什么数据而已。分别是下面这三个目录的定义： / （root，根目录）：与开机系统有关。 FHS标准建议：根目录所在分区应该越小越好，且应用程序所安装的软件最好不要与根目录放在同一个分区内，保持根目录越小，这样不但性能最好，其根目录所在文件系统也较不容易发生问题。 根目录下面应该放置这些目录： /bin /boot /dev /etc /home /lib /media /mnt /opt /root /sbin /srv /tmp 特别注意，根目录与开机有关，开机过程中仅有根目录会被挂载，其它分区则是在开机完成之后才会持续进行挂载的行为。正因如此，根目录下与开机过程有关的目录就不能够与根目录放到不同的分区去。这些目录如下： /etc ：配置文件 /bin ：重要的执行文件 /dev ：所需要的设备文件 /lib ：执行文件所需的函数库与内核所需的模块 /sbin ：重要的系统执行文件 /usr （Unix Software Resource）：与软件安装和执行有关。 这里面放置的数据属于可分享的与不可变动的。 FHS建议所有软件开发者应该将他们的数据合理地分别放置到这个目录下的子目录，而不是自行新建该软件自己独立的目录。 该目录下面有如下所示的目录： /usr/X11R6/ /usr/bin/ /usr/include/ /usr/lib/ /usr/local/ /usr/sbin/ /usr/share/ /usr/src/ /var （VARiable）：与系统运作过程有关。 该目录只要针对常态性变动的文件，包括缓存（cache）、登陆文件（log file）以及某些软件运行时所产生的文件，包括程序文件（lock file，run file），或者例如MySQL数据库的文件等。 常见的子目录如下： /var/cache/ /var/lib/ /var/lock/ /var/log/ /var/mail/ /var/run/ /var/spool/ 2. Linux系统目录说明 常见目录的作用整理如下表： 目录名 作用 /bin bin是Binary的缩写，该目录下存放的是最常用的命令 /boot 该目录下存放的是启动Linux时使用的一些核心文件，包括一些链接文件以及镜像文件 /dev dev是Device（设备）的缩写。该目录下存放的是Linux的外部设备。在Linux中，访问设备的方式和访问文件的方式是相同的 /etc 该目录下存放的是所有系统管理所需要的配置文件和子目录 /home 这是用户的家目录。在Linux中， 每个用户都有一个自己的目录，一般该目录名是以用户名来命名的（root用户有自己的家目录/root） /lib和/lib64 这两个目录下存放的是系统最基本的动态链接共享库，其作用类似于Windows里的DLL文件，几乎所有的应用程序都需要用到这些共享库。其中/lib64为64位的软件包的库文件所在目录 /media 系统会自动识别一些设备（如U盘、光驱等），当识别后，Linux会把识别的设备挂载到该目录下 /mnt 系统提供该目录是为了让用户临时挂载别的文件系统。我们可以将光驱挂载到/mnt/上，然后进入该目录查看光驱里的内容 /opt 这是给主机额外安装软件所设置的目录，该目录默认为空。比如，你要安装一个Oracle数据库，可以放到该目录下。 /proc 该目录是一个虚拟目录，是系统内存的映射，可以直接访问它来获取系统信息。该目录的内容在内存里，我们可以直接修改里面的某些文件。内存和CPU的详细信息都在该目录下（cpuinfo和meminfo），修改内核参数或调优时会在该目录下进行文件的参数修改，其中的数字目录文件表示进程ID，其中的文件表示状态等信息。比如，可以通过下面的命令来屏蔽主机的ping命令，使他人无法ping通你的机器。在日常工作中，你会经常用到类似的用法： echo 1 &gt; /proc/sys/net/icmp_echo_ignore_all /root 该目录是系统管理员的用户家目录 /run 这个目录其实和/var/run是同一个目录，它们属于链接文件的关系，这里面存放的是一些服务的PID。一个服务启动完后，是有一个PID文件的。 /sbin s就是Super User的意思，该目录存放的是系统管理员使用的系统管理程序 /srv 该目录存放的是一些服务启动之后需要提取的数据 /sys 该目录存放的是与硬件驱动程序相关的信息 /sys/class 包含所有注册在kernel里面的设备类型，链接到device /sys/dev 维护一个按照字符设备和块设备的主次号码列表，链接到device /sys/device 是全局设备结构体系，包含所有被发现的注册在各种总线上的各种物理设备，是内核层次表达模型，也是/sys文件系统管理设备的最重要的目录结构 /sys/fs 描述系统中所有的文件系统 /sys/kernel 存放的是内核中所有可调整的参数 /tmp 该目录用来存放一些临时文件 /usr 这是一个非常重要的目录，用户的很多应用程序和文件都存放在该目录下 /usr/bin 该目录存放的是系统用户使用的应用程序 /usr/sbin 该目录存放的是超级用户使用的比较高级的管理程序和系统守护进程 /usr/src 该目录是内核源代码默认的放置目录 /var 该目录存放的是不断扩充且经常修改的目录，包括各种日志文件或者PID文件，其中刚刚提到的/var/run就是在这个目录下面 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS的单用户和救援模式]]></title>
    <url>%2F2017%2F08%2F26%2FLinux%2F004.%20CentOS%E7%9A%84%E5%8D%95%E7%94%A8%E6%88%B7%E5%92%8C%E6%95%91%E6%8F%B4%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[GO 1. CentOS 6 1.1 CentOS 6 的七个运行级别 运行级别的配置文件为 /etc/inittab。查看这个文件，其中有七个运行级别的说明。 cat /etc/inittab 查看该文件的的内容如下： 12345678910# Default runlevel. The runlevels used are:# 0 - halt (Do NOT set initdefault to this)# 1 - Single user mode# 2 - Multiuser, without NFS (The same as 3, if you do not have networking)# 3 - Full multiuser mode# 4 - unused# 5 - X11# 6 - reboot (Do NOT set initdefault to this)#id:3:initdefault: 七个运行级别的说明 运行级别 说明 0 关机 1 单用户 2 多用户模式，但没有NFS服务 3 命令行模式 4 预留，没有用 5 图形界面模式 6 重启 默认运行级别的设置 /etc/inittab配置文件的最后一行便是用来设置默认运行级别的。 id:3:initdefault: 把其中的数字更改，就更改了默认的运行级别 默认是3级别，在命令行下，运行 init 5 就是启动图形模式了。 同理，init 0 为关机，init 6 为重启 要想启动图像，要提前安装好图形的支持，用下面的命令安装： yum groupinstall “Desktop” “X Window System” 1.2. CentOS 6 的单用户模式 单用户相当于Windows里的安全模式，假如忘记了root密码，则进入该模式即可重新修改root密码。按下面的方法进入这种模式（init 1 是进不了的）： 重启Linux，3秒内，按一下回车 若有设置grub密码，需先按p，输入密码后方可进行后面的操作 此时 CentOS (2.6.32-504.el6.x86_64) 这一行是高亮的，即我们选中的就是这一行，这行的意思是 Linux版本为 CentOS，后面小括号内是内核版本信息。 另外在这个界面里，我们还可以获取一些信息，输入 e会在启动前编辑命令行； 输入 a 会在启动前更改内核的一些参数； 输入 c 则会进入命令行。 按e，选择第二行，再按e（目的是修改启动参数） 在最后面加入single或者数字1，再或者大写字母S 先按回车再按b（boot） 这样就成功进入单用户模式，我们可以在该模式下修改root 密码。 说明：如果在Linux的启动参数中，去掉rhgb，则系统在启动过程中就没有进度条了，只显示详细的进程启动 1.3. CentOS 6 的救援模式 救援模式即 rescue，这个模式主要是应用于，系统无法进入的情况。如 grub 损坏或者某一个配置文件修改出错。救援模式相当于Windows的WinPE，是一个内存操作系统。使用方法如下： 光盘或USB启动，进入系统安装盘启动界面。 使用上下方向键选择 Rescue installed system 然后回车。语言这一项保持默认，直接回车。 键盘类型，也默认，直接回车。 接着让我们设置网络，如果不需要联网直接用 tab 键选择 no，然后回车。 接下来这一步，提示我们 Rescue 环境将会找到我们已经安装的 Linux 系统，并将其挂载到/mnt/sysimage 下，这一步我们选择 Continue 然后回车。 回车后，将会看到一个小提示框，它告诉我们 Linux 系统挂载到了/mnt/sysimage，如果想获得 root 环境，需要执行命令 chroot /mnt/sysimage。 继续回车，又弹出下面的提示。 再继续回车，此时又出现一个框，有三种模式可以选择： shell 模式会直接进入命令行，可以进行的操作有编辑文件、修改用户密码等； fakd 是诊断模式； reboot 会直接重启； 这一步我们选择第一个 shell 模式，然后回车，进入 root 环境。 此时还不能操作 Linux 系统上的文件，因为目前还在光盘上的系统上。要想修改原来 Linux 系统上的文件还需要执行一个命令： chroot /mnt/sysimage 原来的 bash-4.1 变成了 sh-4.1 , 此时我们才可以像在原来的Linux 系统上做一些操作，比如更改 root 密码或者修改某个文件等。任务完成后，需要先exit，才能关机或重启。 2. CentOS 7 2.1. CentOS 7 的emergency模式 这个模式相当与CentOS 6的单用户模式，只不过在 7 版本开始已经不用运行级别这一概念了，所以也就没有了单用户模式。不过，在emergency模式下可以达到之前的单用户模式下的操作目的。 这个模式的使用方法如下： 重启系统 重启Linux，3秒内，按一下回车 按方向键移动光标，定位在第一行，按字母e编辑它，然后进入另一个界面 移动向下的方向键，把光标定位到linux16开头的行 进入emergency模式 按向右的方向键，将光标移动到 ro 那里，把 ro 改成 rw init=/sysroot/bin/bash 同时按住Ctrl和x这两个键，系统就会进入该模式了 修改root密码 首先切换到原始系统，chroot /sysroot/ 然后再进行修改密码passwd等操作，若是出现乱码，可以设置语系为英语，LANG=en 修改密码后，需要执行下这个命令： touch /.autorelabel 这个命令一定要写对，否则更改的密码将不能生效 执行这一步的作用是让SELinux生效，如果不执行，所修改的密码不会生效 执行完上述命令后，同时按Ctrl和d键（即等同于输入exit）,再进行系统的重启（reboot）。之后就可以用新的密码登陆了 2.2. CentOS 7 的救援模式 CentOS 7 的救援模式的使用方法如下： 光盘或USB启动进入到安装界面 进入rescue模式 使用上下方向键选择 Troubleshooting 回车进入另一界面 使用上下方向键选择 Rescure a CentOS Linux system，连续敲两次回车进入下一界面 这一界面里会有很多提示。按照提示，选择第1项，所以输入数字”1”，回车后再次回车，由出现了一个界面 这一界面告诉我们：原始系统已挂载到了 /mnt/sysimage，若要进入原始系统，需要执行 chroot /mnt/sysimage 命令 执行命令后，进行救援工作。 救援工作完成后，退出原始系统（exit或Ctrl+D），然后重启系统。 3. Systemd初始化进程红帽RHEL7系统已经替换掉了以往熟悉的初始化进程System V init，正式采用全新的Systemd初始化进程服务。systemd初始化进程服务采用了并发启动机制，开机速度得到了不小的提升。既然RHEL7系统选择了systemd初始化进程服务，随之也没有了运行级别这个概念，Linux系统启动时要做大量的初始化工作——例如挂在文件系统和交换分区、启动各类进程服务等等操作，这些都可以看作是一个个的单元（Unit），即用目标（target）代替了运行级别这个概念，区别如下表所示： sysvinit运行级别 systemd目标名称 作用 0 runlevel0.target,poweroff.target 关机 1 runlevel1.target,rescue.target 单用户模式 2 runlevel2.target,multi-user.target 等同于级别3 3 runlevel3.target,multi-user.target 多用户的文本界面 4 runlevel4.target,multi-user.target 等同于级别3 5 runlevel5.target,graphical.target 多用户的图形界面 6 runlevel6.target,reboot.target 重启 emergency emergency.target 紧急Shell 如果想要将系统默认的运行目标修改为”多用户，无图形”的模式，那么这可以用ln命令把该文件链接到/etc/systemd/system/目录下的default.target文件即可，命令如下：ln -sf /lib/systemd/system/multi-user.target /etc/systemd/system/default.target OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[远程连接Linux主机]]></title>
    <url>%2F2017%2F08%2F26%2FLinux%2F003.%20%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5Linux%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[GO 1. 使用Putty连接远程Linux主机Putty免费开源，小巧玲珑，在WIndows和Linux上都支持。所以我选择使用这个工具来管理远程Linux主机。使用它的好处是：可以随意的复制粘贴，可以通过鼠标滚轮查看之前显示的历史信息。 Putty套件的工具有很多，它们的功能如下所示： PuTTY（SSH和telnet客户端软件） PSCP（SCP客户端，用来远程复制文件） PSFTP（SFTP客户端，使用SSH协议传输文件） PuTTYtel（一个只有telnet功能的客户端软件） Plink（Windows下的命令行接口，使用它可以在cmd下使用PuTTY） Pageant（SS和的密钥守护进程，开启后，密钥保存到内存中，连接时不再输入密钥的密码，PuTTY、PSCP、PSFTP和Plink都可以使用） PuTTYgen（生成密钥对的工具） 在本文中，只用到PuTTY和PuTTYgen两个软件。 1.1. 使用密码登陆 填写远程Linux基本信息 Host Name（or IP address）这一栏填 服务器的IP。 Port 这一栏保持22不变。 Connection type 也保持ssh不变。 Save Sessions 这里自定义一个名字，主要用来区分主机。 定义字符集 为了防止乱码，对于管理安装了中文支持的远程Linux系统来说，要在Putty这里也设置支持中文。 点一下左侧的 Window –&gt; Translation，看右侧的 Character set translation on received data，选择 UTF-8。 然后再点一下左侧的 Session，最后点右侧的 save。 远程连接Linux 点Open，初次连接是会有一个提示（第一次连接的时候），它的意思是要打开的Linux还未在本机登记，是否要信任它。点击“是”即可连接。 然后连接成功后即可登陆管理远程的Linux了。 1.2. 使用密钥登陆 SSH服务支持以一种安全认证机制，即密钥认证。所谓的密钥认证，实际上是使用一对加密字符串，一个称为公钥(publickey)， 任何人都可以看到其内容，用于加密；另一个称为私钥(privatekey)，只有拥有者才能看到，用于解密。通过公钥加密过的密文使用私钥可以轻松解密，但根据公钥来猜测私钥却十分困难。SSH 的密钥认证就是使用了这一特性。服务器和客户端都各自拥有自己的公钥和私钥。PuTTY 是可以使用这种机制登录 Linux 的。 生成密钥对 Putty生成密钥对的工具是Puttygen，打开它。右下角的 1024 改成 2048，这表示密钥长度为 2048 位，这样更安全，然后点一下 ―Generate‖按钮, 这样就开始生成密钥了，请来回动一下鼠标，这样才可以快速生成密钥对，大约几秒后就完了。 “Key comment”这里可以保持不变也可以自定义，它是对该密钥的简单介绍。“Kye passphrase”这里用来给你的密钥设置密码，这样安全一些，当然也可以留空，建议你设置一个密码。“Confirm passphrase”这里再输入一遍刚刚你设置的密码。 保存私钥 单击“Save private key”，选择一个存放路径，并定义名字，点“保存”。这个就是所谓的私钥（一个*.ppk文件），请把它保存到一个比较安全的地方，谨防丢掉或被别人看到。 复制公钥到Linux 回到刚才生成密钥的窗口，在 “Key”的下方有一段长长的字符串，这串字符串就是公钥的内容，把整个公钥字符串复制下来。然后粘贴到 Linux 的这个文件中： /root/.ssh/authorized_keys。注意这个文件的名字是固定的。下面请做如下操作： 创建/root/.ssh 目录，因为这个目录默认是不存在的。# mkdir /root/.ssh 更改这个目录的权限。# chmod 700 /root/.ssh 把公钥内容粘贴进/root/.ssh/authorized_keys 文件中。 vi /root/.ssh/authorized_keys 回车后，按一下“i”进入编辑模式，然后直接点击鼠标右键就粘贴了，粘贴后，按一下“Esc”键，然后输入“:wq”回车保存退出该文件。 关闭SeLinux SeLinux 是 CentOS 的一种安全机制，它的存在的确让 Linux 系统安全了很多，但也产生了不少的麻烦。在这，如果不关闭 seLinux，使用密钥登录会提示 “Server refused our key”, 关闭方法如下： 临时关闭：setenforce 0 永久关闭：vi /etc/selinux/config ，把该配置文件中的SELINUX=enforcing修改为“SELINUX=disabled”，保存退出后然后重启系统。 说明： /etc/selinux/config配置文件中有三种模式：enforcing（默认开启）、permissive（提醒）和disabled（关闭）。 关闭防火墙 关闭netfilter （即iptables） iptables -F 临时将iptables的规则清空（防火墙清空） /etc/init.d/iptables save （或service iptables save） 将清楚后的防火墙规则保存到 /etc/sysconfig/iptables 设置putty通过密钥登陆 打开 PuTTY 软件，点一下我们保存好的 session，然后点右侧的“Load”，在左侧靠下面点一下“SSH”前面的+然后选择“Auth”看右侧“Private key file for authentication:”下面的长条框里目前为空，点一下“Browse”, 找到我们刚刚保存好的私钥，点“打开”。此时这个长条框里就有了私钥的地址，当然你也可以自行编辑这个路径。然后再回到左侧，点一下最上面的“Session”，在右侧再点一下“Save”。 保存好 session 后，点一下右下方的“Open”。出现登录界面，你会发现和原来的登录提示内容有所不同。 现在不再输入 root 密码，而是需要输入密钥的密码，如果先前在生产密钥的时候你没有设置密码，输入 root 后会直接登录系统。 需要注意几点： /root/.ssh目录的权限为700 SELinux要关闭 /root/.ssh/authorized_keys文件名要写对 公钥的文件内容要粘贴对 2. 两台Linux互相登陆有时候需要在Linux系统上登陆到另一台Linux主机，这就需要用到以下的技能。用以实现这个目的，CentOS自带的客户端软件是 openssh-clients。 2.1. 检查openssh-clients是否安装 检查是否安装，运行下面的命令：ssh -V 若没有安装，则运行下面的命令安装：yum install -y openssh-clients 2.2. 使用密码登陆 登陆命令格式如下：ssh Username@IPaddress一个例子： ssh root@192.168.0.105 查看当前登陆的用户身份： whoami 仅显示用户名 who am i 显示用户名、登陆终端、登陆时间、登陆来源IP 2.3. 使用密钥登陆 客户端生成密钥对执行如下命令来生成密钥对：ssh-keygen “Enter file in which to save the key (/root/.ssh/id_rsa): “ 首先，可以自定义私钥的存放位置，默认路径为/root/.ssh/id_rsa。可以采用默认值，回车即可。 “Enter passphrase (empty for no passphrase): “ 然后，定义私钥的密码，可以留空，直接回车即可。也可以设置一个密码。 “Enter same passphrase again: “ 接下来，会让我们再一次输入密码，然后回车，变生成了密钥对了。 可以在相关的目录里面找到私钥（id_rsa）和公钥（id_rsa.pub） 把把公钥复制到目标Linux上面 查看公钥内容并复制 把复制的内容粘贴到 /root/.ssh/suthorized_keys（该文件的创建过程参考Putty的密钥登陆） 确认该文件的权限，chmod 600 /root/.ssh/authorized_keys 登录Linux ssh 目标Linux的IP地址 补充：非root用户的密钥登陆与root用户的配置过程类似。 3. 补充内容3.1. SSH限制来源IP即SSH的黑名单和白名单，是以下这两个文件： /etc/hosts.allow /etc/hosts.deny 3.2. 禁止普通用户登陆系统当服务器进行高负荷的管理操作时，禁止普通用户登陆系统的方法如下：12touch /etc/nologin //禁止rm -f /etc/nologin //取消禁止 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统的启动流程]]></title>
    <url>%2F2017%2F08%2F26%2FLinux%2F002.%20Linux%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[GO 1. Linux系统的启动流程了解系统的启动流程，能够让我们在Linux系统在启动过程中遇到故障时，可以很快速地找到是在哪一步遇到了问题，这样我们就可以针对性地去排查故障。（以CentOS6系统为例说明） 1.1. 第一阶段：硬件引导启动 首先是BIOS加电自检，BIOS寻找启动介质，是硬盘还是光盘或者是其他启动介质。 找到启动介质后，在该介质中找到MBR。 MBR是启动介质（比如硬盘）的第一个分区的第一个扇区，大小为512字节。 其中前面的446字节是bootloader（CentOS安装的时候会在这里安装一个grub程序），紧接着64字节是分区表，最后面2字节是用来校验的，我们把它叫做55AA。 1.2. 第二阶段：grub启动引导程序 找到了MBR，就找到了grub，它就是一个引导程序，它会引导我们想启动的系统。（grub的配置文件是 /boot/grub/grub.conf，与/etc/grub.conf是软链接） grub引导分为两个阶段：执行stage1和stage2。 stage1是直接放在MBR中的，也就是前面446字节里面。 stage2比较大，所以被放在了文件系统里。 对于目前较新的文献系统（如ext4）来说，stage2是不能识别到的，所以在执行完stage1后，需要借助于一个中间桥梁stage1_5来识别stage2所在的文件系统，然后再执行stage2。 执行完stage2后，它就会去解析grub的配置文件 /boot/grub/grub.conf，在该配置文件中它又找到了内核和内核映像（initrd）的位置。 1.3. 第三阶段：内核引导 内核和内核映像（initrd）找到了，所以内核接管掌控权 按理说内核能够识别到几乎所有的硬件设备，但实际上内核的身材是非常小的，它只含有最基本的硬件驱动，而其它的常见硬件驱动是放在 initrd 中的。 所以这个阶段，initrd先释放到内存中，临时构成一个只读的文件系统，在这个只读的文件系统中，内核去执行临时文件系统里面的init进程，目的是加载各种硬件的驱动。 当所需的驱动加载完后，内核才挂载真正的根文件系统，内核把控制权交给了/sbin/init进程。 1.4. 第四阶段：系统初始化阶段/sbin/init 进程是系统其它所有进程的父进程，当它接管了系统的控制权后，首先会去读取/etc/inittab配置文件来执行相应的脚本进行系统初始化，如设置键盘、字体，装载模块，设置网络等。主要包括以下工作： 执行系统初始化脚本（/etc/rc.d/rc.sysinit），对系统进行基本的配置，以读写方式挂载根文件系统及其它文件系统，到此系统算是基本运行起来了，后面需要进行运行级别的确定及相应服务的启动。rc.sysinit所做的事情（不同的Linux发行版，该文件可能有些差异）如下： 获取网络环境与主机类型。首先会读取网络环境配置文件（/etc/sysconfig/network），获取主机名与默认网关等网络环境。 测试与载入内存设备 /proc、 /sys 及 usb设备。除了/proc 外，系统会主动检测是否有usb设备，并主动加载usb驱动，尝试载入usb文件系统。 决定是否启动SELinux。 接口设备的检测与即插即用（PNP）参数的测试。 用户自定义模块的加载。用户可以在 /etc/syscongfig/*.modules 加入自定义的模块，此时它会加载到系统中。 加载核心的相关设置。按 /etc/sysctl.conf 这个配置文件的设置值配置功能。 设置系统时间（clock）。 设置终端的控制台字形。 设置 raid 及 LVM 等硬盘功能。 检验磁盘文件系统。 进行磁盘配额 quota 的转换。 重新以读取模式载入系统磁盘。 启动 quota 功能。 启动系统随机数设备（产生随机数功能）。 清除启动过程中的临时文件。 将启动信息加载到 /var/log/dmesg 日志文件中。 ==》当 /etc/rc.d/rc.sysinit 执行完后，系统就可以顺利工作了，只是还需要启动系统所需要的各种服务，这样主机才可以提供相关的网络和主机功能，因此会执行下面的脚本。 执行 /etc/rc.d/rc 脚本。 该文件定义了服务启动的顺序是先K后S，而具体的每个运行级别的服务状态是放在 /etc/rc.d/rc*.d（*代表启动级别0~6）目录下，所有的文件均是指向/etc/init.d下相应文件的软链接。 rc.sysinit 通过分析 /etc/inittab 文件来确定系统的启动级别，然后才去执行 /etc/rc.d/rc*.d 下的文件。 注意：也就是说，/etc/目录下的 init.d、rc、rc*.d、rc.local和rc.sysinit 均是指向 /etc/rc.d 目录下相应文件和目录的软链接。我们以启动级别3为例来简要说一下： /etc/rc.d/rc3.d目录下的内容都是以S或者K开头的软链接文件，它们都链接到/etc/rc.d/init.d目录下的各种shell脚本。 S表示启动时需 start 的服务内容，K表示关机时需关闭的服务内容。 /etc/rc.d/rc*.d 中的系统服务会在系统后台启动，如果要对某个运行级别中的服务进行更具体的定制，通过 chkconfig 命令来操作，或者通过 setup、ntsys、system-config-services 来进行定制。 如果我们需要自己增加启动的内容，可以在init.d目录中增加相关的shell脚本，然后在rc*.d目录中建立指向该shell脚本的软链接文件即可。 这些shell脚本的启动或结束顺序是由S或K字母后面的数字决定，数字越小的脚本越优先执行。例如：/etc/rc.d/rc3.d/S01sysstat 就比 /etc/rc.d/rc3.d/S99local 先执行。 执行用户自定义引导程序 /etc/rc.d/rc.local。 其实当执行 /etc/rc.d/rc3.d/S99local时，它就是在执行/etc/rc.d/rc.local。前一个文件是后一个文件的软链接。 一般来说，自定义的程序，只需要将命令放在rc.local里面就可以了，这个shell脚本就是保留给用户自定义启动内容的。 完成了系统所有的启动任务后，Linux会启动终端或X-Window来等待用户登陆。 tty1、tty2、tty3……这表示在运行等级1，2，3，4的时候，都会执行 /sbin/mingetty，而且执行了六个，所以Linux会有六个纯文本终端，mingetty就是启动终端的命令。 除了这6个之外还会执行 /etc/X11/prefdm-nodaemon ，它主要启动X-Window。 至此，系统就完全启动完毕了。 2. 系统启动流程的示意图- Linux系统启动流程简图 - Linux系统启动流程详图 3. grub的配置文件3.1. grub配置文件说明grub的配置文件是 /etc/grub.conf，它的基本配置说明如下： default=0（1，2……）表示默认启动那个选项，可自定义 timeout=5 表示等待几秒进入默认的选项，可自定义 title后面的内容表示每个选项的标题，也就是在开机时候的各个选项的名字，可自定义 启动参数，最好不要改，改错了，就进不去系统了 3.2. grub加密 不加密密码的设置方式 在/etc/grub.conf配置文件中的title那行的上面添加一行”password=密码”即可 加密密码的设置方式 grub-md5-crypt grub-crypt --md5|--sha-256|--sha-512 用以上的命令来获得加密的密码，然后将其复制到/etc/grub.conf文件中的”password –md5|–sha-256|–sha-512 加密的密码”即可 说明：–md5|–sha-256|–sha-512 这三种只选一种即可 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux配置静态IP联网]]></title>
    <url>%2F2017%2F08%2F26%2FLinux%2F001.%20Linux%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81IP%E8%81%94%E7%BD%91%2F</url>
    <content type="text"><![CDATA[GO 1. CentOS6 的网络配置1.1. 获取IP、网关等信息安装好CentOS后，第一件事情就是配置IP，让机器连接网络，之后便能够通过远程工具（如Putty、Xshell、SecureCRT等）来进行管理了。 首先，可以用 ifconfig 查看网卡的IP等信息。 输入 ifconfig 后默认只有一个网卡的信息，即 lo 网卡，它是回环网卡，每个计算机都有这个网卡IP的，它的主要作用是机器内部通信。 可以用 ifconfig -a 来查看所有网卡的信息（包括未启用的网卡）。一般会显示名字类似 eth0 网卡的信息，这时候这块网卡还未启用，接下来我们应该启用它。 用 dhclient 让网卡自动获取一个IP。 这个命令是自动获取IP的命令，如果Linux所在网络环境有dhcp服务器，运行该命令后，Linux机器就可以自动获取到一个IP。（在服务器上用不到） 此时，这个IP是自动获取的，也就是动态的，实际机房的服务器IP并不是自动获取的，都需要固定好，所以，应该为eth0网卡设置一个静态IP。 在设置静态IP之前，先用 route 命令查到 NETMASK 和 GATEWAY，以便我们在设置静态IP时填在配置文件里。 route 这个命令是用来查看路由的。 route -n 可查看到网关。 还有一个命令可以查看到IP地址： ip add 配置网卡的配置文件 1.2. 配置网卡配置文件配置eth0网卡为静态IP，即配置该网卡的配置文件。 它的配置文件类似于 /etc/sysconfig/network-scripts/ifcfg-eth0 在这个配置文件中需要更改的地方有： 12345678ONBOOT=no 改为 yes //开机启动网卡BOOTPROTO=dhcp 改为 static //IP的类型，动态还是静态==&gt;新添加的几行内容：IPADDR=192.168.1.222 //这个IP地址是我们通过命令 ifconfig eth0 查到的。（之前通过dhclient命令获取的动态IP，可以自己填写为合适的IP地址）NETMASK=255.255.255.0 //子网掩码GATEWAY=192.168.1.1 //网关DNS1=202.106.0.20 //域名服务器的地址，目前的IP地址为联通的一个DNS服务器IP。DNS2=8.8.8.8 //可以添加多个DNS服务器IP，就像这样写成DNS1和DNS2 修改后的配置文件内容如下所示（一个例子）： 123456789101112DEVICE=eth0HWADDR=00:0C:29:B0:78:92TYPE=EthernetUUID=5efd98d1-d7b2-447f-9036-e4c73dfab70aONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=staticIPADDR=192.168.0.103NETMASK=255.255.255.0GATEWAY=192.168.0.1DNS1=4.4.4.4DNS2=8.8.8.8 1.3. 重启网络服务修改完配置文件后，需要将网络服务重启才能生效。输入下面的命令即可重启网络服务： service network restart 或者 /etc/init.d/network restart 1.4. 测试网络连通性通过 ping 命令来测试一下网络的连通性： ping www.sina.com 如果ping通了，就说明静态IP配置成功，并能连接外网了。 在Linux下ping会一直持续，需要按快捷键 Ctr+C 终止该程序。 2. CentOS7 的网络配置2.1. 获取IP、网关等信息 自动获取IP : dhclient 查看自动获取IP后是否可以联网 : ping www.sina.com 查看IP : ip addr 查看网关 : ip route 2.2. 配置网卡配置文件这一步是为了配置静态IP。 网卡的配置文件的名字类似于 /etc/sysconfig/network-scripts/ifcfg-ens33 在这个配置文件中需要更改的地方有： 12345678ONBOOT=no 改为 yes //开机启动网卡BOOTPROTO=dhcp 改为 static //IP的类型，动态还是静态==&gt;新添加的几行内容：IPADDR=192.168.1.222 //这个IP地址是我们通过命令 ifconfig eth0 查到的。（之前通过dhclient命令获取的动态IP，可以自己填写为合适的IP地址）NETMASK=255.255.255.0 //子网掩码GATEWAY=192.168.1.1 //网关DNS1=202.106.0.20 //域名服务器的地址，目前的IP地址为联通的一个DNS服务器IP。DNS2=8.8.8.8 //可以添加多个DNS服务器IP，就像这样写成DNS1和DNS2 修改后的配置文件内容如下所示（一个例子）： 123456789101112131415161718192021TYPE=EthernetBOOTPROTO=staticDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33UUID=18e90827-5eed-4b32-a5e1-3abdad76d8ccDEVICE=ens33ONBOOT=yesIPADDR=192.168.0.105NETMASK=255.255.255.0GATEWAY=192.168.0.1DNS1=119.29.29.29 2.3. 重启网络服务 重启网络服务 systemctl restart network.service 再查看IP检查是否正确 ip addr 2.4. 测试网络连通性 ping -c 4 www.sina.com 3. 网络初识补充内容3.1. 网卡名称说明 lo：回环网卡，只在本地使用 eth0：以太网卡，用以太网线连接 fddil：光纤网卡，用光纤网线连接 3.2. ifconfig 查看网卡IPifconfig不加任何参数，只打印当前网卡的IP相关信息（子网掩码、网关等），在之前的博客中已经记录了关于这个命令的使用。在shell下设置IP，需要修改相关的配置文件,/etc/sysconfig/network-scripts/ifcfg-eth0，如果是eth1网卡，则是/etc/sysconfig/network-scripts/ifcfg-eth1，若是ens33网卡，则是/etc/sysconfig/network-scripts/ifcfg-ens33。 如果Linux上有多个网卡，而只想重启某一个网卡的话，可以使用这个命令：ifdown eth0 ; ifup eth0ifdown 即停掉网卡，ifup即启动网卡。有一点需要注意，如果我们远程登陆服务器，当使用ifdown eth0这个命令的时候，很有可能后面的命令ifup eth0不会被运行，这样导致我们断网而无法连接服务器，所有请尽量使用service network restart这个命令来重启网卡。 3.3. 查看网卡连接状态查看网卡连接状态的命令为：mii-tool eth0 在虚拟机上该命令所显示的内容是： SIOCGMIIPHY on &#39;eth0&#39; failed: Operation not supported 在真机上该命令所显示的内容是：eth0: nogotiated 100baseTx-FD, Link ok 只要看到”Link ok”就说明网卡为连接状态，如果显示”No link”说明网卡坏掉了或者没有连接网线。 还有一个命令也可以查看网卡的状态：ethtool 网卡名 如果网卡没有连接，最后面一行Link detected显示为no 命令示例如下：123[root@theshuhost ~]# ethtool eth0Settings for eth0: Link detected: yes 3.4. 单网卡配置多个IP临时的： ifconfig eth0:1 192.168.1.2/255.255.255.0 永久的： 在Linux系统中，网卡是可以设定多重IP的。其方法如下： cd /etc/sysconfig/network-scripts/ cp ifcfg-eth0 ifcfg-eth0\:1 然后编辑ifcfg-eth0:1这个配置文件，内容如下，一定要注意DEVICE这里要写成”eth0:1” 1234567891011# cat ifcfg-eth0\:1DEVICE=eth0:1HWADDR=00:0C:29:D9:F0:52TYPE=EthernetUUID=a5442526-0329-421d-86cf-8d7f16d01374ONBOOT=yesBOOTPROTO=noneIPADDR=192.168.80.5NETMASK=255.255.255.0GATEWAY=192.168.80.2NM_CONTROLLED=yes 其实就是改一下 NAME、DEVICE、IPADDR这几处 编辑好后，重启网卡：ifdown eth0 &amp;&amp; ifup eth0 之后再查看网卡ip检查是否设置成功：ifconfig，可以看到多了一个ifcfg-eth0:1 3.5. 永久更改主机名当装完系统后，默认的主机名为localhost，使用hostname命令就可以知道您的linux主机名是什么：12# hostnamelocalhost.localdomain 同样可以使用hostname命令可以更改主机名（这种更改方式只是这次登陆有效，重启后还会恢复原样）：123# hostname theshu# hostnametheshu 若是想永久更改主机名，则需要修改相关的配置文件/etc/hostname，其修改内容如下：12# vim /etc/hostnametheshu 或是修改相关配置文件/etc/sysconfig/network，修改内容如下：123# vim /etc/sysconfig/networkNETWORKING=yesHOSTNAME=Aming.localdomain 在CentOS7中，还有一种更改主机名的方法，这中方法会自动更改文件内容，如下所示：12345[root@theshuhost ~]# hostnamectl set-hostname theshu[root@theshuhost ~]# hostnametheshu[root@theshuhost ~]# cat /etc/hostnametheshu 3.2. 常用的几个操作- 单网卡的关闭与启动 关闭：ifconfig eth0 down 启动：ifconfig eth0 up - 查看路由表 route -n - 禁止PING实现方法如下： 临时 1echo 1 &gt; /pro/sys/net/ipv4/icmp_echo_ignore_all 永久 12修改 /etc/sysctl.conf 这个文件，添加如下一行:net.ipv4.icmp_echo_ignore_all = 1 - 开启转发实现方法如下： 临时 1echo 1 &gt; /proc/sys/net/ipv4/ip_forward 永久 12修改 /etc/sysctl.conf 这个文件，添加如下一行:net.ipv4.ip_forward = 1 - 查看端口查看服务器上开启了哪些端口：1netstat -antp 相关工具：nmap 3.3. DNS的配置文件DNS是用来解析域名用的，平时我们访问网站都是直接输入一个网址，而DNS把这个网址解析到一个IP。 在Linux下设置DNS非常简单，只要把DNS地址写到一个配置文件中即可。这个配置文件就是/etc/resolv.conf。 - /etc/resolv.confDNS（NameServer）配置文件是 /etc/resolv.conf。 该文件的内容如下（一个示例）： 123; generated by sbin/dhclient-scriptnameserver 8.8.8.8nameserver 220.181.137.37 如果我们是dhcp自动获取的IP，那么它会自动在/etc/resolv.conf里获取dns的ip，如果我们手动编辑该配置文件，那么重启网络服务后还会自动还原，因为我们打开了dhclient的服务，所以为了不让它受dhclient的影响，我们需要杀死dhclient：killall dhclient，同样也需要杀死NetworkManager进程； 默认需要我们在网卡配置文件（/etc/sysconfig/network-scripts/ifcfg-eth0）重定义DNS服务器的IP，但如果在网卡配置文件中加上 PEERDNS=no 后，则该配置文件中的DNS1= 语句失效。 关于配置文件/etc/resolv.conf的说明： resolv.conf有它固有的格式，一定要写成nameserver IP的格式。 上面那行以”;”开头的是注释。 建议写两个或多个nameserver，默认会用第一个nameserver去解析域名，当第一个解析不到时会使用第二个，以此类推。 在Linux下面有一个特殊的文件/etc/hosts也能解析域名，如下。 - /etc/hosts/etc/hosts 文件是一个简易的DNS服务器，在该文件中添加IP和域名，即可在本地实现DNS的功能。不过需要我们手动在这里面添加”IP+域名”这些内容，它的作用是临时解析某个域名，非常有用。 示例如下：1234# vim /etc/hosts127.0,0,1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.1.111 www.baidu.com 保存一下，再ping一下www.baidu.com就会到192.168.1.111了。 关于配置文件/etc/hosts的说明： /etc/hosts 的格式很简单，没一行作为一条记录，分成两部分，第一部分是IP，第二部分是域名。 关于/etc/hosts文件有几点需要注意： 一个IP后面可以跟多个域名，可以是几十个，甚至上百个 每行只能有一个IP，也就是说，一个域名不能对应多个IP 如果有多行中出现相同的域名（前面IP不一样），会按最前面出现的记录来解析 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux在线帮助的使用]]></title>
    <url>%2F2017%2F08%2F25%2FLinux%2F000.%20Linux%E5%9C%A8%E7%BA%BF%E5%B8%AE%E5%8A%A9%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[GO 1. 命令执行错误信息当我们执行一条命令的时候，发生了错误，一般会在屏幕上面显示该错误的信息，我们可以通过这个错误信息来寻求解决办法。 1.1. command not found我们遇到最多的错误大概就是这个command not found了，它的意思是命令找不到。通常出现这个错误的可能原因如下： 这个命令不存在，因为该软件没有安装之故，解决方法就是安装该软件。 这个命令所在的目录目前的用户并没有将它加入命令搜索路径之中，请参考bash的PATH说明。 打错了命令。 2. man pageman 命令 即可查看关于所查命令的相关帮助信息，命令正确执行后进入的页面称为”Man Page”。我们可以用man man来查看man命令的使用。 2.1. 指令数字代表的意义在Man Page的第一行，命令名称的后面的括号里面的数字，是有意义的，它们可以帮助我们了解或直接查询相关的资料。它们的意义代表如下: 代号 代表内容 1 使用者可以操作的指令或可执行文件 2 系统内核可调用的函数与工具 3 一些常用的函数（function）与函数库（library） 4 设备文件的说明 5 配置文件或某些文件的格式 6 游戏（games） 7 惯例与协议等，如Linux标准文件系统、网络协议、ASCII等等的说明 8 系统管理员可用的管理命令 9 跟内核有关的文件 2.2. Man Page的主要内容 代号 内容说明 NAME 简短的命令、数据名称说明 SYNOPSIS 简单的命令的语法格式 DESCRIPTION 较为完整的说明，这部分最好仔细看看 OPTIONS 针对SYNOPSIS部分中，有列举的所有可用的参数说明 COMMANDS 当这个程序在执行时i，可以在此程序中下达的命令 FILES 这个程序或数据所使用或参考的某些文件 SEE ALSO 可以参考的与其相关的其它说明 EXAMPLE 一些例子 BUGS 已知的BUG AUTHORS 作者 COPYRIGHT 版权协议 2.3. 在Man Page中的按键操作 按键 进行的工作 空格键 向下翻一页 [Page Down] 向下翻一页 [Page up] 向上翻一页 [Home] 去到第一页 [End] 去到最后一页 /string 向下搜索 string 这个字符串 ?string 向上搜索 string 这个字符串 n,N n表示继续搜索，N表示反向搜索 q 结束这次的Man Page 2.4. 通常用man的方式通常在查阅某个数据时是这样来查阅的： 先查看NAME的项目，大略看一下这个数据的意思。 再仔细看一下DESCRIPTION，这个部分会提到很多相关的资料与用法，从这个地方可以学到很多小细节。 而如果这个命令其实很熟悉了，那么主要就是查阅关于 OPTIONS 的部分了。可以知道每个选项的意义，这样就可以执行比较细部的命令内容。 最后会再看一下跟这个资料有关的还有哪些东西可以使用的。也就是SEE ALSO项目。 某些说明内容还会列举有关的文件（FILES 部分）来供我们参考。这些都是很有帮助的。 2.5. man page的数据文件man page的数据文件通常放在/usr/share/man这个目录里，然而我们也可以通过修改它的man page查询路径来改善这个目录的问题。修改/etc/man.config(有的版本为man.conf或manpath.conf)即可。 2.6 man的其它用法2.6.1. man -f-f选项可以获取更多的信息，如下：123# man -f infoinfo (1) - read Info documentsinfo (5) - readable online documentation 然后可以用相应的数字来查看特定的信息：1man 1 info 2.6.2. man -k-k选项的作用是，在系统的说明文件中，只要包含后面的关键字就将该说明列出来。如下所示：1man -k man 2.6.3. 与man有关的两个命令 whatis [命令或数据] 等同于 man -f [命令或数据] apropos [命令或数据] 等同于 man -k [命令或数据] 需要注意的是，这两个特殊命令要能使用，必须要创建whatis数据库才行。这个数据库的创建需要以root身份执行这个命令: makewhatis 3. info page3.1. info的介绍基本上，info与man的用途差不多。与man不同的是，info page是将文件数据拆成一个一个的段落，每个段落用自己的页面来撰写，并且在各个页面中还有类似网页的“超链接”来跳到各不同的页面中，每个独立的页面也被称为一个节点（node）。所以，你可以将info page想成是命令行模式的网页显示数据。 不过你要查询的目标数据的说明文件必须要以info的格式来写成才能够使用info的特殊功能（例如超链接）。而这个支持info命令的文件默认是放在/usr/share/info/这个目录下。 使用info info可以得到如下的界面：123456789101112131415161718192021222324File: info.info, Node: Top, Next: Getting Started, Up: (dir) Info: An Introduction********************* The GNU Project distributes most of its on-line manuals in the "Infoformat", which you read using an "Info reader". You are probably usingan Info reader to read this now. There are two primary Info readers: 'info', a stand-alone programdesigned just to read Info files (*note What is Info?: (info-stnd)Top.),and the 'info' package in GNU Emacs, a general-purpose editor. Atpresent, only the Emacs reader supports using a mouse. If you are new to the Info reader and want to learn how to use it,type the command 'h' now. It brings you to a programmed instructionsequence. To read about advanced Info commands, type 'n' twice. This bringsyou to 'Advanced Info Commands', skipping over the 'Getting Started'chapter. --zz-Info: (info.info.gz)Top, 52 lines --Top------------------------------------Welcome to Info version 5.1. Type h for help, m for menu item. 3.2. 第一行的说明info page的界面里，第一行显示了很多信息。第一行里面的数据意义如下： file：代表这个info page的数据是来自info.info文件所提供的。 Node：代表目前的这个页面是属于Top节点。意思是info.info内含有很多信息，而Top仅是info.info文件内的一个节点内容而已。 Next：下一节点的名称为Getting Started，你也可以按N到下一个节点去。 UP：回到上一层的节点总览界面，你也可以按下U回到上一层。 Prev：前一个节点。但是由于Top是info.info的第一个节点，所以上面没有前一个节点的信息。从第一行你可以知道这个节点的内容、来源与相关链接的信息。 3.3. info page 中的按键说明 按键 进行工作 空格键 向下翻一页 [Page Down] 向下翻一页 [Page Up] 向上翻一页 [Tab] 在节点之间移动，有节点的地方，通常会以*显示 [Enter] 当光标在节点上面时，按下回车键就可以进入该节点 B 移动光标到该info界面当中的第一个节点处 E 移动光标到该info界面当中的最后一个节点处 N 前往下一个节点处 P 前往上一个节点处 U 向上移动一层 S（/） 在info page当中进行查询 H 显示帮助菜单 ? 命令一览表 Q 结束这次的info page 4. 其它有用的文件一般而言，命令或者软件开发者都会将自己的命令或者是软件的说明制作成“在线帮助文件”。但是，毕竟不是什么都需要做成在线帮助文件的，还有相当多的说明需要额外的文件。此时，这个所谓的How-To（如何做）就很重要了。还有，某些软件不仅是告诉你“如何做”，还会有一些相关的原理会说明。 那么这些帮助文件放在了哪里呢？就是放在/usr/share/doc这个目录下。所以说，你只要到这个目录下面，就会发现有很多的说明文件，还不需要到网上找数据。而且这个目录下面的数据主要是以软件包为主的，例如GCC这个软件包的相关信息在/usr/share/doc/gcc-xxx（那个xxx表示版本的意思）中。 5. 总结 有些信息可在屏幕上面获取。 在命令行界面下，有任何你不知道的命令或文件格式，但是你想要了解它，都可以使用man或者info来查询。 而如果你想要架设一些其它的服务，或想要利用一整套软件来达成某项功能时，请赶快到/usr/share/doc下面查一查有没有该服务的说明文档。 另外，再次强调，因为Linux毕竟是外国人发明的，所以这些帮助文件主要是以英语为主。需要学习一下英文来提高英文的阅读能力。 OK]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《空城纪》许嵩和栈弈]]></title>
    <url>%2F2017%2F05%2F20%2F%E8%BD%AC%E8%BD%BD%2F001.%20%E3%80%8A%E7%A9%BA%E5%9F%8E%E7%BA%AA%E3%80%8B%E8%AE%B8%E5%B5%A9%E5%92%8C%E6%A0%88%E5%BC%88%2F</url>
    <content type="text"><![CDATA[空城纪『序』整整一年没有写长篇故事了。 一般所谓长篇，就是把一个短篇塞进去很多无关紧要的废话而后兴致勃勃地发表。 可能比较无聊。 可恰好的是，我们都很无聊，需要这种无聊的东西来打发无聊的时光。 去年写《奇迹》，打发了一代人的无聊时光。每天在打完cs脸颊红扑扑的状态下被迫去写上2000字满足大众需要。后来由于文章内死人太多，遭到抨击，加之大学开学。不了了之。 姑且。 今年就在这儿写点东西。想起来了就写了。想不起来了就不写了。这没什么好奇怪的。就像你想起来上厕所了就上了，看到老情人一激动忘了就忘了。水喝多了尿床了就尿床了。虽然我文思如尿崩的时代已然过去。 可以看成小说，可以视为纪实。并不重要。我和栈弈的一些遭遇或者美遇，都要在这渐次上演。 语文老师说过。人物只是线索。 这是对了。 写文章如果不是我。写得如果不是我和栈弈及其他一切周遭人等，该发生的仍旧发生。如同桡尺关节始终是处于桡尺骨结合处。 一任的无聊。 我们处在一个背信弃义类似野狗上青天的时代。 周遭的一切何等荒芜乃至于觉得什么都没有。 什么都没有。代表着什么。他？的。 项羽火烧了阿房宫。咸阳城外风化成一片荒冢。 叫做空城纪。 ————Vae 空城纪『一』说到我和Vae的相遇…恩，先不说这个，既然Vae在序言里迟迟不让栈弈出场，礼尚往来，正式开始的第一篇里还是由栈弈来唱一出独角戏吧。 对于以后将要胡扯的这一系列故事而言，起点应该是2004年的9月，全国各地的各种大学纷纷红着眼睛收钱收学生的时段，而我步入大二。 混迹于学校本部一年的我和其他人一起搬到了学校新区。新校区位于大学城的边缘，而大学城位于这个城市的边缘，具体方位是靠近两座山的地方，一座大蜀山，一座小蜀山，大蜀山是公园，小蜀山是公墓。 我们来到新区后，对这个狭小偏僻的地方感到很大的失望，具体失望之处会在今后慢慢解析。有一日班里某君在操场南面的小树林西面的小土包后面的一个旮旯处发现一只皱巴巴的保险套，于是我们相信这里已经是野外了。 我们开学较早，在我们刚刚开始感受旷野大风吹的时候，Vae以及即将与他同窗的其他人物正在各自的家里享受着最后的安逸，可能还夹杂着对大学生活的些许憧憬。当然，这无可厚非，？？？说过，想知道梨子的滋味，就要改造它，亲口尝一尝；同样的，想知道上大学的滋味，就要被它改造，让它上一上。所以在这之前，你可以肆意的幻想，我也相信一切皆有可能，就如同一个梨子吃下去，可能你止咳化痰，也可能你痢疾拉肚。 别介意，Vae讨论完文思和尿崩的关系之后，我又探讨了大学和痢疾的关联，因为栈弈和Vae总是会有一些相同的地方，而其中一个，就是我们都在这所医科大学里念着无法做医生的专业，叫做卫生管理。 这个名字乍听起来很容易让人想到是医院里管理卫生的，传说我们所在的是全国第一所卫生管理学院，还传说后来在复旦南大中山大等等高级场所开设卫生管理专业的人，都是出自于我们这里，而实际的情况是，用人单位更愿意要他们的学生。就好比合肥万燕出现了世界上第一台VCD，而我家买的VCD却产自广东爱多，这样的现象可以归结成一句朴素的话：“个人富不算富，全村富才算富”。 当我已经渐渐习惯了在这样一个新的环境里继续翘课和懒觉事业的时候，忽一日，整个校区旌旗飘扬，原来新生将至。 每一年大学里新生报到的时候都有老生前来迎接的传统，一帮人摆好桌椅，竖好牌子写上自己学院的名称，然后新生即可以对号入院，这样的活动会持续两天。看起来这样的形式可以给新来的学子以夏日的清凉，而实际上，前来迎接的男生或女生都在期待接到一个貌美如花的女子或者玉树临风的男子，然后开始一段恋情。对于刚刚跳出情感旋涡的栈弈自然不会参与这样无聊的活动，于是我选择在这两天回家修养生息，以备即将到来的补考。 修养的第二天上午即将中午的时候，我被一个来自学校的短信惊醒，内容是“快来吧，来看看今年的女生都丑成什么样了！”真的是莫名其妙是不是他在搞笑，丑难道是我造成的不成？但是出于好奇我乘坐一个小时的公车来到了学校看看有多丑，我到达的时候被告之新生已经差不多全到了，看见新丑的机会减小，于是我就坐在接待处跟他们哈起牛皮。这时候很多人从食堂吃饭出来，辅导员告诉我说：拿饭缸的都是新生。 就在此时我听说了一个上午来的新生，一来就抽了他的辅导员，（名词解释：合肥地区“抽”即“骂”之意。）其他流传关于这厮的事情还包括：合肥一中毕业、男性、穿着嘻哈、裤子里可以放一只老母鸡（当然，并没有看见放过）、长发、戴眼镜、镜片兰色、获过省里网页制作大赛一等奖。大家对他的评价是：等着死吧。 那天晚上，我和辅导员一起吃饭，白天那个不幸被抽的辅导员也有幸在场，大家对今年的新生展开新一轮探讨，但是没有进展，依然总结为女生太丑，男生比较丑。而且还有一个网页大赛获过全省冠军的沦落至此，那个辅导员在说这个的时候很显得自豪，全然不顾白天曾被其抽。我随口一问：那个一中的是吧？结果被告知：不，工大附中的。 工大附中？我的母校。 于是栈弈和Vae的另一个共同之处被发掘出来。 再于是，第二天的中午，栈弈出现在Vae的寝室门口。 再再于是，对于以后将要胡扯的这一系列故事而言，起点似乎应该是2001年的9月。 ————栈弈 空城纪『二』在我小时候的记忆里，合肥是一个很小的地方。因为大人告诉过我，从我家到外婆家，不过十公里。骑自行车50分钟就到了。而我家在一个大人们称之为南门的地方，外婆家在一个它们叫做北门的地方。这一南一北的，才十公里，算算老子也就呆在一个一百平方公里的破地方啊。十八岁那年暑假的时候坐在电脑前面认识了一个之前完全不认识的女子，并于二十天后见面，二十二天后发展为男女朋友。这个事情告诉我，合肥真的很小。 我一直希望我能有一个既可以文静的陪我讨论诗文转个身又可以疯狂的陪我去吃去疯去野的美丽女人。可正是现实和理想的差距激励我不断奋斗，没有这样的人。他们告诉我，你这种想法，在古代直接把一个稍微念过几年书的青楼女人赎回家就可以了，而且你是学医的，可以试图把她身上的百病治好，让夕阳飞翔。这让我感到沮丧。其实很多东西都只是一种美妙的愿望，这个愿望的深究，始终是一场残念。 我用二十二天发展的那个女性。她不能陪我讨论诗文。导致我满腹经纶无处投递。她不能陪我疯狂的玩，导致我万千激情无处爆发。然而，我却要死要活的爱上她。我无法证明如果出现一个符合我理想要求的女性的时候我是否会义无反顾的抛弃她，然而算命书上说，你们俩的恋情，一共只有一年，并且是四世轮回。 九月中旬开始的时候，我痛苦的在qq里面和她惜别，因为我要去一个通过我十二年的在校不努力学习考取的一个中不溜的本科院校。之前的大人很兴奋，不断的有人给我钱，向我祝贺，我也在家接了很多电话，家里也请客吃饭。也就是说，老子考取了大学，是和这些人的大力支持分不开的。尽管我不知道谁谁谁是谁谁谁。而她也将奔赴另外一所高校报到。我们感到空气很悲凉。其实哪怕是去北大报到，我仍然感到悲凉。因为所谓学校，无非是一个限制你的地方。尽管校方会卑劣的表示，我们限制了你的人身，但解放了你的思想，当你四年出来之后，你的人生将被重新定位，你会带着母校的思维方式与人文气息与人打交道，走到哪儿，你都是我们的人。 走到哪儿都是你的人。这不是强女干吗。 但我相信，一切都会过去。学校始终阻挡不了我什么。就像我就读的高中，那个号称今日我以x中为荣明日x中以我为荣的傻x学校，沽名钓誉搞了一大堆封号，尽管实质上平庸无奇。其间我不断的旷课，偶尔的上课，没有受到任何相关的处罚。可能是因为教师比较忙。忙于赚钱之余，偶尔管理一下好学生以及部署好家长会等等表面工作，年底的时候因为表现突出获得优秀教师称号，来年以此称号抬高身价，继续赚钱。一般开个小辅导班能搞个30号人，每晚一人交个五十来块；如果要单独辅导，那么一晚估计得三五百才能拿下。这很像古代的青楼女子，被某位达官贵人相中了睡了一晚，之后再想让她出场简直难于上天。如果和微服嫖女昌的皇帝睡了一晚，那么直接晋级为妃子，成为对口陪睡。所谓师风日下，其实是错的，因为我没有看过师风向上的时候。 总的来说。我的生活态度是积极的。那些因为看破红尘而悲观失望的傻x其实是因为根本没有看破，因为无论怎么样，人都是要死的，哪怕这世界上再多的东西让你不爽或者爽。反正是迟早的事，不如尽量自寻快乐。 于是，我很积极的跑去我即将待上四年的学校报名。校内平庸无奇，毫无学术氛围，很多骑三轮车的，卖棉花糖的，残废的，老的路都走不动的，花枝招展如女支女的都在里面穿梭。该校四通八达，到处都是门，俨然成为？？？？，很多人抄近路都要从校内经过一下。这令我欣慰，因为这意味着我可以在以后旷课的岁月里从任何角度逃跑。再往里面走，人山人海，一大堆和我一样大的家伙面带激情的在报名处交钱，每个人身后跟着自己的家长。这气氛令我感到无所适从。我只想抓紧时间交钱走人。于是我抓紧时间，交钱，走人。其间冷言讥讽据说将成为我今后班主任的一个男性。事后我有一丝恐惧，因为这意味着可能在我今后旷课的时候，他会对我进行空前严厉的制裁。 回家的时候路边的花草依然如故。我很怜爱的摸摸饲养三年的小犬，郑重的告诉他，我明天要走了，去一个你一辈子也去不了的地方。你要好好的过活，如果我一年之后回来你死了，我会让你死无全尸。 说这话的时候我不知道，在之后的一年内，我在家的时间和在校时间是基本持平的。 所有的算命书上都写道在我这天出生的属虎的男性是先知。虽然我从未让自己的先知功能为我服务，但是实践证明了，很多时候，我确实具备了一定的预见性。就像这场戏，从入学的一刻，它的结果就已经是注定了的。 稍候的几天里我完全沉浸在爱情的美妙中，并且珍惜每秒钟发短信的时光。因为在这儿谁也不认识。我谁也不想认识。当时的想法是，有老婆就够了。再加上军训是一种非常无聊的东西，每天在那儿傻站，然后评定哪个排站的好，站的久。傻的一塌糊涂。至于能增强身体素质那完全是扯淡，全去当兵好了，念什么书。秀才和兵做的事情总是两样的。要是真有所谓的全面发展，那只能是普遍低级的全面发展。尽管很多人觉得我是全面的发展的。但实质上，我发展的都在一个领域内，并且都是些安静的项目。虽然我看起来不太像文人。室友跟我说我看起来更像坏人。这令我感到满意，并且非常。如果是什么人都可以用肉眼看出来，岂不是毫无悬念。世上的乐趣也因此少了很多。 带我们军训的排长也极度空虚，并且略有文化，每天晚上要与我就人生进行高谈阔论，并且至凌晨三四点。经常室友起夜撒尿看到我们仍然在长谈，唏嘘不已。虽然，我每天都很困乏，并且想尽方法逃脱，比如，逃跑至栈弈处。 栈弈是我认识的第一个非本年级的人。认识当天我正沉迷女色，给女人发完短信打完电话，并对谈话内容进行温习，小脸红扑扑。栈弈非常严正的表情敲敲门，问我是不是叫xxx，并且在手心写下他的名字告诉我。这令我感到非常之正式，虽然我不知道他怎么知道我是谁，也许他也不知道我不知道他怎么知道我是谁。一切都不那么清楚明白。宗旨是，我们认识了。之后接触到的很多事，都不那么清楚明白，这渐次令我习惯。很多时候我不清不楚的获得了。或者不清不楚的失去了。尽管这些同等令人唏嘘。 ————Vae 空城纪『三』合肥的季节气候，是过了冬天就是夏天，过了夏天就是冬天。在那个骄阳似火的新生报到日过后，天气就一天比一天冷，这样的天气很适合睡眠，每日只醒来一次明显不够，往往早晨的第一次醒来都带着淡淡的寒意和尿意，非常愉快，然后便情不自禁地继续睡眠。一般的情况是室友下课回来后把我唤醒，更衣漱洗完毕后，我会去食堂随便搞点吃的，填饱肚子就行了，我对食堂的要求就这么点，只要不限制我的食欲。下午如果没有课的话就不去食堂，而是直接带着兜兜里的一元硬币步行十几分钟来到公交车站乘车回家吃午饭，晚上再乘车回来。 这样的作息让我受益无穷，可以省下早饭的钱来充当日常零花，不足之处是有老师在教室点名的可能和被楼管查到的危险。有一天早晨，当我像往常一样快乐地在床上翻滚的时候，突然传来了敲门的声音，我顿时很警觉，寻思应对法则，正当这时，门外传来一声呼唤： “栈弈在么？” 我用迷朦的双眼仔细辨认了一番，赫然看见Vae站在门外，他不知用什么方法逃避了军训，我们可算做这个校园里偷偷摸摸的两个自由人吧。我穿着个小裤衩顺梯爬下床，套个汗衫，给他倒了杯水，他说不喝，只是想来看看我们的杂志。 这个学院里充斥着各种各样的社团，其中比较著名的，也是在日后对我们的生活拥有影响的只有三个社团，文学社、演艺社、还有一个自虐会。自虐会学名自律会，就是学生代替老师每日上课实行点名夜里实行查房的学生自我虐待组织，是老师和学生的桥梁。演艺社和文学社则顾名思义，栈弈当时正在文学社混着，刚刚完成一本杂志的编印，或许这吸引了Vae的视线，让他冒死逃避军训来阅览杂志。我打算把他吸收进文学社来。 在后来几日的相处中我们逐渐认识了一些周边的人，比如我认识了大棒，比如Vae认识了胡子。 胡子的特征是没有胡子，我进入这所大学的时候他正在上大四，第一次见面是在文学社的招新面试上，我想进入文学社的网络部，当时我站在台上，和考官一问一答。 考官问我：你有什么爱好？ 我回答说：我爱好文学（这显然是必选项），我还爱好上网，还爱好美女。 考官又问：为什么选择我们的网络部？ 我回答说：为了满足我这三大爱好。 面试结束后我就被胡子找去，他声称我已被录取，俨然都是他的功劳一般。 而我则认为有没有他我都会被录取。 因为如果不录取我显然是他们的损失。 而面试的当天就真的有一个人在台上说“你们不录取我那将会是你们的损失”。 结果是，此人被损失。 而胡子，是个神秘的人，从不抽烟却一口能灌下半瓶白酒而面不改色，有个众人称美的女友却从不见两人同行，他会出现在学校里的所有场所却从未在宿舍楼里见到，最为神奇之处在于，不管你在学校惹了多大的麻烦，都可找他解决，大到被人追砍，小到旷课被捉。 胡子快毕业的时候找工作找的十分辛苦，坐着飞机在全国各地飞来飞去，结果是愿意要他的他看不上，看上的又不愿意要他，原因是他四级没过，我很纳闷这样一个神通广大的人为何无法将自己的四级搞定。记得我大一刚刚夏天的一个夜晚，胡子躺在学校？？？？边的草地上，破例地抽起了烟，半晌吐出一句话——“英语要搞好”。 后来的现实证明这句话对我毫无效应。在那个夜晚大约四个月后，胡子摇身一变，成为了Vae他们的辅导员，并在上任第一天受到Vae的冷遇。 再说大棒。 大棒是在Vae寝室认识的，平时睡在Vae对面，黑黑的，宽厚身板，淳朴憨厚的样子，据说来自北方的一个小县城。后来的一个夜晚在水房冲凉的时候遇见他，我顿时明白其名字的由来。在后来的日子里大棒的憨厚让我十分满意，而更令我满意的是大棒结实的身板，于是萌生将他也拉进文学社的想法，这样今后举办什么活动的时候，搬运桌椅的工作将可以顺利完成。不料谈及此事的时候被告知演艺社的人已经捷足先登，大棒已经对其社长死心塌地，决意要加入演艺社而后快。而原因仅仅是该社社长与大棒第一次见面时发了一根烟给他，这让大棒觉得很受尊重。 这是我第一次对大棒感到失望。 同样在Vae寝室认识的还有一个叫宁飞的男生，但与Vae并非室友关系，而是自虐会新发展的小会员，已然上阵来寝室查房了。早在新生报到那天晚上收摊的时候，此人就曾跑来向我询问如何加入自虐会，我对这种问题的答案是无可奉告，为的是少一个被此社团毒害者，不料此人无师自通自学成才找到组织。 此人与Vae竟然还是老校友。 作为已经大二的我深切知道大一的生活是苦闷的，这种苦闷比起高三只有过之而无不及，高三苦闷的时候我会听忧伤的歌曲来配合心情，极其小资。而大一连听歌的兴趣也消失，极其厌恶小资。整天只无精打采，每天零点到十二点睡觉，十二点到零点等待睡觉。 正因为如此我才会对和我同出于工大附中的Vae关爱有加，虽然他是借读在另一所重点高中而并未在工大附中读过一天书，但总比毫无联系的强一些。一个星期四，我对他无微不至的关怀终于得到回报，他声称邀请我出来会餐。 这次会餐对我们意义重大，因为在进食的过程中我得知他现在的女友是花费二十二天得手的，而此女是我高中时曾喜欢过的。得知这个真相之后我很迷茫了几秒钟，不知这个朋友是否能继续做下去，而几秒钟之后，胡子的音容笑貌浮现在我的眼前，我看见他说：“女人永远只能带来烦恼，而兄弟却可以借钱给你。”于是我豁然开朗向Vae 表明态度，然后我们饭扒得更欢了。 记得我高中时候的学校边上有一个网吧，起名叫做“地球村”，基本上任何时间进去都会遇见各种各样的熟人，应证了网吧的名字。有一种我们称之为宿命的东西，矫情一点说是缘分。我在怀疑我生活的地方是否真的很小，每次上街我都会遇见超过两个的熟人。但是曾经有一个让我爱得死去活来的女子，在她从我生命中消失之后我始终认为可以再见一面，却至今没有再遇见，一直到她的容颜由模糊变的清晰，然后再模糊。我始终感觉，当真正爱一个人的时候是记不得她的长相的，即使你们白天刚刚见过。当她的样子慢慢清晰，我慢慢的不再爱她，当她的样子再一次模糊，一切都已尘埃落定，我们只是命运里的路人，恰好有一段同路的旅途而已。 以上的问题可以归功于中国的人口问题，林子大了才会什么鸟儿都有，天下之大才会无奇不有，大千世界才会万象更新，因为人多，我每次上街遇到两个以上的熟人，因为人多，她被人海淹没。 有些事情就是这样，看起来平庸无奇，细想颇有玄机。相遇本是必然，但是为什么单单我们相遇，好象前世欠下的一般。无规律的点放射着无规律的射线，然后相交，然后相依为命狼狈为奸欢天喜地歇斯底里。公交车上坐过同一个位子的两个人，QQ上同时上线的两个人，打错你电话的人，你们毫无关系，你们却如此贴近，上帝安排好了一切还是一切都没有安排？ 尽管结果都是一样。 有些人或许你们本该相遇，但是却匆匆来去；而有些人或许本该相逢如萍，但是却日久生情；有些关系或许不该太近，但是却命中注定；有些关系或许无法逃避，但是却走近默剧；有些时候你感觉胜利在即，却发现一败涂地；有些时候你感觉尚有转机，却发现缘分已尽；有些事情根本不该提起，却又刻骨铭心；有些事情根本应该忘记，然而无能为力。寥寥几人，走进空城，演绎悲欢，拼剪情节。人员各就各位，空城纪由此展开。 ————栈弈]]></content>
      <categories>
        <category>转载</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《断舍离》]]></title>
    <url>%2F2017%2F04%2F25%2FReading%2F002.%20%E3%80%8A%E6%96%AD%E8%88%8D%E7%A6%BB%E3%80%8B%2F</url>
    <content type="text"><![CDATA[GO 该书作者：[日本]山下英子 1. 目的 通过学习断舍离，将会重新审视自己与物品之间的关系，从关注物品转换为关注自我——我需不需要，一旦思考，并致力于将身边所有“不需要、不合适、不舒服”的东西替换为“需要、合适、舒服”的东西，就能让环境变得清爽，也会由此改善心灵环境，从外在到内在，彻底焕然一新。 断舍离非常简单，只需要以自己为而不是物品为主角，去思考什么东西最适合现在的自己。只要是不符合这两个标准的东西就立即淘汰。 2. 方式 断舍离就是通过收拾自己居住的房间，让自己从看得见的世界走向看不见的世界的境界。 因此，要采取的行动是： 断 —— 断绝想要进入自己家的不需要的东西 舍 —— 舍弃家里到处泛滥的破烂儿通过不断重复断和舍，最后会达到这样的状态： 离 —— 脱离对物品的执念，处于游刃有余的自在的空间。 3. 说明补充 要从时间轴和关系轴来看物品。时间轴要定在当下，关系轴要定在自己的需要上。 3.1 筛选物品带来的自我觉察 这种改变的机制是这样的：要得到“这种东西与当下的我很相称，对当下的我来说是必需品”这样的判断，人就必须要清楚的了解自己。通过不断地筛选物品的训练，当下的自我就会越来越鲜明地呈现在自己的眼前，人也就能以此判断出准确的自我形象。 不但确保每样物品都在自己的掌控之下，自己能确实用到它，还要和它成为好朋友——和自己喜欢的东西生活在一起。这样的话，就是达到了“断”。在买东西的时候会反复思量，让物品物尽其用，并且确保能把它的功效发挥到极致，一直到用完。这就是断舍离的最终阶段。 3.2 三种扔不掉东西的人 逃避现实型 执着过去型 担忧未来型 3.3 破烂儿可以分三类 不用的东西漫不经心地保存或放着不管的东西，甚至是已经忘了它的存在的东西，是因为一想到扔掉就心怀不安所以就一直拖着没扔掉的东西。 还在用的东西好歹还算是在用，可其实并不喜欢，所以就随便使用着。我们会乱七八糟地乱放，毫不珍惜地随意乱用这些东西。 充满回忆的东西因为充满了怀念与回忆，所以总也丢不掉，是拥有强大能量的东西。 需要注意到的就是 把自己用不着的东西送给有需要的人时，要说“请收下”，不能说“给你”。 4. 画面美感的要求 物品要用才有价值。物品就在此时、当下，应该出现在需要它的地方。物品处于恰当的位置，才能展现美感。 OK]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《一万小时天才理论》]]></title>
    <url>%2F2017%2F04%2F24%2FReading%2F001.%20%E3%80%8A%E4%B8%80%E4%B8%87%E5%B0%8F%E6%97%B6%E5%A4%A9%E6%89%8D%E7%90%86%E8%AE%BA%E3%80%8B%2F</url>
    <content type="text"><![CDATA[GO 该书作者：[美国]丹尼尔·科伊尔 序 10000小时法则。这一法则是由20世纪70年代的心理学家们提出的，他们认为所有的世界级专家（从作曲家、外科医生到足球运动员）都需要经历10000小时（一般超过10年）的刻苦练习。 10000小时法则的关键在于：没有例外之人。没有人仅用3000小时就能达到世界级水准；7500小时也不行；一定要10000小时——10年，每天3小时——无论你是谁。 才能密码建立于颠覆性的科学发现之上，其中涉及一种叫做髓鞘质（myelin）的神经绝缘体，一些神经学家们称它为学习技能的圣杯。当我们开启神经回路的方式正确（练习正确的挥棒姿势或者弹钢琴）时，髓鞘质就给神经回路包上绝缘体，髓鞘质越厚，绝缘性就越强，我们的动作和思维就越加精确和敏捷。 髓鞘质的重要性体现在一下方面。一是普遍性，每个人都有髓鞘质，虽然小时候生长速度最快，但确实一辈子都在生长。二是通用性，髓鞘质的生长有利于所有类型的技能，包括智力型和体力型。三是无形性，髓鞘质看不见摸不着，只能在恰当的时机才能感受到。但是最重要的是，人们了解了髓鞘质这个新模型，就能清晰地理解技能。投入有效练习地时间和精力越多，就能越块掌握技能。 一万小时天才理论地三大要项：即精深、激情、伯乐。如何融合这三大要项正是掌握技能地关键，少了一项就会减慢这个过程。融合三者，哪怕只有6分钟，事情就会不一样。 第1章 精深1. 冒牌哈佛 谁也不能岁随随便便成功，它来自彻底的自我管理和毅力。——哈佛图书馆训言犯错让你更聪明。——德国寓言 精深练习是建立在一个悖论之上的：朝着既定目标挣扎前进，挑战自己的能力极限，不断犯错，会让你更聪明。类似的说法是，做哪些不得不放慢节奏的事情，犯错并加以改正——就像爬冰山，刚开始的时候会滑倒，会跌跌撞撞，最后会不知不觉中就变得敏捷自如。 精深练习是一个奇怪的概念，理由有二： 它违背了人们对“人才”的第一印象。（常识中与生俱来的天赋很重要，但其实是后天的精深练习更重要） 精深练习需要犯错，才可以转化为技能。谁也不能岁随随便便成功，它来自彻底的自我管理和毅力。——哈佛图书馆训言 2. 才能细胞 我一直认为，除了傻子，人在智力上差别不大，不同的只是热情和努力。——查尔斯达尔文 有两个原则，可以理解技能和髓鞘质之间的关系。 实际上，所有动作都是神经纤维链之间沟通的结果。 技能线路锻炼得越多，使用就越自如。 髓鞘质的原则 回路放电至关重要。髓鞘质不会凭着天真的愿望、模糊的想法，或者哪些洗个热水澡就忘光光的东西而生长。这种生理机制只钟情行动：真真实实的电流脉冲传过神经纤维。它钟情坚持重复。精深练习的动力来自原始状态，即时刻警、忍饥挨饿、目标明确，甚至绝望挣扎的状态。 髓鞘质包罗万象。以不变应万变。髓鞘质并不知道自己会被谁拿来使用，是（棒球的）游击手？还是舒伯特乐章的演奏者？无论何种用途，它的生长遵照同样的规则。髓鞘质一视同仁：哪条回路开启了，哪条回路就会包裹上绝缘体。髓鞘质不在乎你是谁，只在乎你做了什么。 髓鞘质无法逆转。髓鞘质化就像铺路，只朝一个方向前进。一旦技能回路包裹上了绝缘体，你就无法去除这层绝缘体（除非年龄或疾病）。这就是为什么习惯很难打破。改变旧习惯的唯一办法就是重复新动作以养成新习惯。 髓鞘质与年龄。儿童时期，髓鞘质会一波接一波地生成，有些由基因决定，有些与活动相关。这个状态一直持续到30多岁，为人类提供了一个轻松掌握新技能地关键期。此后，髓鞘质还会继续生长。直至50岁，损失地速度将快过生长地速度。人的一生都能够髓鞘质化——值得庆幸的是，5%的磷酸寡核苷酸一直出于处于不成熟状态，随时待命。但是，假如有人希望在晚年学习一门语言或一样乐器，那么他会发现，为生成必要的回路所付出的时间和汗水要多得多。这就是为什么绝大多数世界一流的高手自幼就进入该领域。他们的基因并没有随着年龄的增长而改变，只是生长新髓鞘质的能力不一样了。 如果正确训练自己的技能回路，即在精深练习时，努力完成那些勉强可以完成的事情，技能回路也会越来越敏捷和准确。 技能的通用理论： 精神练习X一万小时=世界级内容 3. 天降人才 优秀是一种习惯。——亚里士多德 4. 三大秘技秘技第一式：组快化 分成三步： 第一步，技能学习者整体了解一项任务——一个大组快，巨大的回路。 第二步，尽可能把它分解成最基础的组快。 第三步，花时间用慢动作练习，再加速，以了解其内在的结构。 说明： 整体吸收：指花时间观察或倾听你所想的技能，比如一首曲子、一个动作，而且这项技能是以连贯的实体形式出现。这一过程基本上相当于在脑中把技能具体化。模仿是很有效的办法。重点是找到其中的技巧。 拆分组快 放慢练习：放慢练习会使你更加关注错误，每一次都提高了精确度——而对于髓鞘质的生长而言，精确就是一切。 秘技第二式：重复练习 “练习并不能使之完美：完美的练习才能使之完美。”髓鞘质为这句话添上了新的内涵。在训练技能方面你，没有什么比实地操练更有效。要在精深练习区练习，否则不管花费了多少时间效果都不会很显著。 秘技第三式：尝试体会 注意力、连接、建立、完整的、警觉、关注、错误、重复、疲劳、边缘、唤醒。 这是一个独特的清单。精深练习是有目标的奋斗：选定目标、努力争取、评估差距、回到初始步骤。髓鞘质的一个进化优势就是，它能够使任何回路绝缘化，甚至是那些一开始我们不喜欢的（可能开始不喜欢，但随着精深练习，髓鞘质的绝缘化，我们可能会享受这样的体验）。 第2章 激情5. 信号统治所有人的普遍原则： 才能需要精深练习； 精深练习需要充分的能量； 某些信号会触发巨大能量的迸发。 6. 疯狂的海岛 培养技能的关键是，树立信心。一旦信心点燃之后，它就能一直燃烧。 正确的语言可以作为信号，以让人维持着激情。 7. 点燃明灯 本节无笔记。 第3章 伯乐8. 伯乐的武器 仅仅看见两颗幼苗，就能知道哪一棵会长得个更高，这可能吗？唯一的答案是，判断谁优谁劣还为时尚早，他们都还在成长。 髓鞘质法则：讲解、示范、模仿、纠正、然后重复。 不要期望一下子取得大幅度的进步。试着每天进不一小点。这是必经之路，而一旦开始进步，就会持续前进。 伟大的教练更像艺术，而非科学。它存在于两个人之间的距离，存在于语言、姿势、表达中。 9. 伯乐的一万小时 如果你休息一天，实力就会倒退两天。 好老师关心学生的一言一行，而且通过这种关心，以及利用他们对该课题已有的深刻理解，他们能够捕捉到学生在技能学习道路上碰到的障碍，以及摸索过程中难以形容的状态，然后按照已经设定的目标与学生沟通。 教师的四大优势： 优势一：知识矩阵——伯乐的杀手锏 一位优秀的老师总是有能力引导学生更加深入，能够看到学生不断的深入，因为他可以从各个角度思考这件事情，而且可以推演出无穷无尽的点。换言之，那是一种神秘的混合物，包含了技术上的知识、策略、经验。能够让他们信手拈来，判断理解学生的进度，接下来该朝着哪些地方努力。简言之，这个只是矩阵是一位伟大的教师的杀手锏。 优势二：洞察力——鹰的视力 “我不会对你们一视同仁，那样没有意义，因为你们每个人都不一样。全能的上帝有着无穷的智慧，没用一个模子造我们。谢天谢地，如果他这么做了，那世界该有多无聊啊？你不觉得吗？你们的身高、体重、背景、智力、才能等等都不一样。所以，你们每一位都应该区别对待，那是最适合你的。我会决定如何对待你们每一个人。” 优势三：简明的指示——神奇的教鞭 优势四：气质与诚信——不可阻挡的魅力 把学员推入髓鞘质生长，最终朝着每位教师都期盼的那一天前进：学生可以自己教自己。 10. 伯乐的赌注 教师就是为了逐步淡出。——托马斯卡拉瑟斯 第4章 后记：一万小时的世界 这个模型的好处是，它适用各种技能，各种情况，小至一个家庭，大至一个国家。 最后补充关于教育 学生需要伟大的老师。 早教光盘不会使孩子更聪明，反而会使他们变笨。因为它有效的阻止了精深练习的机会。光盘上的图像和声音有趣逼真，像是把婴儿泡在温水池里，但是与婴儿在真实生活中跌跌撞撞而获得的大量互动、犯错、学习比起来，则用处不大。 OK]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown基础语法]]></title>
    <url>%2F2017%2F04%2F23%2FTool%2F001.%20Markdown%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[GO 本文转自献给写作者的 Markdown 新手指南 1. Markdown 的优点： 纯文本，所以兼容性极强，可以用所有文本编辑器打开。 让你专注于文字而不是排版。 格式转换方便，Markdown 的文本你可以轻松转换为 html、电子书等。 Markdown 的标记语法有极好的可读性。 2. Markdown 的基础语法：2.1 标题123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 注意：“#”和[标题]之间建议保留一个字符的空格，这是标准的Markdown写法。 2.2 列表2.2.1 无序列表只需要在文字前面加上 - 就可以了。例如：123- 文本1- 文本2- 文本3 2.2.2 有序列表1231. 文本12. 文本23. 文本3 注意：“-”、“&gt;”与文本之间保留一个字符的空格。 2.3 链接和图片2.3.1 插入链接的语法：[显示文本](链接地址) 一个例子：[简书](http://www.jianshu.com) 2.3.2 插入图片的语法：![](图片链接地址) 一个例子：![](http://upload-images.jianshu.io/upload_images/259-0ad0d0bfc1c608b6.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) 注意：插入图片的语法和链接的语法很像，只是前面多了一个 ！ 2.4 引用在我们写作的时候经常需要引用他人的文字，这个时候引用这个格式就很有必要了。 在 Markdown 中，你只需要在你希望引用的文字前面加上 &gt; 就好了，例如： 1&gt; 一盏灯， 一片昏黄； 一简书， 一杯淡茶。 注：”&gt;” 和文本之间要保留一个字符的空格。 2.5 粗体和斜体用两个 * 包含一段文本就是粗体的语法，用一个 * 包含一段文本就是斜体的语法。例如：1*一盏灯*， 一片昏黄；**一简书**， 一杯淡茶。 其中「一盏灯」是斜体，「一简书」是粗体。 2.6 代码引用需要引用代码时，如果引用的语句只有一段，不分行，可以用 ` 将语句包起来。如果引用的语句为多行，可以将三个连续的`置于这段代码的首行和末行。 2.7 表格相关代码：12345| Tables | Are | Cool || ------------- |:-------------:| -----:|| col 3 is | right-aligned | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 | 显示效果： Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 相关代码：12345dog | bird | cat----|------|----foo | foo | foobar | bar | barbaz | baz | baz 显示效果： dog bird cat foo foo foo bar bar bar baz baz baz 2.8 显示链接中带括号的图片代码如下：12![][1][1]: http://latex.codecogs.com/gif.latex?\prod%20\(n_&#123;i&#125;\)+1 注意：像括号这种特殊符号需要用“\”转义。 3. 结束语Markdown的基础语法就是这么多了，对于一个写作者来说，这些就完全够用了。 如果想要学习更多Markdown的用法，参考这一篇文章：『Markdown 语法说明』 OK]]></content>
      <categories>
        <category>Tool</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书记录清单-武侠]]></title>
    <url>%2F2017%2F03%2F18%2FReading%2F000.%20%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95%E6%B8%85%E5%8D%95-%E6%AD%A6%E4%BE%A0%2F</url>
    <content type="text"><![CDATA[已读武侠作品记录 书名 作者 读完日期 一刀倾城 小李飞铲 2014 苍穹神剑 古龙 2014.06.19 月异星斜 古龙 2014.07.20 剑气严霜 古龙 2014.07.20 湘妃剑 古龙 2014.07.22 剑毒梅香 古龙 2014.07.22 孤星传 古龙 2014.07.25 失魂引 古龙 2014.07.28 游侠录 古龙 2014.08.03 护花铃 古龙 2014.09.22 彩环曲 古龙 2014.10.02 残金缺玉 古龙 2014.10.13 飘香剑雨 古龙 2014.10.31 飘香剑雨续 古龙 2014.11.01 剑玄录 古龙 2014.11.04 剑客行 古龙 2015.01.09 浣花洗剑录 古龙 2015.01.20 情人剑 古龙 2015.01.21 大旗英雄传 古龙 2015.01.22 武林外史 古龙 2015.01.24 名剑风流 古龙 2015.01.26 绝代双骄 古龙 2015.02.01 楚留香传奇之血海飘香 古龙 2015.04.18 楚留香传奇之大沙漠 古龙 2015.04.19 楚留香传奇之画眉鸟 古龙 2015.04.21 楚留香续集之鬼恋侠情 古龙 2015.04.21 楚留香续集之蝙蝠传奇 古龙 2015.04.22 楚留香续集之桃花传奇 古龙 2015.04.24 楚留香续集之新月传奇 古龙 2015.04.24 楚留香续集之午夜兰花 古龙 2015.04.27 多情剑客无情剑 古龙 2015.07.06 九月鹰飞 古龙 2015.09.04 欢乐英雄 古龙 2015.09.05 大人物 古龙 2015.09.06 萧十一郎 古龙 2015.09.29 火并萧十一郎 古龙 2015.09.29 流星蝴蝶剑 古龙 2015.10.10 七种武器之长生剑 古龙 2015.10.11 七种武器之碧玉刀 古龙 2015.11.02 七种武器之孔雀翎 古龙 2015.10.11 七种武器之多情环 古龙 2015.11.02 七种武器之霸王枪 古龙 2015.11.03 七种武器之离别钩 古龙 2015.11.04 七种武器之拳头 古龙 2015.11.04 天涯明月刀 古龙 2015.12.15 七杀手 古龙 2015.12.15 剑花烟雨江南 古龙 2015.12.16 三少爷的剑 古龙 2015.12.16 边城浪子 古龙 2015.12.28 血鹦鹉 古龙 2016.01.03 白玉老虎 古龙 2016.01.08 白玉雕龙 古龙 2016.01.08 大地飞鹰 古龙 2016.01.10 陆小凤传奇 古龙 2015.12.17 陆小凤之绣花大盗 古龙 2015.12.18 陆小凤之决战前后 古龙 2015.12.22 陆小凤之阴沟赌坊 古龙 2015.12.23 陆小凤之幽灵山庄 古龙 2015.12.23 陆小凤之凤舞九天 古龙 2015.12.24 陆小凤之剑神一笑 古龙 2015.12.25 圆月弯刀 古龙 2016.02.03 飞刀，又见飞刀 古龙 2016.01.08 英雄无泪 古龙 2016.02.05 七星龙王 古龙 2016.02.09 风铃中的刀声 古龙 2016.02.11 怒剑狂花 古龙 2016.02.16 那一剑的风情 古龙 2016.02.19 边城刀声 古龙 2016.02.19 赌局系列 古龙 2016.02.20 古龙传奇 古龙 2015.12.18 古龙散文集 古龙 2016.01.08 绝不低头 古龙 2016.03.26 菊花的刺 古龙 2016.05.12 闯崆峒 古龙 2016.05.18 铁血红颜 古龙 2016.05.21 丐帮之主 古龙 2016.07.16 碧血洗银枪 古龙 2016.05.21 书剑恩仇录 金庸 2015.06.30 碧血剑 金庸 2016.11.24 射雕英雄传 金庸 2016.12.01 飞狐外传 金庸 2016.12.07 雪山飞狐 金庸 2016.12.09 鸳鸯刀 金庸 2016.12.12 连城诀 金庸 2016.12.15 神雕侠侣 金庸 2016.12.17 倚天屠龙记 金庸 2016.12.20 白马啸西风 金庸 2016.12.20 侠客行 金庸 2016.12.23 笑傲江湖 金庸 2016.12.30 天龙八部 金庸 2017.01.18 鹿鼎记 金庸 2017.12.20 越女剑 金庸 2017.12.25 卫斯理1 倪匡 2017.10.16]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>读书清单</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书记录清单-科幻]]></title>
    <url>%2F2017%2F03%2F18%2FReading%2F000.%20%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95%E6%B8%85%E5%8D%95-%E7%A7%91%E5%B9%BB%2F</url>
    <content type="text"><![CDATA[已读科幻作品记录 书名 作者 读完日期 三体 刘慈欣 2014 球状闪电 刘慈欣 20160224 赡养人类 刘慈欣 20160225 赡养上帝 刘慈欣 20160225 朝闻道 刘慈欣 20160228 带上她的眼睛 刘慈欣 20160225 混沌蝴蝶 刘慈欣 20160225 欢乐颂 刘慈欣 20160225 流浪地球 刘慈欣 20160226 思想者 刘慈欣 20160226 微纪元 刘慈欣 20160226 白垩纪往事 刘慈欣 20160226 地火 刘慈欣 20160226 山 刘慈欣 20160226 全频带阻塞干扰 刘慈欣 20160227 地球大炮 刘慈欣 20160227 吞噬者(诗云前传) 刘慈欣 20160227 诗云 刘慈欣 20160227 坍塌 刘慈欣 20160227 圆圆的肥皂泡 刘慈欣 20160227 魔鬼积木 刘慈欣 20160227 海水高山 刘慈欣 20160227 信使 刘慈欣 20160227 人生 刘慈欣 20160227 命运 刘慈欣 20160227 中国太阳 刘慈欣 20160227 鲸歌 刘慈欣 20160227 乡村教师 刘慈欣 20160227 中国1285 刘慈欣 20160227 镜子 刘慈欣 20160227 纤维 刘慈欣 20160227 超新星纪元 刘慈欣 20160228 拉格朗日墓场 王晋康 20160228 解读生命 王晋康 20160302 水星播种 王晋康 20160305 七重外壳 王晋康 20160305 生存实验 王晋康 20160308 追杀K星人 王晋康 20160309 时间移民 刘慈欣 20160822 北京折叠 郝景芳 20160827 你一生的故事 特德姜 20170221 巴比伦塔 特德姜 20170221 领悟 特德姜 20170222 除以零 特德姜 20170223 蚁生 王晋康 20170929]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>读书清单</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书记录清单-综合]]></title>
    <url>%2F2017%2F03%2F18%2FReading%2F000.%20%E8%AF%BB%E4%B9%A6%E8%AE%B0%E5%BD%95%E6%B8%85%E5%8D%95-%E7%BB%BC%E5%90%88%2F</url>
    <content type="text"><![CDATA[GO 2013-2014 读书清单 书名 作者 读完日期 钢铁是怎样炼成的 尼古拉 奥斯特洛夫斯基 2013 问教余秋雨 吴拯修 2013 话西游养品性 李文库、钱同 2013 古欧洲之谜 埃里希-冯-丹尼肯 2013 明朝那些事儿（系列） 当年明月 2013 把时间当朋友——运用心智获得解放 李笑来 2014 拆掉思维的墙 古典 2014 平凡的世界 路遥 2014 人生 路遥 2014 一生的忠告 [英]查斯特菲尔德伯爵 20140504 别闹了、费曼先生 [美]R.费恩曼 20140519 你干嘛在乎别人怎么想 [美]R.费恩曼 20140618 诛仙 萧鼎 20140628 罪与罚 [俄]陀思妥耶夫斯基 20140819 匆匆那年 九夜茴 20141013 如果你在就好了：一封用旅途写就的情书 蔻蔻梁 20141022 海上灵光 许嵩 201409 乖，摸摸头 大冰 20141026 三毛流浪记全集（漫画） 张乐平 20141117 天才在左疯子在右 塔塔的死亡 20141117 小王子 [法]圣埃克苏佩里 20141117 撒哈拉的故事 三毛 20141118 遇见未知的自己 张德芬 20141118 七大圣 20141118 鬼吹灯（网络版全集） 天下霸唱 2014 盗墓笔记（全集） 南派三叔 20141129 悟空传 今何在 20141212 镜子：照出你看不见的世界史 爱德华多-加莱亚诺 20141217 草房子 曹文轩 20141230 2015 读书清单 书名 作者 读完日期 新世界：灵性的觉醒 艾克哈特-托尔 20150107 人间 曹俊 20150115 走进风月 袁岳 20150214 走进哈佛的美少女：韩国小姐金娜娜 20150214 成就你一生的100个哲理 卢化南 20150227 重遇未知的自己 张德芬 20150316 他们最幸福 大冰 20150331 遇见心想事成的自己 张德芬 20150406 沉默的大多数 王小波 20150428 成为富人的十一种能力 20150502 追风筝的人 卡勒德胡塞尼 20150429 阿狸：梦之城堡 20150429 情人 [法]玛格丽特-杜拉斯 20150505 挪威的森林 村上春树 20150506 世界尽头与冷酷仙境 村上春树 20150514 舞舞舞 村上春树 20150829 寻秦记 黄易 20150531 DOOM启示录 卡什诺 20150604 人件 TomDeNaro&amp;&amp;TimothyKister 20150616 花千骨 fresh果果 20150621 不抱怨的世界 威尔鲍温 20150626 共产党宣言 20150627 马克思传 萧灼基 20150703 写在人生的边上 钱钟书 20150706 The secret 秘密 郎达拜斯 20150706 菊花与刀 [美]鲁斯-本尼迪克特 20150713 追寻生命的意义 弗兰克尔、何忠强、、杨凡池 20150715 藏海花 南派三叔 20150717 黄河鬼馆 南派三叔 20150726 怒江之战 南派三叔 20150728 大漠苍狼 南派三叔 20150801 沙海 南派三叔 20150803 名家笔下的狗儿们 红孩-编 20150804 雾 巴金 20150808 骆驼祥子 老舍 20150808 少有人走的路 [美]约瑟夫-查斯特罗 20150811 呐喊与彷徨 鲁迅 20150817 编程之道 [美]Carlo Chung 20150819 阿弥陀佛么么哒 大冰 20150929 谁杀了我的牛 卡米洛-克鲁斯 20151008 升级你的大脑 20151017 1988：我想和这个世界谈谈 韩寒 20151017 看见真相的男孩 [英]西里尔-斯科特 20151020 阿米系列 恩里克-巴里奥斯 20151023 上帝咬过的苹果，那些缺陷天才们 梁笑梅 20151118 特斯拉自传 尼古拉特斯拉 20151118 风雨中抱紧自由 周若渠 20151120 马克吐温自传 马克吐温 20151201 另一宇宙来的人 冠玄 20151221 人的一半是外星人一半是地球人 李卫东 20151221 被禁止的科学 J-道格拉斯-凯尼恩 20151221 开动大脑——引爆学习力 苏引华 20151224 江湖异人传 向恺然 20151225 我是个算命先生 易之 20151225 我是个大师123 易之 20151226 苏格拉底的6个问题 克里斯托弗-菲利普斯 20151225 深度学习的艺术 知乎 20151227 火星救援 [美]安迪威尔 20151230 2016 读书清单 书名 作者 读完日期 蓝皮书计划UFO之谜 安克编 20160101 鲁滨逊漂流记 [英]丹尼尔-笛福 20160102 不必读书目 刀尔登 20160102 季羡林：读书与做人 季羡林 20160105 论十大关系 毛泽东 20160105 人生的意义 特里-伊格尔顿 20160109 解忧杂货店 东野圭吾 20160111 岛上书店 加布瑞埃拉-泽文 20160112 再生魔术之女 东野圭吾[短篇] 20160112 寻找时间的人 [爱尔兰]凯特-汤普森 20160114 麦田里的守望者 [美]杰罗姆·大卫·塞林格 20160130 细米 曹文轩 20160202 衣锦夜行 程毅南 20160207 幸福课 动机在杭州 20160207 电脑的秘密 20160216 Into the wild JonKrakauer 20160114 给讨厌数学的人：数学的奥妙和生活 小室直树 20160301 我们聊一聊：15位名人给大学生34封私人信 20160221 知乎周刊：你不是你的性别 20160308 知乎周刊：程序人生 20160308 过得刚好 郭德纲 20160311 老炮儿 管虎、董润年 20160311 一个人的朝圣 蕾秋-乔伊斯 20160314 陪安东尼度过漫长岁月-红橙黄 20160314 一个人的朝圣2：奎妮的情歌 蕾秋-乔伊斯 20160316 皮囊 蔡俊达 20160316 哲学家们都干了些什么 林欣浩 20160322 阿Q正传 鲁迅 20160322 中国缺什么，日本缺什么 近藤大介 20160323 读书这么好的事 张新颖 20160327 30岁之前别结婚 [美]陈愉/著，王剑波/译 20160418 超右脑英语学习法 [日]七田真 20160420 阅读就是魅力 kindle 20160424 二十年目睹怪现状 [清]吴妍人 20160427 信息简史 [美]詹姆斯-格雷克 20160506 最好的我们 八月长安 20160419 牛津通识读本：数学 蒂莫西-高尔斯 20160514 胡萝卜须 [法]列纳尔 著 王振孙 译 20160514 阿甘正传 [美]温斯顿-格卢姆 20160522 舍得让爱你的人受苦 张德芬 20160523 罗素的故事 20160523 活出全新的自己 张德芬 20160524 第三种猩猩-人类的身世和未来 戴蒙德 20160527 瓦尔登湖（译本） 梭罗 20160527 地心游记 [法]儒勒凡尔纳 20160528 七日谈 刀尔登 20160530 蔷薇园 [波斯]萨迪 20160603 只是为了好玩：Linux之父林纳斯自传 20160609 余罪（全8卷） 常书欣 20160624 老人与海 欧内斯特海明威 20160703 黑客与画家 保罗-格雷厄姆 20160710 肖申克的救赎 ［美］史蒂芬·金 20160730 看见 柴静 20160802 男人这东西 ［日］渡边淳一 20160807 八十天环游世界 凡尔纳 20160820 白夜行 东野圭吾 20160825 不抱怨的世界2 威尔鲍勃 20160902 断舍离 20160906 变形记 卡夫卡 20160908 海边的卡夫卡 村上春树 20160911 偷影子的人 马克李维 20160912 新月集 ［印度］泰戈尔 20160912 哈姆雷特 莎士比亚 20160913 人为什么活着 王小波 20160917 白说 白岩松 20160924 黑铁时代 王小波 20160929 死亡通知单（五本） 周浩晖 20160929 人间失格 太宰治 许时嘉 20161014 蒙马特遗书 邱妙津 20161015 无声告白 [美]伍绮诗 20161020 钟形罩 [美]西尔维亚普拉斯 20161027 谁动了我的奶酪 斯宾塞约翰逊 20161028 JT叔叔的理科教室-庄子 20161031 黑笑小说 20161118 蝇王 威廉戈尔丁 20161123 动物凶猛 王朔 20161212 2017 读书清单 书名 作者 读完日期 这一生，只为爱而活 20170305 走在阳光下 龙奔新 20170305 花间一枝禅 释然 20170306 一万小时天才理论 [美]丹尼尔科伊尔 20170405 刘慈欣谈科幻 刘慈欣 20170604 汤姆索亚历险记 马克吐温 20170915 白夜追凶 谢十三 20171220 2018 读书清单 书名 作者 读完日期 Ok]]></content>
      <categories>
        <category>Reading</category>
      </categories>
      <tags>
        <tag>读书清单</tag>
      </tags>
  </entry>
</search>
